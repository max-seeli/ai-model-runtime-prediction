{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HjktAqHVaPdD"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOZHfG34D1PoT1BARzFwonx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Ref:\n",
        "\n",
        "*   [TPU Graphs](https://arxiv.org/pdf/2308.13490.pdf)\n",
        "*   [GraphSAGE](https://arxiv.org/pdf/1706.02216.pdf)\n",
        "*   [Ranked List Loss for Deep Metric Learning](https://arxiv.org/pdf/1903.03238.pdf)\n"
      ],
      "metadata": {
        "id": "MpDNTtZ1akyt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO:\n",
        "\n",
        "*   split dataset to make upload faster\n",
        "*   test validation\n"
      ],
      "metadata": {
        "id": "F_YEokYoShJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes:\n",
        "\n",
        "*   Training simple model with MSE loss:\n",
        "    *   need hyperparamter search\n",
        "    *   why does the loss spice at the beginning of each epoch (batches are randomized)\n",
        "    *   oberservations: seems that the smaller models just learn some average absolute value, but not really a ranking\n",
        "    * probably model would have to be huge to rank correctly\n",
        "\n",
        "*   Training simple model with ranking loss:\n",
        "    *   Ranked List Loss\n",
        "    *   Extract the smallest k times\n",
        "\n",
        "*   Abandoning simple model:\n",
        "    *   Replicate TPU paper:\n",
        "        *   SageGraphs\n",
        "        *   ResGCN"
      ],
      "metadata": {
        "id": "X7rIMJhPqz5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies\n"
      ],
      "metadata": {
        "id": "1wDu2al2QKi7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TALB-TcjPpOB",
        "outputId": "2e8b210f-3448-42c3-b82c-a0ecc90c7ca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=904ea7c403cfc362d9d53766c4a10f2b1487ff61c40a6e912780f7a2b46cdc1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.3.1\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-geometric\n",
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch_geometric import nn as gnn\n",
        "\n",
        "from torch.nn import Linear, ReLU, Dropout\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from einops import reduce, repeat, rearrange\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "jJmWt_9HQSE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpuIRATBtfT0",
        "outputId": "c4c6eca2-c44a-4938-f7ab-b6d2d6a86872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "HwOap_4GQUm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaWsGUUAQa5U",
        "outputId": "b751c169-b5bc-4c75-b614-1ddceca85094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.unpack_archive(\"/content/drive/MyDrive/google-tpu/predict-ai-model-runtime.zip\", \"/content/data\")"
      ],
      "metadata": {
        "id": "oATdpYnXm-b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splits = [\"train\", \"valid\", \"test\"]\n",
        "\n",
        "nlp_default = '/content/data/npz_all/npz/layout/nlp/default'\n",
        "nlp_random = '/content/data/npz_all/npz/layout/nlp/random'\n",
        "xla_default = '/content/data/npz_all/npz/layout/xla/default'\n",
        "xla_random = '/content/data/npz_all/npz/layout/xla/random'\n",
        "\n",
        "xla_tile = '/content/data/npz_all/npz/tile/xla'"
      ],
      "metadata": {
        "id": "YHMebHg8QTsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_to_df(directory, split):\n",
        "\n",
        "    path = os.path.join(directory, split)\n",
        "    files = [os.path.join(path, file) for file in os.listdir(path)]\n",
        "    data_list = []\n",
        "    for file in tqdm(files):\n",
        "        data = dict(np.load(file))\n",
        "        data_list.append(data)\n",
        "\n",
        "    return pd.DataFrame(data_list)"
      ],
      "metadata": {
        "id": "bmsTgG-hRhcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### geometric dataloader"
      ],
      "metadata": {
        "id": "HhTogUWnaWTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Dataset, Data\n",
        "class RuntimeDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataset):\n",
        "            super().__init__()\n",
        "            self.dataset = dataset\n",
        "\n",
        "    def len(self): # TODO: not __len__ and __get__?\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def get(self, index):\n",
        "        data_row = self.dataset.loc[index]\n",
        "        normalized_runtime = torch.tensor(data_row['config_runtime'] / data_row['config_runtime_normalizers'], dtype=torch.float32)\n",
        "        return Data(\n",
        "          node_feat=torch.tensor(data_row['node_feat'], dtype=torch.float32),\n",
        "          edge_index=torch.tensor(data_row['edge_index'], dtype=torch.long).t().contiguous(),\n",
        "          node_opcode=torch.tensor(data_row['node_opcode'], dtype=torch.int32),\n",
        "          config_feat=torch.tensor(data_row['config_feat'], dtype=torch.float32),\n",
        "          y=normalized_runtime,\n",
        "          number_configs=torch.tensor([len(data_row['config_feat'])]) # needed to match config_feat to the corresponding graph in the batch\n",
        "        )"
      ],
      "metadata": {
        "id": "9yGq6NdzaaK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "def runtime_data_loader(dataset: RuntimeDataset, batch_size=32, shuffle=True):\n",
        "    '''\n",
        "       dataset: RuntimeDataset, containing data\n",
        "       ranking: if True will rank the different configurations and include according tensor in the dataset\n",
        "    '''\n",
        "\n",
        "    data_loader = DataLoader(dataset, batch_size, shuffle=True)\n",
        "    return data_loader"
      ],
      "metadata": {
        "id": "tBzr8xQuaiTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "axi4mAqeR68e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Batch\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, len_opcode_embedd, hidden_dim, output_dim, num_layers):\n",
        "        super(GNN, self).__init__()\n",
        "\n",
        "        self.len_opcode = len_opcode_embedd\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Embeddings\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings = 120, embedding_dim=len_opcode_embedd)\n",
        "\n",
        "        #GNN\n",
        "        input_dim = len_opcode_embedd + 140\n",
        "        layers = []\n",
        "        layers.append(GCNConv(input_dim, hidden_dim))\n",
        "        for _ in range(num_layers - 2):\n",
        "            layers.append(GCNConv(hidden_dim, hidden_dim))\n",
        "        layers.append(GCNConv(hidden_dim, output_dim))\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "\n",
        "        # Linear\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(output_dim + 24, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "\n",
        "        opcode_embedd = self.embedding_layer(data['node_opcode']) # (n,) -> (n,len_opcode_embedd)\n",
        "\n",
        "        x = torch.cat((opcode_embedd, data['node_feat']), dim=1) # [(n, len_opcode_embedd), (n,140)] -> (n, len_opcode_embedd + 140)\n",
        "\n",
        "        for layer in self.conv:\n",
        "            x = layer(x, data['edge_index'])\n",
        "            x = torch.relu(x)\n",
        "\n",
        "\n",
        "        # differ two cases:\n",
        "        # 1) batched data used for training\n",
        "        # 2) single graph Data object used for inference\n",
        "\n",
        "        if isinstance(data, Batch):\n",
        "\n",
        "          '''\n",
        "          The geometric data loader will take batch_size number of graphs. Then it will take all nodes in all these graphs and fuse them together into one graph.\n",
        "          On this fuesed graph it will perform the convolution to calculate all the node embeddings at once.\n",
        "          To apply the linear layer we have to seperate out all the graphs out of the batch again.\n",
        "          '''\n",
        "\n",
        "          # tensor used to store config predictions for each graph\n",
        "          configs = torch.empty(0,1).to(device)\n",
        "\n",
        "          # used to retrieve the config_feat tensors for each graph\n",
        "          total = 0\n",
        "\n",
        "          for graph_ind in range(data.num_graphs):\n",
        "\n",
        "            # using a mask to gather all nodes that belong to the graph_ind-th graph\n",
        "            node_indices = (data.batch == graph_ind).nonzero(as_tuple=True)[0]\n",
        "            # first dimension is the number of nodes in the graph with index graph_ind, second dimensions is the feature dimension of the convolution (n, output_dim)\n",
        "            graph_nodes = x[node_indices]\n",
        "\n",
        "            # reduce node embeedings to get a graph embedding\n",
        "            temp = reduce(graph_nodes, 'n f -> f', 'mean')\n",
        "\n",
        "            # number of configurations for the graph_ind-th graph\n",
        "            c = data.number_configs[graph_ind]\n",
        "\n",
        "            # config_feat for the graph_ind-th graph\n",
        "            graph_config_feat = data.config_feat[total:total+c]\n",
        "\n",
        "            total += c\n",
        "\n",
        "            # concatinating graph embedding with config_feat\n",
        "            temp = repeat(temp, 'f -> r f', r=c)\n",
        "            temp = torch.cat((temp, graph_config_feat), dim=1)\n",
        "\n",
        "\n",
        "            # apply linear layer to tensor with shape (c, output_dim+24)\n",
        "            temp = self.linear(temp)\n",
        "\n",
        "            # add calculated runtimes to configs\n",
        "            configs = torch.cat((configs, temp), dim=0)\n",
        "\n",
        "          configs = rearrange(configs, 'f 1 -> f')\n",
        "\n",
        "          return configs\n",
        "\n",
        "\n",
        "        # only working with one grap object\n",
        "        else:\n",
        "\n",
        "          x = reduce(x, 'n f -> f', 'mean') # (n, output_dim) -> (output_dim, )\n",
        "\n",
        "          x = repeat(x, 'f -> r f', r=len(data['config_feat'])) # (output_dim,) -> (c, output_dim)\n",
        "\n",
        "          x = torch.cat((x, data['config_feat']), dim=1) # [(x, output_dim), (c,24)] -> (c, output_dim + 24)\n",
        "\n",
        "          x = self.linear(x)\n",
        "\n",
        "          x = rearrange(x, 'f 1 -> f')\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "IhTaT48l29YH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN_bugged(nn.Module):\n",
        "    def __init__(self, len_opcode_embedd, hidden_dim, output_dim, num_layers):\n",
        "        super(GNN_bugged, self).__init__()\n",
        "        # Embeddings\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings = 120, embedding_dim=len_opcode_embedd)\n",
        "\n",
        "        #GNN\n",
        "        input_dim = len_opcode_embedd + 140\n",
        "        layers = []\n",
        "        layers.append(GCNConv(input_dim, hidden_dim))\n",
        "        for _ in range(num_layers - 2):\n",
        "            layers.append(GCNConv(hidden_dim, hidden_dim))\n",
        "        layers.append(GCNConv(hidden_dim, output_dim))\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "\n",
        "        # Linear\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(output_dim + 24, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        opcode_embedd = self.embedding_layer(data['node_opcode']) # (n,) -> (n,len_opcode_embedd)\n",
        "\n",
        "        x = torch.cat((opcode_embedd, data['node_feat']), dim=1) # [(n, len_opcode_embedd), (n,140)] -> (n, len_opcode_embedd + 140)\n",
        "\n",
        "        for layer in self.conv:\n",
        "            x = layer(x, data['edge_index'])\n",
        "            x = torch.relu(x)\n",
        "\n",
        "        x = reduce(x, 'n f -> f', 'mean') # (n, output_dim) -> (outputdim, )\n",
        "\n",
        "        x = repeat(x, 'f -> r f', r=len(data['config_feat'])) # (output_dim,) -> (c, output_dim)\n",
        "\n",
        "        x = torch.cat((x, data['config_feat']), dim=1) # [(x, output_dim), (c,24)] -> (c, output_dim + 24)\n",
        "\n",
        "        x = self.linear(x)\n",
        "\n",
        "        x = rearrange(x, 'b 1 -> b')\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "Nh8jyoN7R8oQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class dummy_model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(dummy_model, self).__init__()\n",
        "    self.linear = nn.Sequential(\n",
        "            nn.Linear(24, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "  def forward(self, x):\n",
        "      x = self.linear(x)\n",
        "      x = rearrange(x, 'f 1 -> f')\n",
        "      return x"
      ],
      "metadata": {
        "id": "ymZ22GYp8En3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class testing(nn.Module):\n",
        "  def __init__(self, prob: float):\n",
        "    super(testing, self).__init__()\n",
        "    self.prob = prob\n",
        "\n",
        "  def forward(self, data):\n",
        "    return data.y\n"
      ],
      "metadata": {
        "id": "tFyOvImex97L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Loop"
      ],
      "metadata": {
        "id": "5S4h21wDSCfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MSE_training(model: GNN, dataloader: DataLoader, epochs: int, lr=0.01):\n",
        "    '''\n",
        "    Training model using MSE\n",
        "    '''\n",
        "\n",
        "    print(type(model))\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "    #optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "    loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for batch, data in enumerate(dataloader):\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            x_pred = model(data)\n",
        "            #print(f\"shapes: {x_pred.shape}, {data['y'].shape}\")\n",
        "            loss = loss_fn(x_pred, data['y'])\n",
        "            loss.backward()\n",
        "            if batch % 200 == 0:\n",
        "                print('Epoch [{}/{}], Batch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, batch+1, len(dataloader), loss.item()))"
      ],
      "metadata": {
        "id": "Omv7foIQSPQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_dummy(model, dataloader,epochs,lr=0.01):\n",
        "  '''\n",
        "  Training model using MSE\n",
        "  '''\n",
        "\n",
        "  print(type(model))\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  #optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "  #optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "  loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      for batch, data in enumerate(dataloader):\n",
        "          data = data.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          x_pred = model(data.config_feat)\n",
        "          #print(f\"shapes: {x_pred.shape}, {data['y'].shape}\")\n",
        "          loss = loss_fn(x_pred, data['y'])\n",
        "          loss.backward()\n",
        "          if batch % 200 == 0:\n",
        "              print('Epoch [{}/{}], Batch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, batch+1, len(dataloader), loss.item()))"
      ],
      "metadata": {
        "id": "5Nbo1jtL9nT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation"
      ],
      "metadata": {
        "id": "2pck0LfZRq4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor([3.0, 4.0, 5.0, 1.0, 2.0])\n",
        "x_ranked = torch.argsort(x.squeeze(), descending=False)\n",
        "\n",
        "print(x_ranked)\n",
        "# Output: tensor([3, 4, 0, 1, 2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4duoOmJM0d-O",
        "outputId": "f9666301-9453-436f-c610-ce286aab91d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 4, 0, 1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_graph_ranking(x: torch.tensor, y: torch.tensor, k: int):\n",
        "    '''\n",
        "    evaluation metric for tiles\n",
        "    '''\n",
        "    x_ranked = torch.argsort(x.squeeze(), descending=False)\n",
        "    k_top = []\n",
        "\n",
        "    for i in range(min(len(x_ranked), k)):\n",
        "        k_top.append(y[x_ranked[i]])\n",
        "\n",
        "    best_runtime = torch.min(y)\n",
        "    k_top_best_runtime = min(k_top)\n",
        "\n",
        "    return 2 - k_top_best_runtime / best_runtime"
      ],
      "metadata": {
        "id": "DtheKFRcRujU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_model(model: GNN, dataloader: DataLoader, k: int):\n",
        "  '''\n",
        "  counts graphs for which the top k predictions contained the actual best runtime\n",
        "  '''\n",
        "  correct, total = 0, 0\n",
        "  model.to(device)\n",
        "  for _, data in enumerate(tqdm(dataloader)):\n",
        "    data = data.to(device)\n",
        "    total = total + data.num_graphs\n",
        "    x_pred = model(data)\n",
        "    ind = 0\n",
        "    for i in range(data.num_graphs):\n",
        "\n",
        "      if validate_graph_ranking(x_pred[ind:ind+data.number_configs[i]], data.y[ind:ind+data.number_configs[i]], k) == 1:\n",
        "        correct += 1\n",
        "      ind += data.number_configs[i]\n",
        "\n",
        "  print(f'correct k-tops predictions: [{correct}/{total}], {100*correct/total}%')"
      ],
      "metadata": {
        "id": "tXQ84Wtr-daR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_dummy_model(model, dataloader: DataLoader, k: int):\n",
        "  '''\n",
        "  counts graphs for which the top k predictions contained the actual best runtime\n",
        "  '''\n",
        "  correct, total = 0, 0\n",
        "  model.to(device)\n",
        "  for _, data in enumerate(tqdm(dataloader)):\n",
        "    data = data.to(device)\n",
        "    total = total + data.num_graphs\n",
        "    x_pred = model(data.config_feat)\n",
        "    ind = 0\n",
        "    for i in range(data.num_graphs):\n",
        "\n",
        "      if validate_graph_ranking(x_pred[ind:ind+data.number_configs[i]], data['y'][ind:ind+data.number_configs[i]], k) == 1:\n",
        "        correct = correct + 1\n",
        "\n",
        "      ind += data.number_configs[i]\n",
        "\n",
        "  print(f'correct k-tops predictions: [{correct}/{total}], {100*correct/total}%')"
      ],
      "metadata": {
        "id": "icio3CIK-4NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "ICQ6-FGiNLjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data_loader\n"
      ],
      "metadata": {
        "id": "cz9a6qzr_yMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = load_data_to_df(xla_tile, \"train\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiWbSiK0SL48",
        "outputId": "beeff0b0-8bf8-4644-8b48-a77540433644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5709/5709 [00:15<00:00, 357.14it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "dataset = RuntimeDataset(df)\n",
        "data_loader = runtime_data_loader(dataset, batch_size=4)\n",
        "len(data_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B81Dmus2SG3L",
        "outputId": "4cba3547-54e4-43b4-879f-2d3de0934816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1428"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### validation"
      ],
      "metadata": {
        "id": "m_icNCsPy7XG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_val = testing(0.5)\n",
        "validate_model(test_val, data_loader, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Mupaylqy7DM",
        "outputId": "e0f02a3c-6fff-49fa-fd1d-db52fedb363b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1428/1428 [00:06<00:00, 206.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct k-tops predictions: [5709/5709], 100.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dummy model"
      ],
      "metadata": {
        "id": "az9vHaIn_2f2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "dummy = dummy_model()\n",
        "train_dummy(dummy, data_loader, 3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylLLKWrn9RIV",
        "outputId": "558e9de2-43d4-4cd5-b4da-096d1b6ca585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.dummy_model'>\n",
            "Epoch [1/3], Batch [1/1428], Loss: 33.4778\n",
            "Epoch [1/3], Batch [201/1428], Loss: 36.1460\n",
            "Epoch [1/3], Batch [401/1428], Loss: 153.7309\n",
            "Epoch [1/3], Batch [601/1428], Loss: 44.9505\n",
            "Epoch [1/3], Batch [801/1428], Loss: 76.1029\n",
            "Epoch [1/3], Batch [1001/1428], Loss: 97.7942\n",
            "Epoch [1/3], Batch [1201/1428], Loss: 18.3323\n",
            "Epoch [1/3], Batch [1401/1428], Loss: 24.0022\n",
            "Epoch [2/3], Batch [1/1428], Loss: 41.0310\n",
            "Epoch [2/3], Batch [201/1428], Loss: 41.1890\n",
            "Epoch [2/3], Batch [401/1428], Loss: 55.5533\n",
            "Epoch [2/3], Batch [601/1428], Loss: 54.1709\n",
            "Epoch [2/3], Batch [801/1428], Loss: 44.5520\n",
            "Epoch [2/3], Batch [1001/1428], Loss: 13.8332\n",
            "Epoch [2/3], Batch [1201/1428], Loss: 28.6817\n",
            "Epoch [2/3], Batch [1401/1428], Loss: 28.2588\n",
            "Epoch [3/3], Batch [1/1428], Loss: 516.8983\n",
            "Epoch [3/3], Batch [201/1428], Loss: 109.7388\n",
            "Epoch [3/3], Batch [401/1428], Loss: 210.7040\n",
            "Epoch [3/3], Batch [601/1428], Loss: 17.1954\n",
            "Epoch [3/3], Batch [801/1428], Loss: 28.5319\n",
            "Epoch [3/3], Batch [1001/1428], Loss: 37.1865\n",
            "Epoch [3/3], Batch [1201/1428], Loss: 42.5041\n",
            "Epoch [3/3], Batch [1401/1428], Loss: 42.8816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validate_dummy_model(dummy, data_loader, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgC7MjQB_FaY",
        "outputId": "b02fda9b-6310-4032-9f6f-99f2eebce571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1428/1428 [00:10<00:00, 136.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct k-tops predictions: [470/5709], 8.232615169031353%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### gnn"
      ],
      "metadata": {
        "id": "bZXJyOrd_5_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model_bugged = GNN_bugged(len_opcode_embedd=8, hidden_dim=32, output_dim=16, num_layers=3)\n",
        "MSE_training(model_bugged, data_loader, 3, lr=0.0001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLHRPDIONJl4",
        "outputId": "1a4a2cd2-2a1c-40d7-9c78-18f748685619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.GNN_bugged'>\n",
            "Epoch [1/3], Batch [1/1428], Loss: 110787552.0000\n",
            "Epoch [1/3], Batch [201/1428], Loss: 712377024.0000\n",
            "Epoch [1/3], Batch [401/1428], Loss: 178438800.0000\n",
            "Epoch [1/3], Batch [601/1428], Loss: 33185614.0000\n",
            "Epoch [1/3], Batch [801/1428], Loss: 251439200.0000\n",
            "Epoch [1/3], Batch [1001/1428], Loss: 11946582.0000\n",
            "Epoch [1/3], Batch [1201/1428], Loss: 228379216.0000\n",
            "Epoch [1/3], Batch [1401/1428], Loss: 235065065472.0000\n",
            "Epoch [2/3], Batch [1/1428], Loss: 5062701056.0000\n",
            "Epoch [2/3], Batch [201/1428], Loss: 7467978752.0000\n",
            "Epoch [2/3], Batch [401/1428], Loss: 1007073344.0000\n",
            "Epoch [2/3], Batch [601/1428], Loss: 52635556.0000\n",
            "Epoch [2/3], Batch [801/1428], Loss: 283247456.0000\n",
            "Epoch [2/3], Batch [1001/1428], Loss: 12246102016.0000\n",
            "Epoch [2/3], Batch [1201/1428], Loss: 162581728.0000\n",
            "Epoch [2/3], Batch [1401/1428], Loss: 108249000.0000\n",
            "Epoch [3/3], Batch [1/1428], Loss: 259787024.0000\n",
            "Epoch [3/3], Batch [201/1428], Loss: 1033679872.0000\n",
            "Epoch [3/3], Batch [401/1428], Loss: 608960768.0000\n",
            "Epoch [3/3], Batch [601/1428], Loss: 41255012.0000\n",
            "Epoch [3/3], Batch [801/1428], Loss: 825892992.0000\n",
            "Epoch [3/3], Batch [1001/1428], Loss: 113346992.0000\n",
            "Epoch [3/3], Batch [1201/1428], Loss: 149087920.0000\n",
            "Epoch [3/3], Batch [1401/1428], Loss: 8690951.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validate_model(model_bugged, data_loader, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8N45jMq3DJu",
        "outputId": "9a953d7b-55a2-4c09-e46b-75e65a3217be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1428/1428 [00:15<00:00, 95.16it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct k-tops predictions: [329/5709], 5.7628306183219475%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model = GNN(len_opcode_embedd=32, hidden_dim=512, output_dim=256, num_layers=8)\n",
        "MSE_training(model, data_loader, 15, lr=0.1)"
      ],
      "metadata": {
        "id": "FkTpq81MSUW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02d66a9e-1212-4ae4-e227-9e8fcdbcfeda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.GNN'>\n",
            "Epoch [1/15], Batch [1/1428], Loss: 2142616.7500\n",
            "Epoch [1/15], Batch [201/1428], Loss: 48851048.0000\n",
            "Epoch [1/15], Batch [401/1428], Loss: 18449040.0000\n",
            "Epoch [1/15], Batch [601/1428], Loss: 29798194.0000\n",
            "Epoch [1/15], Batch [801/1428], Loss: 1977245.0000\n",
            "Epoch [1/15], Batch [1001/1428], Loss: 48957076.0000\n",
            "Epoch [1/15], Batch [1201/1428], Loss: 468172.1250\n",
            "Epoch [1/15], Batch [1401/1428], Loss: 1801847936.0000\n",
            "Epoch [2/15], Batch [1/1428], Loss: 3641160.7500\n",
            "Epoch [2/15], Batch [201/1428], Loss: 9909286.0000\n",
            "Epoch [2/15], Batch [401/1428], Loss: 236798544.0000\n",
            "Epoch [2/15], Batch [601/1428], Loss: 2537408.2500\n",
            "Epoch [2/15], Batch [801/1428], Loss: 17903664.0000\n",
            "Epoch [2/15], Batch [1001/1428], Loss: 543794752.0000\n",
            "Epoch [2/15], Batch [1201/1428], Loss: 26592594.0000\n",
            "Epoch [2/15], Batch [1401/1428], Loss: 6845207.0000\n",
            "Epoch [3/15], Batch [1/1428], Loss: 42193964.0000\n",
            "Epoch [3/15], Batch [201/1428], Loss: 64478348.0000\n",
            "Epoch [3/15], Batch [401/1428], Loss: 44976600.0000\n",
            "Epoch [3/15], Batch [601/1428], Loss: 53291396.0000\n",
            "Epoch [3/15], Batch [801/1428], Loss: 11306995.0000\n",
            "Epoch [3/15], Batch [1001/1428], Loss: 4105945.7500\n",
            "Epoch [3/15], Batch [1201/1428], Loss: 16951416.0000\n",
            "Epoch [3/15], Batch [1401/1428], Loss: 6289134.0000\n",
            "Epoch [4/15], Batch [1/1428], Loss: 16168316.0000\n",
            "Epoch [4/15], Batch [201/1428], Loss: 6501153.5000\n",
            "Epoch [4/15], Batch [401/1428], Loss: 11350570.0000\n",
            "Epoch [4/15], Batch [601/1428], Loss: 67028260.0000\n",
            "Epoch [4/15], Batch [801/1428], Loss: 16809442.0000\n",
            "Epoch [4/15], Batch [1001/1428], Loss: 124720.2656\n",
            "Epoch [4/15], Batch [1201/1428], Loss: 301408.7812\n",
            "Epoch [4/15], Batch [1401/1428], Loss: 224905.9375\n",
            "Epoch [5/15], Batch [1/1428], Loss: 1085444.2500\n",
            "Epoch [5/15], Batch [201/1428], Loss: 1152169.3750\n",
            "Epoch [5/15], Batch [401/1428], Loss: 2070853.3750\n",
            "Epoch [5/15], Batch [601/1428], Loss: 970535.5625\n",
            "Epoch [5/15], Batch [801/1428], Loss: 861779264.0000\n",
            "Epoch [5/15], Batch [1001/1428], Loss: 7978950.0000\n",
            "Epoch [5/15], Batch [1201/1428], Loss: 221246.6562\n",
            "Epoch [5/15], Batch [1401/1428], Loss: 36917844.0000\n",
            "Epoch [6/15], Batch [1/1428], Loss: 68655200.0000\n",
            "Epoch [6/15], Batch [201/1428], Loss: 42404428.0000\n",
            "Epoch [6/15], Batch [401/1428], Loss: 26568312.0000\n",
            "Epoch [6/15], Batch [601/1428], Loss: 54456860.0000\n",
            "Epoch [6/15], Batch [801/1428], Loss: 98991568.0000\n",
            "Epoch [6/15], Batch [1001/1428], Loss: 9458315.0000\n",
            "Epoch [6/15], Batch [1201/1428], Loss: 249234.0469\n",
            "Epoch [6/15], Batch [1401/1428], Loss: 500301.0312\n",
            "Epoch [7/15], Batch [1/1428], Loss: 123185816.0000\n",
            "Epoch [7/15], Batch [201/1428], Loss: 5821480.0000\n",
            "Epoch [7/15], Batch [401/1428], Loss: 9764584.0000\n",
            "Epoch [7/15], Batch [601/1428], Loss: 4169269.5000\n",
            "Epoch [7/15], Batch [801/1428], Loss: 7836941312.0000\n",
            "Epoch [7/15], Batch [1001/1428], Loss: 5824515.5000\n",
            "Epoch [7/15], Batch [1201/1428], Loss: 59635617792.0000\n",
            "Epoch [7/15], Batch [1401/1428], Loss: 748690.8750\n",
            "Epoch [8/15], Batch [1/1428], Loss: 174246.7656\n",
            "Epoch [8/15], Batch [201/1428], Loss: 125095880.0000\n",
            "Epoch [8/15], Batch [401/1428], Loss: 80408680.0000\n",
            "Epoch [8/15], Batch [601/1428], Loss: 4544662.0000\n",
            "Epoch [8/15], Batch [801/1428], Loss: 21528438.0000\n",
            "Epoch [8/15], Batch [1001/1428], Loss: 14063233024.0000\n",
            "Epoch [8/15], Batch [1201/1428], Loss: 3356770.0000\n",
            "Epoch [8/15], Batch [1401/1428], Loss: 839948.1250\n",
            "Epoch [9/15], Batch [1/1428], Loss: 1050982592.0000\n",
            "Epoch [9/15], Batch [201/1428], Loss: 568154432.0000\n",
            "Epoch [9/15], Batch [401/1428], Loss: 201933.5938\n",
            "Epoch [9/15], Batch [601/1428], Loss: 102850496.0000\n",
            "Epoch [9/15], Batch [801/1428], Loss: 1781692.3750\n",
            "Epoch [9/15], Batch [1001/1428], Loss: 1494522.6250\n",
            "Epoch [9/15], Batch [1201/1428], Loss: 21187250.0000\n",
            "Epoch [9/15], Batch [1401/1428], Loss: 655766.6250\n",
            "Epoch [10/15], Batch [1/1428], Loss: 8052847.0000\n",
            "Epoch [10/15], Batch [201/1428], Loss: 7596564.0000\n",
            "Epoch [10/15], Batch [401/1428], Loss: 57880368.0000\n",
            "Epoch [10/15], Batch [601/1428], Loss: 432496.3125\n",
            "Epoch [10/15], Batch [801/1428], Loss: 129872.5547\n",
            "Epoch [10/15], Batch [1001/1428], Loss: 138484252672.0000\n",
            "Epoch [10/15], Batch [1201/1428], Loss: 3201949.5000\n",
            "Epoch [10/15], Batch [1401/1428], Loss: 493617248.0000\n",
            "Epoch [11/15], Batch [1/1428], Loss: 2994964.0000\n",
            "Epoch [11/15], Batch [201/1428], Loss: 18984644.0000\n",
            "Epoch [11/15], Batch [401/1428], Loss: 5285292.5000\n",
            "Epoch [11/15], Batch [601/1428], Loss: 5429896.5000\n",
            "Epoch [11/15], Batch [801/1428], Loss: 40619868.0000\n",
            "Epoch [11/15], Batch [1001/1428], Loss: 118279984.0000\n",
            "Epoch [11/15], Batch [1201/1428], Loss: 119272.5234\n",
            "Epoch [11/15], Batch [1401/1428], Loss: 287964384.0000\n",
            "Epoch [12/15], Batch [1/1428], Loss: 151876304.0000\n",
            "Epoch [12/15], Batch [201/1428], Loss: 10424011.0000\n",
            "Epoch [12/15], Batch [401/1428], Loss: 853265.9375\n",
            "Epoch [12/15], Batch [601/1428], Loss: 664661.3750\n",
            "Epoch [12/15], Batch [801/1428], Loss: 33503306.0000\n",
            "Epoch [12/15], Batch [1001/1428], Loss: 33518488.0000\n",
            "Epoch [12/15], Batch [1201/1428], Loss: 288661.8125\n",
            "Epoch [12/15], Batch [1401/1428], Loss: 398608.4375\n",
            "Epoch [13/15], Batch [1/1428], Loss: 296322.7812\n",
            "Epoch [13/15], Batch [201/1428], Loss: 104700464.0000\n",
            "Epoch [13/15], Batch [401/1428], Loss: 859524.1875\n",
            "Epoch [13/15], Batch [601/1428], Loss: 217463.5625\n",
            "Epoch [13/15], Batch [801/1428], Loss: 554291.3750\n",
            "Epoch [13/15], Batch [1001/1428], Loss: 66034488.0000\n",
            "Epoch [13/15], Batch [1201/1428], Loss: 37248928.0000\n",
            "Epoch [13/15], Batch [1401/1428], Loss: 374379.2188\n",
            "Epoch [14/15], Batch [1/1428], Loss: 94300664.0000\n",
            "Epoch [14/15], Batch [201/1428], Loss: 12106211.0000\n",
            "Epoch [14/15], Batch [401/1428], Loss: 6561999.0000\n",
            "Epoch [14/15], Batch [601/1428], Loss: 90530248.0000\n",
            "Epoch [14/15], Batch [801/1428], Loss: 23714028.0000\n",
            "Epoch [14/15], Batch [1001/1428], Loss: 96326.3047\n",
            "Epoch [14/15], Batch [1201/1428], Loss: 35456680.0000\n",
            "Epoch [14/15], Batch [1401/1428], Loss: 12653979.0000\n",
            "Epoch [15/15], Batch [1/1428], Loss: 13126769.0000\n",
            "Epoch [15/15], Batch [201/1428], Loss: 637624.4375\n",
            "Epoch [15/15], Batch [401/1428], Loss: 92823448.0000\n",
            "Epoch [15/15], Batch [601/1428], Loss: 4342215.5000\n",
            "Epoch [15/15], Batch [801/1428], Loss: 1547886.2500\n",
            "Epoch [15/15], Batch [1001/1428], Loss: 251566736.0000\n",
            "Epoch [15/15], Batch [1201/1428], Loss: 81167240.0000\n",
            "Epoch [15/15], Batch [1401/1428], Loss: 1703643.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validate_model(model, data_loader, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWSGB5hxHLIZ",
        "outputId": "880f4820-945e-4aa9-8cee-cf3de63e73d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1428/1428 [00:25<00:00, 55.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct k-tops predictions: [156/5709], 2.7325275880189177%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_control = GNN(len_opcode_embedd=8, hidden_dim=32, output_dim=16, num_layers=3)\n",
        "validate_model(model_control, data_loader, 5)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model_control_bugged = GNN_bugged(len_opcode_embedd=8, hidden_dim=32, output_dim=16, num_layers=3)\n",
        "validate_model(model_control_bugged, data_loader, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "7M8zKjd43KJn",
        "outputId": "aa6e1a4f-ceed-45e2-8cf0-99b753daa5fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ec96a5766f7a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_control\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_opcode_embedd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_control\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "dataset = RuntimeDataset(df)\n",
        "data_loader = runtime_data_loader(dataset)\n",
        "len(data_loader)"
      ],
      "metadata": {
        "id": "3WbBxwLNGtdg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}