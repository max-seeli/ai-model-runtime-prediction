{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpDNTtZ1akyt"
      },
      "source": [
        "\n",
        "Ref:\n",
        "\n",
        "*   [TPU Graphs](https://arxiv.org/pdf/2308.13490.pdf)\n",
        "*   [GraphSAGE](https://arxiv.org/pdf/1706.02216.pdf)\n",
        "*   [Ranked List Loss for Deep Metric Learning](https://arxiv.org/pdf/1903.03238.pdf)\n",
        "* [Hyperparameter Search](https://scikit-learn.org/stable/modules/grid_search.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_YEokYoShJm"
      },
      "source": [
        "TODO:\n",
        "\n",
        "*   split dataset to make upload faster\n",
        "*   test validation\n",
        "*   in layout the config data should be a torch.int32, but overflows if not torch.long"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7rIMJhPqz5N"
      },
      "source": [
        "Notes:\n",
        "\n",
        "*   Training simple model with MSE loss:\n",
        "    *   need hyperparamter search\n",
        "    *   why does the loss spice at the beginning of each epoch (batches are randomized)\n",
        "    *   oberservations: seems that the smaller models just learn some average absolute value, but not really a ranking\n",
        "    * probably model would have to be huge to rank correctly\n",
        "\n",
        "*   Training simple model with ranking loss:\n",
        "    *   Ranked List Loss\n",
        "    *   Extract the smallest k times\n",
        "\n",
        "*   Abandoning simple model:\n",
        "    *   Replicate TPU paper:\n",
        "        *   SageGraphs\n",
        "        *   ResGCN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wDu2al2QKi7"
      },
      "source": [
        "## Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TALB-TcjPpOB",
        "outputId": "6b6883d8-61ec-49f6-d4b2-d842098bbc19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/661.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/661.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m655.4/661.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=5cdc832cc7985370ea8b157ee912dcb24bdb478f2fd04edd4857fb0476bb014a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.3.1\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-geometric\n",
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jJmWt_9HQSE_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from torch_geometric import nn as gnn\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, ReLU, Dropout\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from einops import reduce, repeat, rearrange\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpuIRATBtfT0",
        "outputId": "6eb9d3f0-bacc-451e-bb70-d498de7728da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwOap_4GQUm3"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaWsGUUAQa5U",
        "outputId": "af7c92c1-3ce8-41f8-e157-e7336f51a253"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6ugv1vYeQoP"
      },
      "source": [
        "### zipped data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oATdpYnXm-b_"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.unpack_archive(\"/content/drive/MyDrive/google-tpu/predict-ai-model-runtime.zip\", \"/content/data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHMebHg8QTsg"
      },
      "outputs": [],
      "source": [
        "splits = [\"train\", \"valid\", \"test\"]\n",
        "\n",
        "layout_nlp_default = '/content/data/npz_all/npz/layout/nlp/default'\n",
        "layout_nlp_random = '/content/data/npz_all/npz/layout/nlp/random'\n",
        "layout_xla_default = '/content/data/npz_all/npz/layout/xla/default'\n",
        "layout_xla_random = '/content/data/npz_all/npz/layout/xla/random'\n",
        "\n",
        "tile_xla = '/content/data/npz_all/npz/tile/xla'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXOnzxw3vKnF"
      },
      "outputs": [],
      "source": [
        "def load_data_to_df(directory, split):\n",
        "\n",
        "    path = os.path.join(directory, split)\n",
        "    files = [os.path.join(path, file) for file in os.listdir(path)]\n",
        "    data_list = []\n",
        "    for file in tqdm(files):\n",
        "        data = dict(np.load(file))\n",
        "        data_list.append(data)\n",
        "\n",
        "    return pd.DataFrame(data_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwgtm3jkeam4"
      },
      "source": [
        "### unzipped data in drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3EW2Co2dlJB-"
      },
      "outputs": [],
      "source": [
        "# unzipped archive in drive\n",
        "splits = [\"train\", \"valid\", \"test\"]\n",
        "\n",
        "layout_nlp_default = '/content/drive/MyDrive/google-tpu/predict-ai-model-runtime/npz_all/npz/layout/nlp/default'\n",
        "layout_nlp_random = '/content/drive/MyDrive/google-tpu/predict-ai-model-runtime/npz_all/npz/layout/nlp/random'\n",
        "layout_xla_default = '/content/drive/MyDrive/google-tpu/predict-ai-model-runtime/npz_all/npz/layout/xla/default'\n",
        "layout_xla_random = '/content/drive/MyDrive/google-tpu/predict-ai-model-runtime/npz_all/npz/layout/xla/random'\n",
        "\n",
        "tile_xla= '/content/drive/MyDrive/google-tpu/predict-ai-model-runtime/npz_all/npz/tile/xla'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bmsTgG-hRhcn"
      },
      "outputs": [],
      "source": [
        "def load_data_to_df(directory, split):\n",
        "\n",
        "    path = os.path.join(directory, split)\n",
        "    files = [os.path.join(path, file) for file in os.listdir(path)]\n",
        "    data_list = []\n",
        "    for file in tqdm(files):\n",
        "        data = dict(np.load(file))\n",
        "        data_list.append(data)\n",
        "\n",
        "    return pd.DataFrame(data_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhTogUWnaWTr"
      },
      "source": [
        "### geometric dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9yGq6NdzaaK3"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import Dataset, Data\n",
        "from typing import Literal\n",
        "\n",
        "class RuntimeDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, mode: Literal[\"tile\", \"layout\", \"layout_all\"]):\n",
        "            super().__init__()\n",
        "\n",
        "            self.mode = mode\n",
        "\n",
        "            if self.mode == \"layout_all\":\n",
        "\n",
        "              '''\n",
        "              Approach:\n",
        "              For every graph add c number of graphs to the dataset where every one of these graphs has node features that are the concat node features.\n",
        "              (nodes that don't have additional features are padded with zeros)\n",
        "              This has implications for training: we are now predicting a scalar value for each graph configuration (can not really train with ranking loss anymore)\n",
        "              '''\n",
        "\n",
        "              self.dataset = pd.DataFrame(columns=['graph_id', 'node_feat', 'node_opcode', 'edge_index', 'config_runtime'])\n",
        "\n",
        "              for index, row in data.iterrows():\n",
        "\n",
        "                # tensors to large, not memory efficient enough\n",
        "\n",
        "                c = row['config_runtime'].shape[0]\n",
        "\n",
        "                node_feat = torch.tensor(row['node_feat'], dtype=torch.float32) # (n, 140)\n",
        "                node_config_feat = torch.tensor(row['node_config_feat'], dtype=torch.float32) # (c, nc, 18)\n",
        "\n",
        "                node_feat = repeat(node_feat, 'n f -> r n f', r = c) # repeats every node c times (c, n, 140)\n",
        "                node = torch.zeros((c, node_feat.shape[1], 18)) # (c, n, 18)\n",
        "\n",
        "                node = torch.cat((node_feat, node), dim=2)\n",
        "\n",
        "                for j in range(node_config_feat.shape[1]):\n",
        "                  node[:,j,18:] = node_config_feat[:,j,:]\n",
        "\n",
        "                for i in range(c):\n",
        "\n",
        "                  graph = {'graph_id': index,\n",
        "                           'node_feat': node[i],\n",
        "                           'node_opcode': row['node_opcode'],\n",
        "                           'edge_index': row['edge_index'],\n",
        "                           'config_runtime': row['config_runtime'][i]\n",
        "                           }\n",
        "                  self.dataset.append(graph, ignore_index=True)\n",
        "\n",
        "            else:\n",
        "              self.dataset = data\n",
        "              self.mode = mode\n",
        "\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def get(self, index):\n",
        "        data_row = self.dataset.loc[index]\n",
        "        if self.mode == \"tile\":\n",
        "          normalized_runtime = torch.tensor(data_row['config_runtime'] / data_row['config_runtime_normalizers'], dtype=torch.float32)\n",
        "          return Data(\n",
        "            node_feat=torch.tensor(data_row['node_feat'], dtype=torch.float32),\n",
        "            edge_index=torch.tensor(data_row['edge_index'], dtype=torch.long).t().contiguous(),\n",
        "            node_opcode=torch.tensor(data_row['node_opcode'], dtype=torch.int32),\n",
        "            config_feat=torch.tensor(data_row['config_feat'], dtype=torch.float32),\n",
        "            y=normalized_runtime, # TODO: rename\n",
        "            number_configs=torch.tensor([len(data_row['config_runtime'])]) # needed to match config_feat to the corresponding graph in the batch\n",
        "          )\n",
        "\n",
        "\n",
        "        else:\n",
        "\n",
        "          data_row = self.dataset.loc[index]\n",
        "\n",
        "          return Data(\n",
        "            graph_id = torch.tensor(data_row['graph_id'], dtype=torch.long),\n",
        "            node_feat=data_row['node_feat'],\n",
        "            edge_index=torch.tensor(data_row['edge_index'], dtype=torch.long).t().contiguous(),\n",
        "            node_opcode=torch.tensor(data_row['node_opcode'], dtype=torch.int32),\n",
        "            config_runtime=torch.tensor(data_row['config_runtime'], dtype=torch.float32),\n",
        "            node_config_ids = torch.tensor(data_row['node_config_ids'], dtype=torch.long)\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tBzr8xQuaiTJ"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "def runtime_data_loader(dataset: RuntimeDataset, batch_size=32, shuffle=True):\n",
        "    '''\n",
        "       dataset: RuntimeDataset, containing data\n",
        "    '''\n",
        "\n",
        "    data_loader = DataLoader(dataset, batch_size, shuffle=True)\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cqbIhQhKhvS2"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def layout_loader(data, indicies, sample_size, batch_size=32):\n",
        "\n",
        "  df = pd.DataFrame(columns=['graph_id', 'node_feat', 'node_opcode', 'edge_index', 'config_runtime'])\n",
        "\n",
        "  for index, row in data.iterrows():\n",
        "\n",
        "    c = row['config_runtime'].shape[0]\n",
        "\n",
        "\n",
        "\n",
        "    node_feat = torch.tensor(row['node_feat'], dtype=torch.float32) # (n, 140)\n",
        "    node_config_feat = torch.tensor(row['node_config_feat'], dtype=torch.float32) # (c, nc, 18)\n",
        "\n",
        "    node = torch.zeros(node_feat.shape[0], 18)\n",
        "    node = torch.cat((node_feat, node), dim=1)\n",
        "\n",
        "\n",
        "    for _ in range(min(sample_size, c)):\n",
        "      rand_config = random.randint(0, c-1)\n",
        "      indicies[index].append(rand_config)\n",
        "\n",
        "      for i in range(node_config_feat.shape[1]):\n",
        "        node[row['node_config_ids'][i],:18] = node_config_feat[rand_config, i, :]\n",
        "\n",
        "      # debugging\n",
        "      # print(f\"graph: {index}, config: {rand_config}, value: {row['config_runtime'][rand_config]}\")\n",
        "\n",
        "      next_row = {'graph_id': index,\n",
        "                  'node_feat': node,\n",
        "                  'node_opcode': row['node_opcode'],\n",
        "                  'edge_index': row['edge_index'],\n",
        "                  'config_runtime': row['config_runtime'][rand_config],\n",
        "                  'node_config_ids': row['node_config_ids']\n",
        "                  }\n",
        "      df = pd.concat([df, pd.DataFrame([next_row])], ignore_index=True)\n",
        "\n",
        "  dataset = RuntimeDataset(df, \"layout\")\n",
        "\n",
        "  return indicies, runtime_data_loader(dataset, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk8nE5OfoufC"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Batch\n",
        "\"\"\"\n",
        "Basic approach as described in the google paper using a GCN\n",
        "\"\"\"\n",
        "class Vanilla_Tile_GNN(nn.Module):\n",
        "\n",
        "    def __init__(self, len_opcode_embedd, hidden_dim, output_dim, num_layers):\n",
        "        super(Vanilla_Tile_GNN, self).__init__()\n",
        "\n",
        "        self.len_opcode = len_opcode_embedd\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Embeddings\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings = 120, embedding_dim=len_opcode_embedd)\n",
        "\n",
        "        #GNN\n",
        "        input_dim = len_opcode_embedd + 140\n",
        "        layers = nn.ModuleList()\n",
        "        layers.append(GCNConv(input_dim, hidden_dim))\n",
        "        for _ in range(num_layers - 2): # TODO list comp, ReLU\n",
        "            layers.append(GCNConv(hidden_dim, hidden_dim))\n",
        "        layers.append(GCNConv(hidden_dim, output_dim))\n",
        "\n",
        "        self.conv = layers\n",
        "\n",
        "        # Linear\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(output_dim + 24, 48),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, 48),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "\n",
        "        opcode_embedd = self.embedding_layer(data['node_opcode']) # (n,) -> (n,len_opcode_embedd)\n",
        "\n",
        "        x = torch.cat((opcode_embedd, data['node_feat']), dim=1) # [(n, len_opcode_embedd), (n,140)] -> (n, len_opcode_embedd + 140 + 18)\n",
        "\n",
        "        for layer in self.conv:\n",
        "          x = layer(x, data['edge_index'])\n",
        "          x = torch.relu(x)\n",
        "\n",
        "        # differ two cases:\n",
        "        # 1) batched data used for training\n",
        "        # 2) single graph Data object used for inference\n",
        "\n",
        "        if isinstance(data, Batch):\n",
        "\n",
        "          '''\n",
        "          The geometric data loader will take batch_size number of graphs. Then it will take all nodes in all these graphs and fuse them together into one graph.\n",
        "          On this fuesed graph it will perform the convolution to calculate all the node embeddings at once.\n",
        "          To apply the linear layer we have to seperate out all the graphs out of the batch again.\n",
        "          '''\n",
        "\n",
        "          # tensor used to store config predictions for each graph\n",
        "          configs = torch.empty(0,1).to(device)\n",
        "\n",
        "          # used to retrieve the config_feat tensors for each graph\n",
        "          total = 0\n",
        "\n",
        "          for graph_ind in range(data.num_graphs):\n",
        "\n",
        "            # using a mask to gather all nodes that belong to the graph_ind-th graph\n",
        "            node_indices = (data.batch == graph_ind).nonzero(as_tuple=True)[0]\n",
        "            # first dimension is the number of nodes in the graph with index graph_ind, second dimensions is the feature dimension of the convolution (n, output_dim)\n",
        "            graph_nodes = x[node_indices]\n",
        "\n",
        "            # reduce node embeedings to get a graph embedding\n",
        "            temp = reduce(graph_nodes, 'n f -> f', 'mean')\n",
        "\n",
        "            # number of configurations for the graph_ind-th graph\n",
        "            c = data.number_configs[graph_ind]\n",
        "\n",
        "            # config_feat for the graph_ind-th graph\n",
        "            graph_config_feat = data.config_feat[total:total+c]\n",
        "\n",
        "            total += c\n",
        "\n",
        "            # concatinating graph embedding with config_feat\n",
        "            temp = repeat(temp, 'f -> r f', r=c)\n",
        "            temp = torch.cat((temp, graph_config_feat), dim=1)\n",
        "\n",
        "\n",
        "            # apply linear layer to tensor with shape (c, output_dim+24)\n",
        "            temp = self.linear(temp)\n",
        "\n",
        "            # add calculated runtimes to configs\n",
        "            configs = torch.cat((configs, temp), dim=0)\n",
        "\n",
        "          configs = rearrange(configs, 'f 1 -> f')\n",
        "\n",
        "          return configs\n",
        "\n",
        "        # only working with one graph object\n",
        "\n",
        "        else:\n",
        "\n",
        "          x = reduce(x, 'n f -> f', 'mean') # (n, output_dim) -> (output_dim, )\n",
        "\n",
        "          x = repeat(x, 'f -> r f', r=len(data['config_feat'])) # (output_dim,) -> (c, output_dim)\n",
        "\n",
        "          x = torch.cat((x, data['config_feat']), dim=1) # [(x, output_dim), (c,24)] -> (c, output_dim + 24)\n",
        "\n",
        "          x = self.linear(x)\n",
        "\n",
        "          x = rearrange(x, 'f 1 -> f')\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "fvrsfyRKkBn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "mQuXlMCPHUIJ"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import Batch\n",
        "\"\"\"\n",
        "TODO: add regularisation\n",
        "      make the linear layer variable\n",
        "      batch normalization\n",
        "\"\"\"\n",
        "class Tile_GNN(nn.Module):\n",
        "\n",
        "    def __init__(self, len_opcode_embedd, hidden_dim_conv, output_dim_conv, num_layers_conv, dropout_conv,\n",
        "                                          hidden_dim_lin, num_layers_lin, dropout_lin):\n",
        "        super(Tile_GNN, self).__init__()\n",
        "\n",
        "        self.len_opcode_embedd = len_opcode_embedd\n",
        "        self.hidden_dim_conv = hidden_dim_conv\n",
        "        self.output_dim_conv = output_dim_conv\n",
        "        self.num_layers_conv = num_layers_conv\n",
        "        self.dropout_conv = 0 if dropout_conv is None else dropout_conv\n",
        "\n",
        "        self.hidden_dim_lin = hidden_dim_lin\n",
        "        self.num_layers_lin = num_layers_lin\n",
        "        self.dropout_lin = dropout_lin\n",
        "        self.dropout_lin = 0 if dropout_lin is None else dropout_lin\n",
        "\n",
        "        # Dropout\n",
        "        self.conv_dropout = nn.Dropout(p=self.dropout_conv)\n",
        "        self.lin_dropout = nn.Dropout(p=self.dropout_lin)\n",
        "        # Embeddings\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings = 120, embedding_dim=self.len_opcode_embedd)\n",
        "\n",
        "        # GNN\n",
        "        input_dim = self.len_opcode_embedd + 140\n",
        "        layers = nn.ModuleList()\n",
        "        layers.append(GCNConv(input_dim, self.hidden_dim_conv))\n",
        "        for _ in range(self.num_layers_conv - 2): # TODO list comp, ReLU\n",
        "            layers.append(GCNConv(self.hidden_dim_conv, self.hidden_dim_conv))\n",
        "        layers.append(GCNConv(self.hidden_dim_conv,self.output_dim_conv))\n",
        "\n",
        "        self.conv = layers\n",
        "\n",
        "        # Linear\n",
        "        lin_layers = [nn.Linear(self.output_dim_conv + 24, self.hidden_dim_lin), nn.ReLU(), self.lin_dropout]\n",
        "        for i in range(self.num_layers_lin - 2):\n",
        "          lin_layers.append(nn.Linear(self.hidden_dim_lin, self.hidden_dim_lin))\n",
        "          lin_layers.append(nn.ReLU())\n",
        "          lin_layers.append(self.lin_dropout)\n",
        "        lin_layers.append(nn.Linear(self.hidden_dim_lin, 1))\n",
        "\n",
        "        self.linear = nn.Sequential(*lin_layers)\n",
        "\n",
        "    def forward(self, data):\n",
        "\n",
        "        opcode_embedd = self.embedding_layer(data['node_opcode']) # (n,) -> (n,len_opcode_embedd)\n",
        "\n",
        "        x = torch.cat((opcode_embedd, data['node_feat']), dim=1) # [(n, len_opcode_embedd), (n,140)] -> (n, len_opcode_embedd + 140 + 18)\n",
        "\n",
        "        for layer in self.conv:\n",
        "          x = layer(x, data['edge_index'])\n",
        "          x = torch.relu(x)\n",
        "          x = self.conv_dropout(x)\n",
        "\n",
        "        # differ two cases:\n",
        "        # 1) batched data used for training\n",
        "        # 2) single graph Data object used for inference\n",
        "\n",
        "        if isinstance(data, Batch):\n",
        "\n",
        "          '''\n",
        "          The geometric data loader will take batch_size number of graphs. Then it will take all nodes in all these graphs and fuse them together into one graph.\n",
        "          On this fuesed graph it will perform the convolution to calculate all the node embeddings at once.\n",
        "          To apply the linear layer we have to seperate out all the graphs out of the batch again.\n",
        "          '''\n",
        "\n",
        "          # tensor used to store config predictions for each graph\n",
        "          configs = torch.empty(0,1).to(device)\n",
        "\n",
        "          # used to retrieve the config_feat tensors for each graph\n",
        "          total = 0\n",
        "\n",
        "          for graph_ind in range(data.num_graphs):\n",
        "\n",
        "            # using a mask to gather all nodes that belong to the graph_ind-th graph\n",
        "            node_indices = (data.batch == graph_ind).nonzero(as_tuple=True)[0]\n",
        "            # first dimension is the number of nodes in the graph with index graph_ind, second dimensions is the feature dimension of the convolution (n, output_dim)\n",
        "            graph_nodes = x[node_indices]\n",
        "\n",
        "            # reduce node embeedings to get a graph embedding\n",
        "            temp = reduce(graph_nodes, 'n f -> f', 'mean')\n",
        "\n",
        "            # number of configurations for the graph_ind-th graph\n",
        "            c = data.number_configs[graph_ind]\n",
        "\n",
        "            # config_feat for the graph_ind-th graph\n",
        "            graph_config_feat = data.config_feat[total:total+c]\n",
        "\n",
        "            total += c\n",
        "\n",
        "            # concatinating graph embedding with config_feat\n",
        "            temp = repeat(temp, 'f -> r f', r=c)\n",
        "            temp = torch.cat((temp, graph_config_feat), dim=1)\n",
        "\n",
        "\n",
        "            # apply linear layer to tensor with shape (c, output_dim+24)\n",
        "            temp = self.linear(temp)\n",
        "\n",
        "            # add calculated runtimes to configs\n",
        "            configs = torch.cat((configs, temp), dim=0)\n",
        "\n",
        "          configs = rearrange(configs, 'f 1 -> f')\n",
        "\n",
        "          return configs\n",
        "\n",
        "        # only working with one graph object\n",
        "\n",
        "        else:\n",
        "\n",
        "          x = reduce(x, 'n f -> f', 'mean') # (n, output_dim) -> (output_dim, )\n",
        "\n",
        "          x = repeat(x, 'f -> r f', r=len(data['config_feat'])) # (output_dim,) -> (c, output_dim)\n",
        "\n",
        "          x = torch.cat((x, data['config_feat']), dim=1) # [(x, output_dim), (c,24)] -> (c, output_dim + 24)\n",
        "\n",
        "          x = self.linear(x)\n",
        "\n",
        "          x = rearrange(x, 'f 1 -> f')\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhTaT48l29YH"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import Batch\n",
        "class Layout_GNN(nn.Module):\n",
        "\n",
        "    def __init__(self, len_opcode_embedd, hidden_dim, output_dim, num_layers):\n",
        "        super(Layout_GNN, self).__init__()\n",
        "\n",
        "        self.len_opcode = len_opcode_embedd\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Embeddings\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings = 120, embedding_dim=len_opcode_embedd)\n",
        "\n",
        "        #GNN\n",
        "        input_dim = len_opcode_embedd + 140 + 18\n",
        "        layers = nn.ModuleList()\n",
        "        layers.append(GCNConv(input_dim, hidden_dim))\n",
        "        for _ in range(num_layers - 2): # TODO list comp, ReLU\n",
        "            layers.append(GCNConv(hidden_dim, hidden_dim))\n",
        "        layers.append(GCNConv(hidden_dim, output_dim))\n",
        "\n",
        "        self.conv = layers\n",
        "\n",
        "        # Linear\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(output_dim, 48),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, 48),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "\n",
        "        opcode_embedd = self.embedding_layer(data['node_opcode']) # (n,) -> (n,len_opcode_embedd)\n",
        "\n",
        "        x = torch.cat((opcode_embedd, data['node_feat']), dim=1) # [(n, len_opcode_embedd), (n,140 + 18)] -> (n, len_opcode_embedd + 140 + 18)\n",
        "\n",
        "        for layer in self.conv:\n",
        "          x = layer(x, data['edge_index'])\n",
        "          x = torch.relu(x)\n",
        "\n",
        "        # differ two cases:\n",
        "        # 1) batched data used for training\n",
        "        # 2) single graph Data object used for inference\n",
        "\n",
        "        if isinstance(data, Batch):\n",
        "\n",
        "          '''\n",
        "          The geometric data loader will take batch_size number of graphs. Then it will take all nodes in all these graphs and fuse them together into one graph.\n",
        "          On this fuesed graph it will perform the convolution to calculate all the node embeddings at once.\n",
        "          To apply the linear layer we have to seperate out all the graphs out of the batch again.\n",
        "          '''\n",
        "\n",
        "          # tensor used to store config predictions for each graph\n",
        "          configs = torch.empty(0).to(device)\n",
        "\n",
        "          for graph_ind in range(data.num_graphs):\n",
        "\n",
        "            # using a mask to gather all nodes that belong to the graph_ind-th graph\n",
        "            node_indices = (data.batch == graph_ind).nonzero(as_tuple=True)[0]\n",
        "            # first dimension is the number of nodes in the graph with index graph_ind, second dimensions is the feature dimension of the convolution (n, output_dim)\n",
        "            graph_nodes = x[node_indices]\n",
        "\n",
        "            # reduce node embeedings to get a graph embedding\n",
        "            temp = reduce(graph_nodes, 'n f -> f', 'mean')\n",
        "            # apply linear layer to tensor with shape (c, output_dim+24)\n",
        "            temp = self.linear(temp)\n",
        "\n",
        "\n",
        "            # add calculated runtimes to configs\n",
        "            configs = torch.cat((configs, temp), dim=0)\n",
        "\n",
        "          return configs\n",
        "\n",
        "        # only working with one graph object\n",
        "\n",
        "        else:\n",
        "\n",
        "          x = reduce(x, 'n f -> f', 'mean') # (n, output_dim) -> (output_dim, )\n",
        "\n",
        "          x = self.linear(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S4h21wDSCfV"
      },
      "source": [
        "## Train Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbN1tFabfQ-f"
      },
      "source": [
        "### Tiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Omv7foIQSPQf"
      },
      "outputs": [],
      "source": [
        "def MSE_training_tile(model: Tile_GNN, dataloader: DataLoader, epochs: int, lr=0.01):\n",
        "    '''\n",
        "    Training model using MSE\n",
        "    '''\n",
        "\n",
        "    print(type(model))\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "    #optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "    loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        for batch, data in enumerate(dataloader):\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            x_pred = model(data)\n",
        "            #print(f\"shapes: {x_pred.shape}, {data['y'].shape}\")\n",
        "            loss = loss_fn(x_pred, data['y'])/len(data['y'])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            #if batch % 200 == 0:\n",
        "            #    print('Epoch [{}/{}], Batch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, batch+1, len(dataloader), loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "I3qJ4u2Y63m4"
      },
      "outputs": [],
      "source": [
        "def no_batch_training_tile(model, dataset, epochs, lr=0.01):\n",
        "  '''\n",
        "  Training model using MSE\n",
        "  '''\n",
        "\n",
        "  print(type(model))\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  #optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "  #optimizer = torch.optim.Adagrad(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "  loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "  model.to(device)\n",
        "  model.train()\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "      for num, graph in enumerate(dataset):\n",
        "          graph = graph.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          x_pred = model(graph)\n",
        "          #print(f\"shapes: {x_pred.shape}, {data['y'].shape}\")\n",
        "          loss = loss_fn(x_pred, graph['y'])/len(graph['y'])\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          #if num % 500 == 0:\n",
        "          #    print('Epoch [{}/{}], Batch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, num+1, len(dataset), loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# implementaion of ListNET Loss (see: https://arxiv.org/pdf/1911.09798v2.pdf)\n",
        "\n",
        "def ListNet_training_tile(model: Tile_GNN, dataloader: DataLoader, epochs: int, lr=0.01):\n",
        "    '''\n",
        "    Training model using MSE\n",
        "    '''\n",
        "\n",
        "    print(type(model))\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "    #optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        for batch, data in enumerate(dataloader):\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            x_pred = model(data)\n",
        "\n",
        "            # predicted distribution, need to negate since lower ist better\n",
        "\n",
        "            pred_distribution = F.softmax(-x_pred, dim=0)\n",
        "\n",
        "            label_distribution = F.softmax(-data['y'], dim=0)\n",
        "\n",
        "            listnet_loss = -torch.sum(label_distribution * torch.log(pred_distribution))\n",
        "\n",
        "            listnet_loss.backward()\n",
        "            optimizer.step()"
      ],
      "metadata": {
        "id": "-tiGXhNgpVf-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testmodel = Tile_GNN(len_opcode_embedd=4, hidden_dim=10, output_dim=5, num_layers=3)"
      ],
      "metadata": {
        "id": "FRI8HvpOrcsG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ListNet_training_tile(testmodel, data_loader, 5, lr=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "L7T9CLv8ryB4",
        "outputId": "488e281c-a2a1-4e7e-8eb3-28ce3ab0f55b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 2/5 [00:48<01:13, 24.38s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-1232929ab838>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mListNet_training_tile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-40440909bc13>\u001b[0m in \u001b[0;36mListNet_training_tile\u001b[0;34m(model, dataloader, epochs, lr)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 or (isinstance(idx, np.ndarray) and np.isscalar(idx))):\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-141d1f294ac6>\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tile\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m           \u001b[0mnormalized_runtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config_runtime'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdata_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config_runtime_normalizers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m           return Data(\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mnode_feat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'node_feat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0medge_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'edge_index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, edge_index, edge_attr, y, pos, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0mpropobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_store\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pop_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pop_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m_pop_cache\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pop_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cached_attr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'_mapping'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validate_model_tiles(testmodel, train_dataset)"
      ],
      "metadata": {
        "id": "aYjE7fursodb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate_model_tiles(testmodel, valid_dataset)"
      ],
      "metadata": {
        "id": "4iyiobEeshCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testmodel_ground = Tile_GNN(len_opcode_embedd=4, hidden_dim=10, output_dim=5, num_layers=3)"
      ],
      "metadata": {
        "id": "TTY5zjcvs2zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE_training_tile(testmodel_ground, data_loader, 5, lr=0.01)"
      ],
      "metadata": {
        "id": "6yYDZPDtsedM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate_model_tiles(testmodel_ground, train_dataset)"
      ],
      "metadata": {
        "id": "qKrEb6QrtEoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate_model_tiles(testmodel_ground, valid_dataset)"
      ],
      "metadata": {
        "id": "DNzKt99OtBVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIxuW_Y-fTN7"
      },
      "source": [
        "### Layout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbjQ_agQfWHW"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Problem: Too many graphs in the layout dataset make it hard to train model.\n",
        "More precisely the problem is not the number of graphs but more the number of configs for each graph.\n",
        "One possible way to mittigate this problem is to train only on a selection of graph configurations.\n",
        "Want to experiment with different selection procedures find select graphs and their configuratoins that bring the most value.\n",
        "'''\n",
        "\n",
        "def MSE_training_layout(model: Layout_GNN, dataset, epochs: int, sample_size=50, batch_size=32, lr=0.01):\n",
        "    '''\n",
        "    Training model using MSE\n",
        "    '''\n",
        "\n",
        "    print(type(model))\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "    #optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "    loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    indicies = [[] for _ in range(len(dataset))]\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "\n",
        "        indicies, dataloader = layout_loader(dataset, indicies, sample_size=sample_size, batch_size=batch_size)\n",
        "\n",
        "        for batch, data in enumerate(dataloader):\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            x_pred = model(data)\n",
        "            loss = loss_fn(x_pred, data['config_runtime'])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            #if batch % 200 == 0:\n",
        "            #    print('Epoch [{}/{}], Batch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, batch+1, len(dataloader), loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pck0LfZRq4R"
      },
      "source": [
        "## Validation\n",
        "TODO:\n",
        "calculate relative weight of layout and tile data\n",
        "validate sample submission and see if it matches their score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "N2RyiEhgJN3B"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import Data\n",
        "\n",
        "def validate_model_tiles(model, dataset):\n",
        "\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = []\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    for tile in tqdm(dataset):\n",
        "        tile.to(device)\n",
        "        out = model(tile)\n",
        "        predictions.append(torch.sort(out).indices)\n",
        "\n",
        "    # Calculate score\n",
        "    score = 0.0\n",
        "\n",
        "    for i, tile in tqdm(enumerate(dataset), total=len(dataset)):\n",
        "        best_prediction = min([dataset[i][\"y\"][pred_ind] for pred_ind in predictions[i][:5]])\n",
        "        best_total = min(dataset[i][\"y\"])\n",
        "        score += 2.0 - best_prediction / best_total\n",
        "\n",
        "    avg_score = score / len(dataset)\n",
        "    print(\"Score:\", avg_score)\n",
        "    return avg_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "48mVzPfpTrKk"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import Data\n",
        "\n",
        "def validate_model_layout(model, dataset):\n",
        "\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = []\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    for graph_ind in range(len(dataset)):\n",
        "      # c = graph['config_runtime'].shape[0]\n",
        "      c = dataset.iloc[graph_ind]['config_runtime'].shape[0]\n",
        "      graph_pred = []\n",
        "      node_config_ids = dataset.iloc[graph_ind]['node_config_ids']\n",
        "      node_config_feat = torch.tensor(dataset.iloc[graph_ind]['node_config_feat'], dtype=torch.float32)\n",
        "      node_feat = torch.tensor(dataset.iloc[graph_ind]['node_feat'], dtype=torch.float32)\n",
        "      node = torch.zeros((node_feat.shape[0], 18))\n",
        "      node = torch.cat((node_feat, node), dim=1)\n",
        "\n",
        "      for config in tqdm(range(c)):\n",
        "        node_config = node.clone()\n",
        "\n",
        "        for i in range(node_config_feat.shape[1]):\n",
        "          node_config[node_config_ids[i], :18] = node_config_feat[config,i,:]\n",
        "        x_pred = model({\n",
        "            'node_feat': node_config,\n",
        "            'edge_index': torch.tensor(dataset.iloc[graph_ind]['edge_index'], dtype=torch.long).t().contiguous(),\n",
        "            'node_opcode': torch.tensor(dataset.iloc[graph_ind]['node_opcode'], dtype=torch.long),\n",
        "            'node_config_ids': torch.tensor(dataset.iloc[graph_ind]['node_config_ids'], dtype=torch.float32)\n",
        "        })\n",
        "\n",
        "        graph_pred.append(x_pred)\n",
        "\n",
        "      predictions.append(graph_pred)\n",
        "\n",
        "      del c, graph_pred, node_config_ids, node_config_feat, node_feat, node\n",
        "\n",
        "    # Calculate score\n",
        "    score = 0.0\n",
        "\n",
        "    for i, tile in tqdm(enumerate(dataset), total=len(dataset)):\n",
        "        best_prediction = min([dataset[i][\"y\"][pred_ind] for pred_ind in predictions[i][:5]])\n",
        "        best_total = min(dataset[i][\"y\"])\n",
        "        score += 2.0 - best_prediction / best_total\n",
        "\n",
        "    avg_score = score / len(dataset)\n",
        "    print(\"Score:\", avg_score)\n",
        "    return avg_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgysBTtYTQGg"
      },
      "source": [
        "## Create Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BAR9nAyUPO3"
      },
      "source": [
        "### Tile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiWbSiK0SL48",
        "outputId": "73860ddf-5740-4093-80f3-63f77b91fa19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5709/5709 [01:29<00:00, 63.66it/s] \n",
            "100%|██████████| 673/673 [00:07<00:00, 87.58it/s] \n"
          ]
        }
      ],
      "source": [
        "df_train = load_data_to_df(tile_xla, \"train\")\n",
        "df_valid = load_data_to_df(tile_xla, \"valid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B81Dmus2SG3L",
        "outputId": "ef0279a8-c964-4fa6-e0d8-2c8bfe35ee51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "train_dataset = RuntimeDataset(df_train, mode=\"tile\")\n",
        "valid_dataset = RuntimeDataset(df_valid, mode=\"tile\")\n",
        "data_loader = runtime_data_loader(train_dataset, batch_size=64)\n",
        "len(data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Tile_GNN(len_opcode_embedd=12, hidden_dim_conv=64, output_dim_conv=32, num_layers_conv=5, dropout_conv=None,\n",
        "                 hidden_dim_lin=48, num_layers_lin=2, dropout_lin=None)"
      ],
      "metadata": {
        "id": "1ZAC8lbCQT8O"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkTpq81MSUW1",
        "outputId": "0edc38ae-a980-47f8-8c23-3740414e1c97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:41<00:00, 13.81s/it]\n"
          ]
        }
      ],
      "source": [
        "MSE_training_tile(model, data_loader, 3, lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MSE_training_tile(model, data_loader, 10, lr=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMQWBye6hLAA",
        "outputId": "dcd4f1e1-e397-445e-99ce-eebf06d71b40"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [02:16<00:00, 13.69s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDOSGX4rRJOM",
        "outputId": "8f7562ee-29d3-40be-e1e5-6dd6aed2815b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5709/5709 [00:29<00:00, 196.03it/s]\n",
            "100%|██████████| 5709/5709 [01:07<00:00, 84.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.5421)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5421)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "validate_model_tiles(model, train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWSGB5hxHLIZ",
        "outputId": "55b7ae90-1fc6-4aa3-f80c-b23ace475c02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 673/673 [00:04<00:00, 156.37it/s]\n",
            "100%|██████████| 673/673 [00:07<00:00, 90.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.8032)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8032)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "validate_model_tiles(model, valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtowqTWI-nh7",
        "outputId": "13dbf96a-4693-4c10-ad65-9f88eeadada8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28577"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "sum(p.numel() for p in model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "\n",
        "cest = timezone('Europe/Berlin')\n",
        "now = datetime.now(timezone('UTC'))\n",
        "now_cest = now.astimezone(cest)\n",
        "now_str = now_cest.strftime('%Y-%m-%d_%H:%M:%S')\n",
        "\n",
        "torch.save(testmodel, '/content/drive/MyDrive/google-tpu/predict-ai-model-runtime/submissions/models/' + now_str)"
      ],
      "metadata": {
        "id": "B42FdvEhljdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tile_model = torch.load('/content/drive/MyDrive/google-tpu/predict-ai-model-runtime/submissions/models/2023-09-22_23:01:26')"
      ],
      "metadata": {
        "id": "HHziaK6ntkrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICQ6-FGiNLjc"
      },
      "source": [
        "## Testing Things"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6XaP5S3vUCj"
      },
      "source": [
        "### Tiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBUBIKLULiTl",
        "outputId": "ea039088-5b2f-4fec-9752-5b388643f912"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.2677960405126214 GB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "5709\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "gb = sys.getsizeof(df_train)/1024**3\n",
        "print(f\"{gb} GB\")\n",
        "print(type(df_train))\n",
        "print(len(df_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2md7BZfLpT-",
        "outputId": "3ed15a03-d90f-49db-d098-58c4c5e4d474"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.12631069403141737 GB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "676\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "gb = sys.getsizeof(df_valid)/1024**3\n",
        "print(f\"{gb} GB\")\n",
        "print(type(df_valid))\n",
        "print(len(df_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfghyr-vL4eg"
      },
      "outputs": [],
      "source": [
        "del df_valid\n",
        "del df_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsYvf6novkAu"
      },
      "source": [
        "### Layout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NyaxI5xyIVu",
        "outputId": "2d14b327-26c0-4ded-a177-4b7c490a329c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tile\n",
            "xla\n",
            "17M\ttest\n",
            "159M\ttrain\n",
            "17M\tvalid\n",
            "layout\n",
            "nlp\n",
            "default\n",
            "4.4M\ttest\n",
            "2.2G\ttrain\n",
            "249M\tvalid\n",
            "random\n",
            "4.6M\ttest\n",
            "2.3G\ttrain\n",
            "251M\tvalid\n",
            "xla\n",
            "default\n",
            "9.7M\ttest\n",
            "375M\ttrain\n",
            "45M\tvalid\n",
            "random\n",
            "11M\ttest\n",
            "358M\ttrain\n",
            "44M\tvalid\n"
          ]
        }
      ],
      "source": [
        "print(\"tile\")\n",
        "print(\"xla\")\n",
        "! cd data/npz_all/npz/tile/xla && du -sh test && du -sh train && du -sh valid\n",
        "print(\"layout\")\n",
        "print(\"nlp\")\n",
        "print(\"default\")\n",
        "! cd data/npz_all/npz/layout/nlp/default && du -sh test && du -sh train && du -sh valid\n",
        "print(\"random\")\n",
        "! cd data/npz_all/npz/layout/nlp/random && du -sh test && du -sh train && du -sh valid\n",
        "print(\"xla\")\n",
        "print(\"default\")\n",
        "! cd data/npz_all/npz/layout/xla/default && du -sh test && du -sh train && du -sh valid\n",
        "print(\"random\")\n",
        "! cd data/npz_all/npz/layout/xla/random && du -sh test && du -sh train && du -sh valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmG8wetGwhg1",
        "outputId": "b7738c61-9653-4ada-f8d6-687c3ebf4fc8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:09<00:00,  1.35s/it]\n"
          ]
        }
      ],
      "source": [
        "df_xla_default_valid = load_data_to_df(layout_xla_default, \"valid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJjZnjwR28iM",
        "outputId": "667d3624-41e7-4113-929a-b975a4dea2a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.9731383491307497 GB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "7\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "gb = sys.getsizeof(df_xla_default_train)/1024**3\n",
        "print(f\"{gb} GB\")\n",
        "print(type(df_xla_default_train))\n",
        "print(len(df_xla_default_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3F1KRz-5zhT",
        "outputId": "548312e2-6439-4cc7-efa8-5cdba050ac28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class '__main__.Layout_GNN'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:40<00:00, 13.60s/it]\n"
          ]
        }
      ],
      "source": [
        "model = Layout_GNN(8,8,8,2)\n",
        "MSE_training_layout(model, df_xla_default_valid, epochs=3, sample_size=50, batch_size=32, lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TsqMr26V3xf",
        "outputId": "895fd728-b72b-42af-cab4-24fbd3dd93f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "validate_model_layout(model, df_xla_default_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKgf3hAwLXmn"
      },
      "outputs": [],
      "source": [
        "del df_xla_default_valid"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "y6ugv1vYeQoP",
        "mwgtm3jkeam4",
        "5S4h21wDSCfV",
        "2pck0LfZRq4R",
        "F6XaP5S3vUCj"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOYe9Ml7deikSHg+7EW9iga"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}