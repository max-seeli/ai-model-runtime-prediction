{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HhTogUWnaWTr",
        "axi4mAqeR68e",
        "5S4h21wDSCfV",
        "2pck0LfZRq4R",
        "F6XaP5S3vUCj"
      ],
      "machine_shape": "hm",
      "toc_visible": true,
      "authorship_tag": "ABX9TyO7LF4DjLLmcmoTxGBnwmFW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/max-seeli/ai-model-runtime-prediction/blob/main/google_tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Ref:\n",
        "\n",
        "*   [TPU Graphs](https://arxiv.org/pdf/2308.13490.pdf)\n",
        "*   [GraphSAGE](https://arxiv.org/pdf/1706.02216.pdf)\n",
        "*   [Ranked List Loss for Deep Metric Learning](https://arxiv.org/pdf/1903.03238.pdf)\n"
      ],
      "metadata": {
        "id": "MpDNTtZ1akyt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO:\n",
        "\n",
        "*   split dataset to make upload faster\n",
        "*   test validation\n"
      ],
      "metadata": {
        "id": "F_YEokYoShJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes:\n",
        "\n",
        "*   Training simple model with MSE loss:\n",
        "    *   need hyperparamter search\n",
        "    *   why does the loss spice at the beginning of each epoch (batches are randomized)\n",
        "    *   oberservations: seems that the smaller models just learn some average absolute value, but not really a ranking\n",
        "    * probably model would have to be huge to rank correctly\n",
        "\n",
        "*   Training simple model with ranking loss:\n",
        "    *   Ranked List Loss\n",
        "    *   Extract the smallest k times\n",
        "\n",
        "*   Abandoning simple model:\n",
        "    *   Replicate TPU paper:\n",
        "        *   SageGraphs\n",
        "        *   ResGCN"
      ],
      "metadata": {
        "id": "X7rIMJhPqz5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies\n"
      ],
      "metadata": {
        "id": "1wDu2al2QKi7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TALB-TcjPpOB",
        "outputId": "29f3295c-a55a-4571-d776-cc9a4b190f23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-geometric\n",
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from torch_geometric import nn as gnn\n",
        "\n",
        "from torch.nn import Linear, ReLU, Dropout\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from einops import reduce, repeat, rearrange\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "jJmWt_9HQSE_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpuIRATBtfT0",
        "outputId": "7ccc6527-9590-4fde-b23b-daba7ebba66b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "HwOap_4GQUm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaWsGUUAQa5U",
        "outputId": "c0be1fbd-33b9-465e-e1bc-9377f6371bbd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.unpack_archive(\"/content/drive/MyDrive/google-tpu/predict-ai-model-runtime.zip\", \"/content/data\")"
      ],
      "metadata": {
        "id": "oATdpYnXm-b_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splits = [\"train\", \"valid\", \"test\"]\n",
        "\n",
        "nlp_default = '/content/data/npz_all/npz/layout/nlp/default'\n",
        "nlp_random = '/content/data/npz_all/npz/layout/nlp/random'\n",
        "xla_default = '/content/data/npz_all/npz/layout/xla/default'\n",
        "xla_random = '/content/data/npz_all/npz/layout/xla/random'\n",
        "xla_tile = '/content/data/npz_all/npz/tile/xla'"
      ],
      "metadata": {
        "id": "YHMebHg8QTsg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_to_df(directory, split):\n",
        "\n",
        "    path = os.path.join(directory, split)\n",
        "    files = [os.path.join(path, file) for file in os.listdir(path)]\n",
        "    data_list = []\n",
        "    for file in tqdm(files):\n",
        "        data = dict(np.load(file))\n",
        "        data_list.append(data)\n",
        "\n",
        "    return pd.DataFrame(data_list)"
      ],
      "metadata": {
        "id": "bmsTgG-hRhcn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### geometric dataloader"
      ],
      "metadata": {
        "id": "HhTogUWnaWTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Dataset, Data\n",
        "from typing import Literal\n",
        "\n",
        "class RuntimeDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, mode: Literal[\"tile\", \"layout\"]):\n",
        "            super().__init__()\n",
        "            if mode == \"tile\":\n",
        "              self.dataset = data\n",
        "              self.mode = mode\n",
        "\n",
        "            elif mode == \"layout\":\n",
        "\n",
        "              '''\n",
        "              Approach:\n",
        "              For every graph add c number of graphs to the dataset where every one of these graphs has node features that are the concat node features.\n",
        "              (nodes that don't have additional features are padded with zeros)\n",
        "              This has implications for training: we are now predicting a scalar value for each graph configuration (can not really train with ranking loss anymore)\n",
        "              '''\n",
        "\n",
        "              self.dataset = pd.DataFrame(columns=['graph_id', 'node_feat', 'node_opcode', 'edge_index', 'config_runtime'])\n",
        "\n",
        "              for index, row in data.iterrows():\n",
        "\n",
        "                c = row['config_runtime'].shape[0]\n",
        "\n",
        "                node_feat = torch.tensor(row['node_feat'], dtype=torch.float32) # (n, 140)\n",
        "                node_config_feat = torch.tensor(row['node_config_feat'], dtype=torch.float32) # (c, nc, 18)\n",
        "\n",
        "                node_feat = repeat(node_feat, 'n f -> r n f', r = c) # repeats every node c times (c, n, 140)\n",
        "                node = torch.zeros((c, node_feat.shape[1], 18)) # (c, n, 18)\n",
        "\n",
        "                node = torch.cat((node_feat, node), dim=2)\n",
        "\n",
        "                for j in range(node_config_feat.shape[1]):\n",
        "                  node[:,j,18:] = node_config_feat[:,j,:]\n",
        "\n",
        "                for i in range(c):\n",
        "\n",
        "                  graph = {'graph_id': index,\n",
        "                           'node_feat': node[i],\n",
        "                           'node_opcode': row['node_opcode'],\n",
        "                           'edge_index': row['edge_index'],\n",
        "                           'config_runime': row['config_runtime'][i]\n",
        "                           }\n",
        "                  self.dataset.append(graph, ignore_index=True)\n",
        "\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def get(self, index):\n",
        "        data_row = self.dataset.loc[index]\n",
        "        if self.mode == \"tile\":\n",
        "          normalized_runtime = torch.tensor(data_row['config_runtime'] / data_row['config_runtime_normalizers'], dtype=torch.float32)\n",
        "          return Data(\n",
        "            node_feat=torch.tensor(data_row['node_feat'], dtype=torch.float32),\n",
        "            edge_index=torch.tensor(data_row['edge_index'], dtype=torch.long).t().contiguous(),\n",
        "            node_opcode=torch.tensor(data_row['node_opcode'], dtype=torch.int32),\n",
        "            config_feat=torch.tensor(data_row['config_feat'], dtype=torch.float32),\n",
        "            y=normalized_runtime, # TODO: rename\n",
        "            number_configs=torch.tensor([len(data_row['config_runtime'])]) # needed to match config_feat to the corresponding graph in the batch\n",
        "          )\n",
        "\n",
        "        else:\n",
        "          data_row = self.datset.loc[index]\n",
        "          return Data(\n",
        "            graph_id = torch.tensor(data_row['graph_id'], dtype=torch.long),\n",
        "            node_feat=data_row['node_feat'],\n",
        "            edge_index=torch.tensor(data_row['edge_index'], dtype=torch.long).t().contiguous(),\n",
        "            node_opcode=torch.tensor(data_row['node_opcode'], dtype=torch.int32),\n",
        "            config_runtime=torch.tensor(data_row['config_runtime'], dtype=torch.long)\n",
        "          )\n"
      ],
      "metadata": {
        "id": "9yGq6NdzaaK3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "def runtime_data_loader(dataset: RuntimeDataset, batch_size=32, shuffle=True):\n",
        "    '''\n",
        "       dataset: RuntimeDataset, containing data\n",
        "    '''\n",
        "\n",
        "    data_loader = DataLoader(dataset, batch_size, shuffle=True)\n",
        "    return data_loader"
      ],
      "metadata": {
        "id": "tBzr8xQuaiTJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "axi4mAqeR68e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Batch\n",
        "class Tile_GNN(nn.Module):\n",
        "    def __init__(self, len_opcode_embedd, hidden_dim, output_dim, num_layers):\n",
        "        super(Tile_GNN, self).__init__()\n",
        "\n",
        "        self.len_opcode = len_opcode_embedd\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Embeddings\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings = 120, embedding_dim=len_opcode_embedd)\n",
        "\n",
        "        #GNN\n",
        "        input_dim = len_opcode_embedd + 140\n",
        "        layers = nn.ModuleList()\n",
        "        layers.append(GCNConv(input_dim, hidden_dim))\n",
        "        for _ in range(num_layers - 2): # TODO list comp, ReLU\n",
        "            layers.append(GCNConv(hidden_dim, hidden_dim))\n",
        "        layers.append(GCNConv(hidden_dim, output_dim))\n",
        "\n",
        "        self.conv = layers\n",
        "\n",
        "        # Linear\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(output_dim + 24, 48),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, 48),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "\n",
        "        opcode_embedd = self.embedding_layer(data['node_opcode']) # (n,) -> (n,len_opcode_embedd)\n",
        "\n",
        "        x = torch.cat((opcode_embedd, data['node_feat']), dim=1) # [(n, len_opcode_embedd), (n,140)] -> (n, len_opcode_embedd + 140)\n",
        "\n",
        "        for layer in self.conv:\n",
        "          x = layer(x, data['edge_index'])\n",
        "          x = torch.relu(x)\n",
        "\n",
        "        # differ two cases:\n",
        "        # 1) batched data used for training\n",
        "        # 2) single graph Data object used for inference\n",
        "\n",
        "        if isinstance(data, Batch):\n",
        "\n",
        "          '''\n",
        "          The geometric data loader will take batch_size number of graphs. Then it will take all nodes in all these graphs and fuse them together into one graph.\n",
        "          On this fuesed graph it will perform the convolution to calculate all the node embeddings at once.\n",
        "          To apply the linear layer we have to seperate out all the graphs out of the batch again.\n",
        "          '''\n",
        "\n",
        "          # tensor used to store config predictions for each graph\n",
        "          configs = torch.empty(0,1).to(device)\n",
        "\n",
        "          # used to retrieve the config_feat tensors for each graph\n",
        "          total = 0\n",
        "\n",
        "          for graph_ind in range(data.num_graphs):\n",
        "\n",
        "            # using a mask to gather all nodes that belong to the graph_ind-th graph\n",
        "            node_indices = (data.batch == graph_ind).nonzero(as_tuple=True)[0]\n",
        "            # first dimension is the number of nodes in the graph with index graph_ind, second dimensions is the feature dimension of the convolution (n, output_dim)\n",
        "            graph_nodes = x[node_indices]\n",
        "\n",
        "            # reduce node embeedings to get a graph embedding\n",
        "            temp = reduce(graph_nodes, 'n f -> f', 'mean')\n",
        "\n",
        "            # number of configurations for the graph_ind-th graph\n",
        "            c = data.number_configs[graph_ind]\n",
        "\n",
        "            # config_feat for the graph_ind-th graph\n",
        "            graph_config_feat = data.config_feat[total:total+c]\n",
        "\n",
        "            total += c\n",
        "\n",
        "            # concatinating graph embedding with config_feat\n",
        "            temp = repeat(temp, 'f -> r f', r=c)\n",
        "            temp = torch.cat((temp, graph_config_feat), dim=1)\n",
        "\n",
        "\n",
        "            # apply linear layer to tensor with shape (c, output_dim+24)\n",
        "            temp = self.linear(temp)\n",
        "\n",
        "            # add calculated runtimes to configs\n",
        "            configs = torch.cat((configs, temp), dim=0)\n",
        "\n",
        "          configs = rearrange(configs, 'f 1 -> f')\n",
        "\n",
        "          return configs\n",
        "\n",
        "        # only working with one graph object\n",
        "\n",
        "        else:\n",
        "\n",
        "          x = reduce(x, 'n f -> f', 'mean') # (n, output_dim) -> (output_dim, )\n",
        "\n",
        "          x = repeat(x, 'f -> r f', r=len(data['config_feat'])) # (output_dim,) -> (c, output_dim)\n",
        "\n",
        "          x = torch.cat((x, data['config_feat']), dim=1) # [(x, output_dim), (c,24)] -> (c, output_dim + 24)\n",
        "\n",
        "          x = self.linear(x)\n",
        "\n",
        "          x = rearrange(x, 'f 1 -> f')\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "IhTaT48l29YH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Batch\n",
        "class Layout_GNN(nn.Module):\n",
        "    def __init__(self, len_opcode_embedd, hidden_dim, output_dim, num_layers):\n",
        "        super(Tile_GNN, self).__init__()\n",
        "\n",
        "        self.len_opcode = len_opcode_embedd\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Embeddings\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings = 120, embedding_dim=len_opcode_embedd)\n",
        "\n",
        "        #GNN\n",
        "        input_dim = len_opcode_embedd + 140\n",
        "        layers = nn.ModuleList()\n",
        "        layers.append(GCNConv(input_dim, hidden_dim))\n",
        "        for _ in range(num_layers - 2): # TODO list comp, ReLU\n",
        "            layers.append(GCNConv(hidden_dim, hidden_dim))\n",
        "        layers.append(GCNConv(hidden_dim, output_dim))\n",
        "\n",
        "        self.conv = layers\n",
        "\n",
        "        # Linear\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(output_dim + 24, 48),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, 48),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "\n",
        "        opcode_embedd = self.embedding_layer(data['node_opcode']) # (n,) -> (n,len_opcode_embedd)\n",
        "\n",
        "        x = torch.cat((opcode_embedd, data['node_feat']), dim=1) # [(n, len_opcode_embedd), (n,140)] -> (n, len_opcode_embedd + 140)\n",
        "\n",
        "        for layer in self.conv:\n",
        "          x = layer(x, data['edge_index'])\n",
        "          x = torch.relu(x)\n",
        "\n",
        "        # differ two cases:\n",
        "        # 1) batched data used for training\n",
        "        # 2) single graph Data object used for inference\n",
        "\n",
        "        if isinstance(data, Batch):\n",
        "\n",
        "          '''\n",
        "          The geometric data loader will take batch_size number of graphs. Then it will take all nodes in all these graphs and fuse them together into one graph.\n",
        "          On this fuesed graph it will perform the convolution to calculate all the node embeddings at once.\n",
        "          To apply the linear layer we have to seperate out all the graphs out of the batch again.\n",
        "          '''\n",
        "\n",
        "          # tensor used to store config predictions for each graph\n",
        "          configs = torch.empty(0,1).to(device)\n",
        "\n",
        "          # used to retrieve the config_feat tensors for each graph\n",
        "          total = 0\n",
        "\n",
        "          for graph_ind in range(data.num_graphs):\n",
        "\n",
        "            # using a mask to gather all nodes that belong to the graph_ind-th graph\n",
        "            node_indices = (data.batch == graph_ind).nonzero(as_tuple=True)[0]\n",
        "            # first dimension is the number of nodes in the graph with index graph_ind, second dimensions is the feature dimension of the convolution (n, output_dim)\n",
        "            graph_nodes = x[node_indices]\n",
        "\n",
        "            # reduce node embeedings to get a graph embedding\n",
        "            temp = reduce(graph_nodes, 'n f -> f', 'mean')\n",
        "\n",
        "            # number of configurations for the graph_ind-th graph\n",
        "            c = data.number_configs[graph_ind]\n",
        "\n",
        "            # config_feat for the graph_ind-th graph\n",
        "            graph_config_feat = data.config_feat[total:total+c]\n",
        "\n",
        "            total += c\n",
        "\n",
        "            # concatinating graph embedding with config_feat\n",
        "            temp = repeat(temp, 'f -> r f', r=c)\n",
        "            temp = torch.cat((temp, graph_config_feat), dim=1)\n",
        "\n",
        "\n",
        "            # apply linear layer to tensor with shape (c, output_dim+24)\n",
        "            temp = self.linear(temp)\n",
        "\n",
        "            # add calculated runtimes to configs\n",
        "            configs = torch.cat((configs, temp), dim=0)\n",
        "\n",
        "          configs = rearrange(configs, 'f 1 -> f')\n",
        "\n",
        "          return configs\n",
        "\n",
        "        # only working with one graph object\n",
        "\n",
        "        else:\n",
        "\n",
        "          x = reduce(x, 'n f -> f', 'mean') # (n, output_dim) -> (output_dim, )\n",
        "\n",
        "          x = repeat(x, 'f -> r f', r=len(data['config_feat'])) # (output_dim,) -> (c, output_dim)\n",
        "\n",
        "          x = torch.cat((x, data['config_feat']), dim=1) # [(x, output_dim), (c,24)] -> (c, output_dim + 24)\n",
        "\n",
        "          x = self.linear(x)\n",
        "\n",
        "          x = rearrange(x, 'f 1 -> f')\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "mQuXlMCPHUIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Loop"
      ],
      "metadata": {
        "id": "5S4h21wDSCfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MSE_training(model: Tile_GNN, dataloader: DataLoader, epochs: int, lr=0.01):\n",
        "    '''\n",
        "    Training model using MSE\n",
        "    '''\n",
        "\n",
        "    print(type(model))\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "    #optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "    loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        for batch, data in enumerate(dataloader):\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            x_pred = model(data)\n",
        "            #print(f\"shapes: {x_pred.shape}, {data['y'].shape}\")\n",
        "            loss = loss_fn(x_pred, data['y'])/len(data['y'])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            #if batch % 200 == 0:\n",
        "            #    print('Epoch [{}/{}], Batch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, batch+1, len(dataloader), loss.item()))"
      ],
      "metadata": {
        "id": "Omv7foIQSPQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def no_batch_training(model, dataset, epochs, lr=0.01):\n",
        "  '''\n",
        "  Training model using MSE\n",
        "  '''\n",
        "\n",
        "  print(type(model))\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  #optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "  #optimizer = torch.optim.Adagrad(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "  loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "  model.to(device)\n",
        "  model.train()\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "      for num, graph in enumerate(dataset):\n",
        "          graph = graph.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          x_pred = model(graph)\n",
        "          #print(f\"shapes: {x_pred.shape}, {data['y'].shape}\")\n",
        "          loss = loss_fn(x_pred, graph['y'])/len(graph['y'])\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          #if num % 500 == 0:\n",
        "          #    print('Epoch [{}/{}], Batch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, num+1, len(dataset), loss.item()))"
      ],
      "metadata": {
        "id": "I3qJ4u2Y63m4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation"
      ],
      "metadata": {
        "id": "2pck0LfZRq4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "\n",
        "def validate_model(model, dataset):\n",
        "\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = []\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    for tile in tqdm(dataset):\n",
        "        tile.to(device)\n",
        "        out = model(tile)\n",
        "        predictions.append(torch.sort(out).indices)\n",
        "\n",
        "    # Calculate score\n",
        "    score = 0.0\n",
        "\n",
        "    for i, tile in tqdm(enumerate(dataset), total=len(dataset)):\n",
        "        best_prediction = min([dataset[i][\"y\"][pred_ind] for pred_ind in predictions[i][:5]])\n",
        "        best_total = min(dataset[i][\"y\"])\n",
        "        score += 2.0 - best_prediction / best_total\n",
        "\n",
        "    avg_score = score / len(dataset)\n",
        "    print(\"Score:\", avg_score)\n",
        "    return avg_score"
      ],
      "metadata": {
        "id": "N2RyiEhgJN3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "ICQ6-FGiNLjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tiles"
      ],
      "metadata": {
        "id": "F6XaP5S3vUCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = load_data_to_df(xla_tile, \"train\")\n",
        "df_valid = load_data_to_df(xla_tile, \"valid\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "MiWbSiK0SL48",
        "outputId": "9179bbbb-e1d9-4020-a2ad-4dbc5d6ec28b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████▏   | 3497/5709 [00:15<00:10, 220.73it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-8b89a2391b95>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxla_tile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxla_tile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-614347516cdd>\u001b[0m in \u001b[0;36mload_data_to_df\u001b[0;34m(directory, split)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mdata_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmagic\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAGIC_PREFIX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 return format.read_array(bytes,\n\u001b[0m\u001b[1;32m    254\u001b[0m                                          \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                                          \u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[0;31m# Now read the actual data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "train_dataset = RuntimeDataset(df_train, mode=\"tile\")\n",
        "valid_dataset = RuntimeDataset(df_valid, mode=\"tile\")\n",
        "data_loader = runtime_data_loader(train_dataset, batch_size=64)\n",
        "len(data_loader)"
      ],
      "metadata": {
        "id": "B81Dmus2SG3L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "54f093a1-aa12-43dd-a694-aa9b0f200de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-9c7f06366967>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRuntimeDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tile\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvalid_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRuntimeDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tile\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mruntime_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model = Tile_GNN(len_opcode_embedd=12, hidden_dim=128, output_dim=64, num_layers=8)\n",
        "MSE_training(model, data_loader, 20, lr=0.01)"
      ],
      "metadata": {
        "id": "FkTpq81MSUW1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "2df0d7d2-1445-43a6-bf16-6b5ace1dcb95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 1/20 [00:26<08:14, 26.03s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-519df2898ea4>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTile_GNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_opcode_embedd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mMSE_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-53-133186332a4d>\u001b[0m in \u001b[0;36mMSE_training\u001b[0;34m(model, dataloader, epochs, lr)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 or (isinstance(idx, np.ndarray) and np.isscalar(idx))):\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-5234070b6470>\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0medge_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'edge_index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mnode_opcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'node_opcode'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mconfig_feat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config_feat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalized_runtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# TODO: rename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mnumber_configs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config_feat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# needed to match config_feat to the corresponding graph in the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validate_model(model, train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDOSGX4rRJOM",
        "outputId": "4d920c9f-9616-4bc2-e927-fba252427f03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5709/5709 [00:42<00:00, 134.09it/s]\n",
            "100%|██████████| 5709/5709 [00:59<00:00, 95.22it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.0900)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0900)"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validate_model(model, valid_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWSGB5hxHLIZ",
        "outputId": "d35dad28-5125-481b-e5ab-25576070f091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 676/676 [00:05<00:00, 130.62it/s]\n",
            "100%|██████████| 676/676 [00:06<00:00, 106.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.9728)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9728)"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.numel() for p in model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtowqTWI-nh7",
        "outputId": "33a7cf48-5045-4967-e15e-f8ba3dba94cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15089"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Layout"
      ],
      "metadata": {
        "id": "dsYvf6novkAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tile\")\n",
        "print(\"xla\")\n",
        "! cd data/npz_all/npz/tile/xla && du -sh test && du -sh train && du -sh valid\n",
        "print(\"layout\")\n",
        "print(\"nlp\")\n",
        "print(\"default\")\n",
        "! cd data/npz_all/npz/layout/nlp/default && du -sh test && du -sh train && du -sh valid\n",
        "print(\"random\")\n",
        "! cd data/npz_all/npz/layout/nlp/random && du -sh test && du -sh train && du -sh valid\n",
        "print(\"xla\")\n",
        "print(\"default\")\n",
        "! cd data/npz_all/npz/layout/xla/default && du -sh test && du -sh train && du -sh valid\n",
        "print(\"random\")\n",
        "! cd data/npz_all/npz/layout/xla/random && du -sh test && du -sh train && du -sh valid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NyaxI5xyIVu",
        "outputId": "2d14b327-26c0-4ded-a177-4b7c490a329c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tile\n",
            "xla\n",
            "17M\ttest\n",
            "159M\ttrain\n",
            "17M\tvalid\n",
            "layout\n",
            "nlp\n",
            "default\n",
            "4.4M\ttest\n",
            "2.2G\ttrain\n",
            "249M\tvalid\n",
            "random\n",
            "4.6M\ttest\n",
            "2.3G\ttrain\n",
            "251M\tvalid\n",
            "xla\n",
            "default\n",
            "9.7M\ttest\n",
            "375M\ttrain\n",
            "45M\tvalid\n",
            "random\n",
            "11M\ttest\n",
            "358M\ttrain\n",
            "44M\tvalid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_xla_default_train = load_data_to_df(xla_default, \"valid\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmG8wetGwhg1",
        "outputId": "c888daec-e7c1-4277-d765-26ecc6ab6d6e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:09<00:00,  1.39s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(df_xla_default_train))\n",
        "print(len(df_xla_default_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJjZnjwR28iM",
        "outputId": "81754fe2-aa44-4f00-c5d0-76c988de1245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_xla_default_train.loc[9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4bH02Wh6PZQ",
        "outputId": "f055786f-2909-4fab-84b3-15b68b159adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "node_feat           [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,...\n",
            "node_opcode         [63, 63, 20, 20, 20, 63, 63, 20, 83, 63, 63, 2...\n",
            "edge_index          [[2, 0], [2, 1], [3, 0], [3, 1], [4, 2], [4, 3...\n",
            "node_config_feat    [[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -...\n",
            "node_config_ids     [2338, 2341, 2343, 2347, 2357, 2360, 2363, 236...\n",
            "config_runtime      [36918487, 36927251, 36918845, 36923070, 36908...\n",
            "node_splits                                              [[0, 22385]]\n",
            "Name: 9, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(df_xla_default_train.head(1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P03bR6JoPlcI",
        "outputId": "39bc9508-f5a4-4d3a-c825-48156f0b286f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "train_dataset = RuntimeDataset(df_xla_default_train.head(1), mode=\"layout\")\n",
        "data_loader = runtime_data_loader(train_dataset, batch_size=9) # work only for batch size=1, (node_config_feat)\n",
        "len(data_loader)"
      ],
      "metadata": {
        "id": "z2Y1NXaZ2fU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = next(iter(data_loader))\n",
        "print(type(test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL-uzCnB4iuK",
        "outputId": "a4ff78a6-eaf7-4e53-e8af-382b7cd34170"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch_geometric.data.batch.DataBatch'>\n"
          ]
        }
      ]
    }
  ]
}