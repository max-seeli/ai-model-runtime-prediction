{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "axi4mAqeR68e",
        "5S4h21wDSCfV",
        "2pck0LfZRq4R",
        "F6XaP5S3vUCj"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO6G6oysp5Fi0pXULkOOqCJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Ref:\n",
        "\n",
        "*   [TPU Graphs](https://arxiv.org/pdf/2308.13490.pdf)\n",
        "*   [GraphSAGE](https://arxiv.org/pdf/1706.02216.pdf)\n",
        "*   [Ranked List Loss for Deep Metric Learning](https://arxiv.org/pdf/1903.03238.pdf)\n"
      ],
      "metadata": {
        "id": "MpDNTtZ1akyt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO:\n",
        "\n",
        "*   split dataset to make upload faster\n",
        "*   test validation\n",
        "*   in layout the config data should be a torch.int32, but overflows if not torch.long"
      ],
      "metadata": {
        "id": "F_YEokYoShJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes:\n",
        "\n",
        "*   Training simple model with MSE loss:\n",
        "    *   need hyperparamter search\n",
        "    *   why does the loss spice at the beginning of each epoch (batches are randomized)\n",
        "    *   oberservations: seems that the smaller models just learn some average absolute value, but not really a ranking\n",
        "    * probably model would have to be huge to rank correctly\n",
        "\n",
        "*   Training simple model with ranking loss:\n",
        "    *   Ranked List Loss\n",
        "    *   Extract the smallest k times\n",
        "\n",
        "*   Abandoning simple model:\n",
        "    *   Replicate TPU paper:\n",
        "        *   SageGraphs\n",
        "        *   ResGCN"
      ],
      "metadata": {
        "id": "X7rIMJhPqz5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies\n"
      ],
      "metadata": {
        "id": "1wDu2al2QKi7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TALB-TcjPpOB",
        "outputId": "a8406ebc-f07c-4e55-85ba-8fe743a2d429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=d1f2dd65efa5aa6639407f30e5cf58dd8766532bae7c4efe425bf61b0f2b6215\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.3.1\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m999.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-geometric\n",
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from torch_geometric import nn as gnn\n",
        "\n",
        "from torch.nn import Linear, ReLU, Dropout\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from einops import reduce, repeat, rearrange\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "jJmWt_9HQSE_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpuIRATBtfT0",
        "outputId": "3b0b99f4-291f-4e1e-b4c3-54d9ce1657a3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "HwOap_4GQUm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaWsGUUAQa5U",
        "outputId": "841917eb-dae9-4bf4-eb26-fc8b0e554528"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### zipped data"
      ],
      "metadata": {
        "id": "y6ugv1vYeQoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.unpack_archive(\"/content/drive/MyDrive/google-tpu/predict-ai-model-runtime.zip\", \"/content/data\")"
      ],
      "metadata": {
        "id": "oATdpYnXm-b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splits = [\"train\", \"valid\", \"test\"]\n",
        "\n",
        "layout_nlp_default = '/content/data/npz_all/npz/layout/nlp/default'\n",
        "layout_nlp_random = '/content/data/npz_all/npz/layout/nlp/random'\n",
        "layout_xla_default = '/content/data/npz_all/npz/layout/xla/default'\n",
        "layout_xla_random = '/content/data/npz_all/npz/layout/xla/random'\n",
        "\n",
        "tile_xla= '/content/data/npz_all/npz/tile/xla'"
      ],
      "metadata": {
        "id": "YHMebHg8QTsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### unzipped data in drive\n"
      ],
      "metadata": {
        "id": "mwgtm3jkeam4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unzipped archive in drive\n",
        "\n",
        "layout_nlp_default = '/content/drive/MyDrive/google-tpu/predict-ai-model-runtime/npz_all/npz/layout/nlp/default'\n",
        "layout_nlp_random = '/content/drive/MyDrive/google-tpu/predict-ai-model-runtime/npz_all/npz/layout/nlp/random'\n",
        "layout_xla_default = '/content/drive/MyDrive/google-tpu/predict-ai-model-runtime/npz_all/npz/layout/xla/default'\n",
        "layout_xla_random = '/content/drive/MyDrive/google-tpu/predict-ai-model-runtime/npz_all/npz/layout/xla/random'"
      ],
      "metadata": {
        "id": "3EW2Co2dlJB-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_to_df(directory, split):\n",
        "\n",
        "    path = os.path.join(directory, split)\n",
        "    files = [os.path.join(path, file) for file in os.listdir(path)]\n",
        "    data_list = []\n",
        "    for file in tqdm(files):\n",
        "        data = dict(np.load(file))\n",
        "        data_list.append(data)\n",
        "\n",
        "    return pd.DataFrame(data_list)"
      ],
      "metadata": {
        "id": "bmsTgG-hRhcn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### geometric dataloader"
      ],
      "metadata": {
        "id": "HhTogUWnaWTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Dataset, Data\n",
        "from typing import Literal\n",
        "\n",
        "class RuntimeDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, mode: Literal[\"tile\", \"layout\", \"layout_all\"]):\n",
        "            super().__init__()\n",
        "\n",
        "            self.mode = mode\n",
        "\n",
        "            if self.mode == \"layout_all\":\n",
        "\n",
        "              '''\n",
        "              Approach:\n",
        "              For every graph add c number of graphs to the dataset where every one of these graphs has node features that are the concat node features.\n",
        "              (nodes that don't have additional features are padded with zeros)\n",
        "              This has implications for training: we are now predicting a scalar value for each graph configuration (can not really train with ranking loss anymore)\n",
        "              '''\n",
        "\n",
        "              self.dataset = pd.DataFrame(columns=['graph_id', 'node_feat', 'node_opcode', 'edge_index', 'config_runtime'])\n",
        "\n",
        "              for index, row in data.iterrows():\n",
        "\n",
        "                # tensors to large, not memory efficient enough\n",
        "\n",
        "                c = row['config_runtime'].shape[0]\n",
        "\n",
        "                node_feat = torch.tensor(row['node_feat'], dtype=torch.float32) # (n, 140)\n",
        "                node_config_feat = torch.tensor(row['node_config_feat'], dtype=torch.float32) # (c, nc, 18)\n",
        "\n",
        "                node_feat = repeat(node_feat, 'n f -> r n f', r = c) # repeats every node c times (c, n, 140)\n",
        "                node = torch.zeros((c, node_feat.shape[1], 18)) # (c, n, 18)\n",
        "\n",
        "                node = torch.cat((node_feat, node), dim=2)\n",
        "\n",
        "                for j in range(node_config_feat.shape[1]):\n",
        "                  node[:,j,18:] = node_config_feat[:,j,:]\n",
        "\n",
        "                for i in range(c):\n",
        "\n",
        "                  graph = {'graph_id': index,\n",
        "                           'node_feat': node[i],\n",
        "                           'node_opcode': row['node_opcode'],\n",
        "                           'edge_index': row['edge_index'],\n",
        "                           'config_runtime': row['config_runtime'][i]\n",
        "                           }\n",
        "                  self.dataset.append(graph, ignore_index=True)\n",
        "\n",
        "            else:\n",
        "              self.dataset = data\n",
        "              self.mode = mode\n",
        "\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def get(self, index):\n",
        "        data_row = self.dataset.loc[index]\n",
        "        if self.mode == \"tile\":\n",
        "          normalized_runtime = torch.tensor(data_row['config_runtime'] / data_row['config_runtime_normalizers'], dtype=torch.float32)\n",
        "          return Data(\n",
        "            node_feat=torch.tensor(data_row['node_feat'], dtype=torch.float32),\n",
        "            edge_index=torch.tensor(data_row['edge_index'], dtype=torch.long).t().contiguous(),\n",
        "            node_opcode=torch.tensor(data_row['node_opcode'], dtype=torch.int32),\n",
        "            config_feat=torch.tensor(data_row['config_feat'], dtype=torch.float32),\n",
        "            y=normalized_runtime, # TODO: rename\n",
        "            number_configs=torch.tensor([len(data_row['config_runtime'])]) # needed to match config_feat to the corresponding graph in the batch\n",
        "          )\n",
        "\n",
        "\n",
        "        else:\n",
        "\n",
        "          data_row = self.dataset.loc[index]\n",
        "\n",
        "          return Data(\n",
        "            graph_id = torch.tensor(data_row['graph_id'], dtype=torch.long),\n",
        "            node_feat=data_row['node_feat'],\n",
        "            edge_index=torch.tensor(data_row['edge_index'], dtype=torch.long).t().contiguous(),\n",
        "            node_opcode=torch.tensor(data_row['node_opcode'], dtype=torch.int32),\n",
        "            config_runtime=torch.tensor(data_row['config_runtime'], dtype=torch.float32),\n",
        "            node_config_ids = torch.tensor(data_row['node_config_ids'], dtype=torch.long)\n",
        "          )"
      ],
      "metadata": {
        "id": "9yGq6NdzaaK3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "def runtime_data_loader(dataset: RuntimeDataset, batch_size=32, shuffle=True):\n",
        "    '''\n",
        "       dataset: RuntimeDataset, containing data\n",
        "    '''\n",
        "\n",
        "    data_loader = DataLoader(dataset, batch_size, shuffle=True)\n",
        "    return data_loader"
      ],
      "metadata": {
        "id": "tBzr8xQuaiTJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def layout_loader(data, indicies, sample_size, batch_size=32):\n",
        "\n",
        "  df = pd.DataFrame(columns=['graph_id', 'node_feat', 'node_opcode', 'edge_index', 'config_runtime'])\n",
        "\n",
        "  for index, row in data.iterrows():\n",
        "\n",
        "    c = row['config_runtime'].shape[0]\n",
        "\n",
        "\n",
        "\n",
        "    node_feat = torch.tensor(row['node_feat'], dtype=torch.float32) # (n, 140)\n",
        "    node_config_feat = torch.tensor(row['node_config_feat'], dtype=torch.float32) # (c, nc, 18)\n",
        "\n",
        "    node = torch.zeros(node_feat.shape[0], 18)\n",
        "    node = torch.cat((node_feat, node), dim=1)\n",
        "\n",
        "\n",
        "    for _ in range(min(sample_size, c)):\n",
        "      rand_config = random.randint(0, c-1)\n",
        "      indicies[index].append(rand_config)\n",
        "\n",
        "      for i in range(node_config_feat.shape[1]):\n",
        "        node[row['node_config_ids'][i],:18] = node_config_feat[rand_config, i, :]\n",
        "\n",
        "      # debugging\n",
        "      # print(f\"graph: {index}, config: {rand_config}, value: {row['config_runtime'][rand_config]}\")\n",
        "\n",
        "      next_row = {'graph_id': index,\n",
        "                  'node_feat': node,\n",
        "                  'node_opcode': row['node_opcode'],\n",
        "                  'edge_index': row['edge_index'],\n",
        "                  'config_runtime': row['config_runtime'][rand_config],\n",
        "                  'node_config_ids': row['node_config_ids']\n",
        "                  }\n",
        "      df = pd.concat([df, pd.DataFrame([next_row])], ignore_index=True)\n",
        "\n",
        "  dataset = RuntimeDataset(df, \"layout\")\n",
        "\n",
        "  return indicies, runtime_data_loader(dataset, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "cqbIhQhKhvS2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Batch\n",
        "class Tile_GNN(nn.Module):\n",
        "\n",
        "    def __init__(self, len_opcode_embedd, hidden_dim, output_dim, num_layers):\n",
        "        super(Tile_GNN, self).__init__()\n",
        "\n",
        "        self.len_opcode = len_opcode_embedd\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Embeddings\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings = 120, embedding_dim=len_opcode_embedd)\n",
        "\n",
        "        #GNN\n",
        "        input_dim = len_opcode_embedd + 140\n",
        "        layers = nn.ModuleList()\n",
        "        layers.append(GCNConv(input_dim, hidden_dim))\n",
        "        for _ in range(num_layers - 2): # TODO list comp, ReLU\n",
        "            layers.append(GCNConv(hidden_dim, hidden_dim))\n",
        "        layers.append(GCNConv(hidden_dim, output_dim))\n",
        "\n",
        "        self.conv = layers\n",
        "\n",
        "        # Linear\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(output_dim + 24, 48),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, 48),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, 1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def __init__(self, len_opcode_embedd, hidden_dim, output_dim, num_layers):\n",
        "        super(Tile_GNN, self).__init__()\n",
        "\n",
        "        self.len_opcode = len_opcode_embedd\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Embeddings\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings = 120, embedding_dim=len_opcode_embedd)\n",
        "\n",
        "        #GNN\n",
        "        input_dim = len_opcode_embedd + 140 + 18\n",
        "        layers = nn.ModuleList()\n",
        "        layers.append(GCNConv(input_dim, hidden_dim))\n",
        "        for _ in range(num_layers - 2): # TODO list comp, ReLU\n",
        "            layers.append(GCNConv(hidden_dim, hidden_dim))\n",
        "        layers.append(GCNConv(hidden_dim, output_dim))\n",
        "\n",
        "        self.conv = layers\n",
        "\n",
        "        # Linear\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(output_dim, 48),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, 48),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "\n",
        "        opcode_embedd = self.embedding_layer(data['node_opcode']) # (n,) -> (n,len_opcode_embedd)\n",
        "\n",
        "        x = torch.cat((opcode_embedd, data['node_feat']), dim=1) # [(n, len_opcode_embedd), (n,140)] -> (n, len_opcode_embedd + 140 + 18)\n",
        "\n",
        "        for layer in self.conv:\n",
        "          x = layer(x, data['edge_index'])\n",
        "          x = torch.relu(x)\n",
        "\n",
        "        # differ two cases:\n",
        "        # 1) batched data used for training\n",
        "        # 2) single graph Data object used for inference\n",
        "\n",
        "        if isinstance(data, Batch):\n",
        "\n",
        "          '''\n",
        "          The geometric data loader will take batch_size number of graphs. Then it will take all nodes in all these graphs and fuse them together into one graph.\n",
        "          On this fuesed graph it will perform the convolution to calculate all the node embeddings at once.\n",
        "          To apply the linear layer we have to seperate out all the graphs out of the batch again.\n",
        "          '''\n",
        "\n",
        "          # tensor used to store config predictions for each graph\n",
        "          configs = torch.empty(0,1).to(device)\n",
        "\n",
        "          # used to retrieve the config_feat tensors for each graph\n",
        "          total = 0\n",
        "\n",
        "          for graph_ind in range(data.num_graphs):\n",
        "\n",
        "            # using a mask to gather all nodes that belong to the graph_ind-th graph\n",
        "            node_indices = (data.batch == graph_ind).nonzero(as_tuple=True)[0]\n",
        "            # first dimension is the number of nodes in the graph with index graph_ind, second dimensions is the feature dimension of the convolution (n, output_dim)\n",
        "            graph_nodes = x[node_indices]\n",
        "\n",
        "            # reduce node embeedings to get a graph embedding\n",
        "            temp = reduce(graph_nodes, 'n f -> f', 'mean')\n",
        "\n",
        "            # number of configurations for the graph_ind-th graph\n",
        "            c = data.number_configs[graph_ind]\n",
        "\n",
        "            # config_feat for the graph_ind-th graph\n",
        "            graph_config_feat = data.config_feat[total:total+c]\n",
        "\n",
        "            total += c\n",
        "\n",
        "            # concatinating graph embedding with config_feat\n",
        "            temp = repeat(temp, 'f -> r f', r=c)\n",
        "            temp = torch.cat((temp, graph_config_feat), dim=1)\n",
        "\n",
        "\n",
        "            # apply linear layer to tensor with shape (c, output_dim+24)\n",
        "            temp = self.linear(temp)\n",
        "\n",
        "            # add calculated runtimes to configs\n",
        "            configs = torch.cat((configs, temp), dim=0)\n",
        "\n",
        "          configs = rearrange(configs, 'f 1 -> f')\n",
        "\n",
        "          return configs\n",
        "\n",
        "        # only working with one graph object\n",
        "\n",
        "        else:\n",
        "\n",
        "          x = reduce(x, 'n f -> f', 'mean') # (n, output_dim) -> (output_dim, )\n",
        "\n",
        "          x = repeat(x, 'f -> r f', r=len(data['config_feat'])) # (output_dim,) -> (c, output_dim)\n",
        "\n",
        "          x = torch.cat((x, data['config_feat']), dim=1) # [(x, output_dim), (c,24)] -> (c, output_dim + 24)\n",
        "\n",
        "          x = self.linear(x)\n",
        "\n",
        "          x = rearrange(x, 'f 1 -> f')\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "mQuXlMCPHUIJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Batch\n",
        "class Layout_GNN(nn.Module):\n",
        "\n",
        "    def __init__(self, len_opcode_embedd, hidden_dim, output_dim, num_layers):\n",
        "        super(Layout_GNN, self).__init__()\n",
        "\n",
        "        self.len_opcode = len_opcode_embedd\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Embeddings\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings = 120, embedding_dim=len_opcode_embedd)\n",
        "\n",
        "        #GNN\n",
        "        input_dim = len_opcode_embedd + 140 + 18\n",
        "        layers = nn.ModuleList()\n",
        "        layers.append(GCNConv(input_dim, hidden_dim))\n",
        "        for _ in range(num_layers - 2): # TODO list comp, ReLU\n",
        "            layers.append(GCNConv(hidden_dim, hidden_dim))\n",
        "        layers.append(GCNConv(hidden_dim, output_dim))\n",
        "\n",
        "        self.conv = layers\n",
        "\n",
        "        # Linear\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(output_dim, 48),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, 48),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "\n",
        "        opcode_embedd = self.embedding_layer(data['node_opcode']) # (n,) -> (n,len_opcode_embedd)\n",
        "\n",
        "        x = torch.cat((opcode_embedd, data['node_feat']), dim=1) # [(n, len_opcode_embedd), (n,140 + 18)] -> (n, len_opcode_embedd + 140 + 18)\n",
        "\n",
        "        for layer in self.conv:\n",
        "          x = layer(x, data['edge_index'])\n",
        "          x = torch.relu(x)\n",
        "\n",
        "        # differ two cases:\n",
        "        # 1) batched data used for training\n",
        "        # 2) single graph Data object used for inference\n",
        "\n",
        "        if isinstance(data, Batch):\n",
        "\n",
        "          '''\n",
        "          The geometric data loader will take batch_size number of graphs. Then it will take all nodes in all these graphs and fuse them together into one graph.\n",
        "          On this fuesed graph it will perform the convolution to calculate all the node embeddings at once.\n",
        "          To apply the linear layer we have to seperate out all the graphs out of the batch again.\n",
        "          '''\n",
        "\n",
        "          # tensor used to store config predictions for each graph\n",
        "          configs = torch.empty(0).to(device)\n",
        "\n",
        "          for graph_ind in range(data.num_graphs):\n",
        "\n",
        "            # using a mask to gather all nodes that belong to the graph_ind-th graph\n",
        "            node_indices = (data.batch == graph_ind).nonzero(as_tuple=True)[0]\n",
        "            # first dimension is the number of nodes in the graph with index graph_ind, second dimensions is the feature dimension of the convolution (n, output_dim)\n",
        "            graph_nodes = x[node_indices]\n",
        "\n",
        "            # reduce node embeedings to get a graph embedding\n",
        "            temp = reduce(graph_nodes, 'n f -> f', 'mean')\n",
        "            # apply linear layer to tensor with shape (c, output_dim+24)\n",
        "            temp = self.linear(temp)\n",
        "\n",
        "\n",
        "            # add calculated runtimes to configs\n",
        "            configs = torch.cat((configs, temp), dim=0)\n",
        "\n",
        "          return configs\n",
        "\n",
        "        # only working with one graph object\n",
        "\n",
        "        else:\n",
        "\n",
        "          x = reduce(x, 'n f -> f', 'mean') # (n, output_dim) -> (output_dim, )\n",
        "\n",
        "          x = self.linear(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "IhTaT48l29YH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Loop"
      ],
      "metadata": {
        "id": "5S4h21wDSCfV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tiles"
      ],
      "metadata": {
        "id": "jbN1tFabfQ-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MSE_training_tile(model: Tile_GNN, dataloader: DataLoader, epochs: int, lr=0.01):\n",
        "    '''\n",
        "    Training model using MSE\n",
        "    '''\n",
        "\n",
        "    print(type(model))\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "    #optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "    loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        for batch, data in enumerate(dataloader):\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            x_pred = model(data)\n",
        "            #print(f\"shapes: {x_pred.shape}, {data['y'].shape}\")\n",
        "            loss = loss_fn(x_pred, data['y'])/len(data['y'])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            #if batch % 200 == 0:\n",
        "            #    print('Epoch [{}/{}], Batch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, batch+1, len(dataloader), loss.item()))"
      ],
      "metadata": {
        "id": "Omv7foIQSPQf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def no_batch_training_tile(model, dataset, epochs, lr=0.01):\n",
        "  '''\n",
        "  Training model using MSE\n",
        "  '''\n",
        "\n",
        "  print(type(model))\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  #optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "  #optimizer = torch.optim.Adagrad(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "  loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "  model.to(device)\n",
        "  model.train()\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "      for num, graph in enumerate(dataset):\n",
        "          graph = graph.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          x_pred = model(graph)\n",
        "          #print(f\"shapes: {x_pred.shape}, {data['y'].shape}\")\n",
        "          loss = loss_fn(x_pred, graph['y'])/len(graph['y'])\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          #if num % 500 == 0:\n",
        "          #    print('Epoch [{}/{}], Batch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, num+1, len(dataset), loss.item()))"
      ],
      "metadata": {
        "id": "I3qJ4u2Y63m4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Y8N0lt5-ItiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Layout"
      ],
      "metadata": {
        "id": "jIxuW_Y-fTN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Problem: Too many graphs in the layout dataset make it hard to train model.\n",
        "More precisely the problem is not the number of graphs but more the number of configs for each graph.\n",
        "One possible way to mittigate this problem is to train only on a selection of graph configurations.\n",
        "Want to experiment with different selection procedures find select graphs and their configuratoins that bring the most value.\n",
        "'''\n",
        "\n",
        "def MSE_training_layout(model: Layout_GNN, dataset, epochs: int, sample_size=50, batch_size=32, lr=0.01):\n",
        "    '''\n",
        "    Training model using MSE\n",
        "    '''\n",
        "\n",
        "    print(type(model))\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "    #optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "    loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    indicies = [[] for _ in range(len(dataset))]\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "\n",
        "        indicies, dataloader = layout_loader(dataset, indicies, sample_size=sample_size, batch_size=batch_size)\n",
        "\n",
        "        for batch, data in enumerate(dataloader):\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            x_pred = model(data)\n",
        "            loss = loss_fn(x_pred, data['config_runtime'])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            #if batch % 200 == 0:\n",
        "            #    print('Epoch [{}/{}], Batch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, batch+1, len(dataloader), loss.item()))"
      ],
      "metadata": {
        "id": "EbjQ_agQfWHW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation"
      ],
      "metadata": {
        "id": "2pck0LfZRq4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "\n",
        "def validate_model_tiles(model, dataset):\n",
        "\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = []\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    for tile in tqdm(dataset):\n",
        "        tile.to(device)\n",
        "        out = model(tile)\n",
        "        predictions.append(torch.sort(out).indices)\n",
        "\n",
        "    # Calculate score\n",
        "    score = 0.0\n",
        "\n",
        "    for i, tile in tqdm(enumerate(dataset), total=len(dataset)):\n",
        "        best_prediction = min([dataset[i][\"y\"][pred_ind] for pred_ind in predictions[i][:5]])\n",
        "        best_total = min(dataset[i][\"y\"])\n",
        "        score += 2.0 - best_prediction / best_total\n",
        "\n",
        "    avg_score = score / len(dataset)\n",
        "    print(\"Score:\", avg_score)\n",
        "    return avg_score"
      ],
      "metadata": {
        "id": "N2RyiEhgJN3B"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "\n",
        "def validate_model_layout(model, dataset):\n",
        "\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = []\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    for graph_ind in range(len(dataset)):\n",
        "      # c = graph['config_runtime'].shape[0]\n",
        "      c = dataset.iloc[graph_ind]['config_runtime'].shape[0]\n",
        "      graph_pred = []\n",
        "      node_config_ids = dataset.iloc[graph_ind]['node_config_ids']\n",
        "      node_config_feat = torch.tensor(dataset.iloc[graph_ind]['node_config_feat'], dtype=torch.float32)\n",
        "      node_feat = torch.tensor(dataset.iloc[graph_ind]['node_feat'], dtype=torch.float32)\n",
        "      node = torch.zeros((node_feat.shape[0], 18))\n",
        "      node = torch.cat((node_feat, node), dim=1)\n",
        "\n",
        "      for config in tqdm(range(c)):\n",
        "        node_config = node.clone()\n",
        "\n",
        "        for i in range(node_config_feat.shape[1]):\n",
        "          node_config[node_config_ids[i], :18] = node_config_feat[config,i,:]\n",
        "        x_pred = model({\n",
        "            'node_feat': node_config,\n",
        "            'edge_index': torch.tensor(dataset.iloc[graph_ind]['edge_index'], dtype=torch.long).t().contiguous(),\n",
        "            'node_opcode': torch.tensor(dataset.iloc[graph_ind]['node_opcode'], dtype=torch.long),\n",
        "            'node_config_ids': torch.tensor(dataset.iloc[graph_ind]['node_config_ids'], dtype=torch.float32)\n",
        "        })\n",
        "\n",
        "        graph_pred.append(x_pred)\n",
        "\n",
        "      predictions.append(graph_pred)\n",
        "\n",
        "      del c, graph_pred, node_config_ids, node_config_feat, node_feat, node\n",
        "\n",
        "    # Calculate score\n",
        "    score = 0.0\n",
        "\n",
        "    for i, tile in tqdm(enumerate(dataset), total=len(dataset)):\n",
        "        best_prediction = min([dataset[i][\"y\"][pred_ind] for pred_ind in predictions[i][:5]])\n",
        "        best_total = min(dataset[i][\"y\"])\n",
        "        score += 2.0 - best_prediction / best_total\n",
        "\n",
        "    avg_score = score / len(dataset)\n",
        "    print(\"Score:\", avg_score)\n",
        "    return avg_score"
      ],
      "metadata": {
        "id": "48mVzPfpTrKk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_model_layout(model, dataset):\n",
        "\n",
        "    # Move model to CPU to save GPU memory\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    print(type(dataset))\n",
        "\n",
        "    # Initialize score\n",
        "    score = 0.0\n",
        "\n",
        "    for graph_ind in tqdm(range(len(dataset))):\n",
        "\n",
        "        graph_data = dataset.iloc[graph_ind]\n",
        "        c = graph_data['config_runtime'].shape[0]\n",
        "\n",
        "        node_config_ids = graph_data['node_config_ids']\n",
        "        node_config_feat = torch.tensor(graph_data['node_config_feat'], dtype=torch.float32)\n",
        "        node_feat = torch.tensor(graph_data['node_feat'], dtype=torch.float32)\n",
        "        node = torch.zeros((node_feat.shape[0], 18))\n",
        "        node = torch.cat((node_feat, node), dim=1)\n",
        "\n",
        "        edge_index = torch.tensor(graph_data['edge_index'], dtype=torch.long).t().contiguous()\n",
        "        node_opcode = torch.tensor(graph_data['node_opcode'], dtype=torch.long)\n",
        "        node_config_ids_tensor = torch.tensor(graph_data['node_config_ids'], dtype=torch.float32)\n",
        "\n",
        "        graph_pred = []\n",
        "\n",
        "        for config in range(c):\n",
        "            node_config = node.clone()\n",
        "\n",
        "            for i in range(node_config_feat.shape[1]):\n",
        "                node_config[node_config_ids[i], :18] = node_config_feat[config, i, :]\n",
        "\n",
        "            x_pred = model({\n",
        "                'node_feat': node_config,\n",
        "                'edge_index': edge_index,\n",
        "                'node_opcode': node_opcode,\n",
        "                'node_config_ids': node_config_ids_tensor\n",
        "            })\n",
        "\n",
        "            graph_pred.append(x_pred)\n",
        "\n",
        "        best_prediction = min([graph_data[\"y\"][pred_ind] for pred_ind in graph_pred[:5]])\n",
        "        best_total = min(graph_data[\"y\"])\n",
        "        score += 2.0 - best_prediction / best_total\n",
        "\n",
        "        # Explicitly delete variables to free up memory\n",
        "        del node_config, graph_pred\n",
        "\n",
        "    # Calculate average score\n",
        "    avg_score = score / len(dataset)\n",
        "    print(\"Score:\", avg_score)\n",
        "    return avg_score\n"
      ],
      "metadata": {
        "id": "xCSbSD7U_7oz"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "ICQ6-FGiNLjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tiles"
      ],
      "metadata": {
        "id": "F6XaP5S3vUCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = load_data_to_df(tile_xla, \"train\")\n",
        "df_valid = load_data_to_df(tile_xla, \"valid\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiWbSiK0SL48",
        "outputId": "8059b068-fce9-45bf-dde5-92f64ec57f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5709/5709 [00:22<00:00, 254.07it/s]\n",
            "100%|██████████| 676/676 [00:02<00:00, 267.01it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "gb = sys.getsizeof(df_train)/1024**3\n",
        "print(f\"{gb} GB\")\n",
        "print(type(df_train))\n",
        "print(len(df_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBUBIKLULiTl",
        "outputId": "ea039088-5b2f-4fec-9752-5b388643f912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2677960405126214 GB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "5709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "gb = sys.getsizeof(df_valid)/1024**3\n",
        "print(f\"{gb} GB\")\n",
        "print(type(df_valid))\n",
        "print(len(df_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2md7BZfLpT-",
        "outputId": "3ed15a03-d90f-49db-d098-58c4c5e4d474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12631069403141737 GB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "train_dataset = RuntimeDataset(df_train, mode=\"tile\")\n",
        "valid_dataset = RuntimeDataset(df_valid, mode=\"tile\")\n",
        "data_loader = runtime_data_loader(train_dataset, batch_size=64)\n",
        "len(data_loader)"
      ],
      "metadata": {
        "id": "B81Dmus2SG3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7be9dc8-dfc4-4100-e8f3-0bd12e7b5586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del df_valid\n",
        "del df_train"
      ],
      "metadata": {
        "id": "cfghyr-vL4eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model = Tile_GNN(len_opcode_embedd=12, hidden_dim=128, output_dim=64, num_layers=8)\n",
        "MSE_training(model, data_loader, 20, lr=0.01)"
      ],
      "metadata": {
        "id": "FkTpq81MSUW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate_model(model, train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDOSGX4rRJOM",
        "outputId": "4d920c9f-9616-4bc2-e927-fba252427f03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5709/5709 [00:42<00:00, 134.09it/s]\n",
            "100%|██████████| 5709/5709 [00:59<00:00, 95.22it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.0900)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0900)"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validate_model(model, valid_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWSGB5hxHLIZ",
        "outputId": "d35dad28-5125-481b-e5ab-25576070f091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 676/676 [00:05<00:00, 130.62it/s]\n",
            "100%|██████████| 676/676 [00:06<00:00, 106.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.9728)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9728)"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.numel() for p in model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtowqTWI-nh7",
        "outputId": "33a7cf48-5045-4967-e15e-f8ba3dba94cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15089"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Layout"
      ],
      "metadata": {
        "id": "dsYvf6novkAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tile\")\n",
        "print(\"xla\")\n",
        "! cd data/npz_all/npz/tile/xla && du -sh test && du -sh train && du -sh valid\n",
        "print(\"layout\")\n",
        "print(\"nlp\")\n",
        "print(\"default\")\n",
        "! cd data/npz_all/npz/layout/nlp/default && du -sh test && du -sh train && du -sh valid\n",
        "print(\"random\")\n",
        "! cd data/npz_all/npz/layout/nlp/random && du -sh test && du -sh train && du -sh valid\n",
        "print(\"xla\")\n",
        "print(\"default\")\n",
        "! cd data/npz_all/npz/layout/xla/default && du -sh test && du -sh train && du -sh valid\n",
        "print(\"random\")\n",
        "! cd data/npz_all/npz/layout/xla/random && du -sh test && du -sh train && du -sh valid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NyaxI5xyIVu",
        "outputId": "2d14b327-26c0-4ded-a177-4b7c490a329c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tile\n",
            "xla\n",
            "17M\ttest\n",
            "159M\ttrain\n",
            "17M\tvalid\n",
            "layout\n",
            "nlp\n",
            "default\n",
            "4.4M\ttest\n",
            "2.2G\ttrain\n",
            "249M\tvalid\n",
            "random\n",
            "4.6M\ttest\n",
            "2.3G\ttrain\n",
            "251M\tvalid\n",
            "xla\n",
            "default\n",
            "9.7M\ttest\n",
            "375M\ttrain\n",
            "45M\tvalid\n",
            "random\n",
            "11M\ttest\n",
            "358M\ttrain\n",
            "44M\tvalid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_xla_default_valid = load_data_to_df(layout_xla_default, \"valid\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmG8wetGwhg1",
        "outputId": "b7738c61-9653-4ada-f8d6-687c3ebf4fc8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:09<00:00,  1.35s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "gb = sys.getsizeof(df_xla_default_train)/1024**3\n",
        "print(f\"{gb} GB\")\n",
        "print(type(df_xla_default_train))\n",
        "print(len(df_xla_default_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJjZnjwR28iM",
        "outputId": "667d3624-41e7-4113-929a-b975a4dea2a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.9731383491307497 GB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Layout_GNN(8,8,8,2)\n",
        "MSE_training_layout(model, df_xla_default_valid, epochs=3, sample_size=50, batch_size=32, lr=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3F1KRz-5zhT",
        "outputId": "548312e2-6439-4cc7-efa8-5cdba050ac28"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.Layout_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:40<00:00, 13.60s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validate_model_layout(model, df_xla_default_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TsqMr26V3xf",
        "outputId": "895fd728-b72b-42af-cab4-24fbd3dd93f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del df_xla_default_valid"
      ],
      "metadata": {
        "id": "wKgf3hAwLXmn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}