{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3m1PmV1JGzBk",
        "RnWUKNBJG3it",
        "1Lt8rnXkIj0w",
        "LlWb0FzGLQlr",
        "eKdaAJKTNIpK"
      ],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyP+XmPDzcLJjSS/QbeOwZOU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/max-seeli/ai-model-runtime-prediction/blob/main/parameter_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dep"
      ],
      "metadata": {
        "id": "3m1PmV1JGzBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric\n",
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkWEhrmvB_rB",
        "outputId": "407a1513-3490-48cb-c07e-46fca1f71361"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/661.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/661.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=0365d232c27cc98333f37b4821be5dcc913c0ae5e7aeb691bcdfc2c0d8e9a9c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.3.1\n",
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "import csv\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from torch_geometric import nn as gnn\n",
        "\n",
        "from torch.nn import Linear, ReLU, Dropout\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from einops import reduce, repeat, rearrange\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-tj11-HCGOU",
        "outputId": "81e3bb9c-589f-41c5-e9b0-d925933e95ba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQ4qm8hUCJ0N",
        "outputId": "c8d81fdc-93b7-4292-b845-19059c48a3c5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "RnWUKNBJG3it"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unzipped archive in drive\n",
        "splits = [\"train\", \"valid\", \"test\"]\n",
        "\n",
        "layout_nlp_default = '/content/drive/MyDrive/google-tpu/predict-ai-model-runtime/npz_all/npz/layout/nlp/default'\n",
        "layout_nlp_random = '/content/drive/MyDrive/google-tpu/predict-ai-model-runtime/npz_all/npz/layout/nlp/random'\n",
        "layout_xla_default = '/content/drive/MyDrive/google-tpu/predict-ai-model-runtime/npz_all/npz/layout/xla/default'\n",
        "layout_xla_random = '/content/drive/MyDrive/google-tpu/predict-ai-model-runtime/npz_all/npz/layout/xla/random'\n",
        "\n",
        "tile_xla= '/content/drive/MyDrive/google-tpu/predict-ai-model-runtime/npz_all/npz/tile/xla'"
      ],
      "metadata": {
        "id": "wMXBQyh5G568"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_to_df(directory, split):\n",
        "\n",
        "    path = os.path.join(directory, split)\n",
        "    files = [os.path.join(path, file) for file in os.listdir(path)]\n",
        "    data_list = []\n",
        "    for file in tqdm(files):\n",
        "        data = dict(np.load(file))\n",
        "        data_list.append(data)\n",
        "\n",
        "    return pd.DataFrame(data_list)"
      ],
      "metadata": {
        "id": "P4ZSRZZOG9uq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Dataset, Data\n",
        "from typing import Literal\n",
        "\n",
        "class RuntimeDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, mode: Literal[\"tile\", \"layout\", \"layout_all\"]):\n",
        "            super().__init__()\n",
        "\n",
        "            self.mode = mode\n",
        "\n",
        "            if self.mode == \"layout_all\":\n",
        "\n",
        "              '''\n",
        "              Approach:\n",
        "              For every graph add c number of graphs to the dataset where every one of these graphs has node features that are the concat node features.\n",
        "              (nodes that don't have additional features are padded with zeros)\n",
        "              This has implications for training: we are now predicting a scalar value for each graph configuration (can not really train with ranking loss anymore)\n",
        "              '''\n",
        "\n",
        "              self.dataset = pd.DataFrame(columns=['graph_id', 'node_feat', 'node_opcode', 'edge_index', 'config_runtime'])\n",
        "\n",
        "              for index, row in data.iterrows():\n",
        "\n",
        "                # tensors to large, not memory efficient enough\n",
        "\n",
        "                c = row['config_runtime'].shape[0]\n",
        "\n",
        "                node_feat = torch.tensor(row['node_feat'], dtype=torch.float32) # (n, 140)\n",
        "                node_config_feat = torch.tensor(row['node_config_feat'], dtype=torch.float32) # (c, nc, 18)\n",
        "\n",
        "                node_feat = repeat(node_feat, 'n f -> r n f', r = c) # repeats every node c times (c, n, 140)\n",
        "                node = torch.zeros((c, node_feat.shape[1], 18)) # (c, n, 18)\n",
        "\n",
        "                node = torch.cat((node_feat, node), dim=2)\n",
        "\n",
        "                for j in range(node_config_feat.shape[1]):\n",
        "                  node[:,j,18:] = node_config_feat[:,j,:]\n",
        "\n",
        "                for i in range(c):\n",
        "\n",
        "                  graph = {'graph_id': index,\n",
        "                           'node_feat': node[i],\n",
        "                           'node_opcode': row['node_opcode'],\n",
        "                           'edge_index': row['edge_index'],\n",
        "                           'config_runtime': row['config_runtime'][i]\n",
        "                           }\n",
        "                  self.dataset.append(graph, ignore_index=True)\n",
        "\n",
        "            else:\n",
        "              self.dataset = data\n",
        "              self.mode = mode\n",
        "\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def get(self, index):\n",
        "        data_row = self.dataset.loc[index]\n",
        "        if self.mode == \"tile\":\n",
        "          normalized_runtime = torch.tensor(data_row['config_runtime'] / data_row['config_runtime_normalizers'], dtype=torch.float32)\n",
        "          return Data(\n",
        "            node_feat=torch.tensor(data_row['node_feat'], dtype=torch.float32),\n",
        "            edge_index=torch.tensor(data_row['edge_index'], dtype=torch.long).t().contiguous(),\n",
        "            node_opcode=torch.tensor(data_row['node_opcode'], dtype=torch.int32),\n",
        "            config_feat=torch.tensor(data_row['config_feat'], dtype=torch.float32),\n",
        "            y=normalized_runtime, # TODO: rename\n",
        "            number_configs=torch.tensor([len(data_row['config_runtime'])]) # needed to match config_feat to the corresponding graph in the batch\n",
        "          )\n",
        "\n",
        "\n",
        "        else:\n",
        "\n",
        "          data_row = self.dataset.loc[index]\n",
        "\n",
        "          return Data(\n",
        "            graph_id = torch.tensor(data_row['graph_id'], dtype=torch.long),\n",
        "            node_feat=data_row['node_feat'],\n",
        "            edge_index=torch.tensor(data_row['edge_index'], dtype=torch.long).t().contiguous(),\n",
        "            node_opcode=torch.tensor(data_row['node_opcode'], dtype=torch.int32),\n",
        "            config_runtime=torch.tensor(data_row['config_runtime'], dtype=torch.float32),\n",
        "            node_config_ids = torch.tensor(data_row['node_config_ids'], dtype=torch.long)\n",
        "          )"
      ],
      "metadata": {
        "id": "qrlhEzuKHIn3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "def runtime_data_loader(dataset: RuntimeDataset, batch_size=32, shuffle=True):\n",
        "    '''\n",
        "       dataset: RuntimeDataset, containing data\n",
        "    '''\n",
        "\n",
        "    data_loader = DataLoader(dataset, batch_size, shuffle=True)\n",
        "    return data_loader"
      ],
      "metadata": {
        "id": "URPQU39mHB8E"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "1Lt8rnXkIj0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Batch\n",
        "\"\"\"\n",
        "TODO: add regularisation\n",
        "      make the linear layer variable\n",
        "      batch normalization\n",
        "\"\"\"\n",
        "class Tile_GNN(nn.Module):\n",
        "\n",
        "    def __init__(self, len_opcode_embedd, hidden_dim_conv, output_dim_conv, num_layers_conv, dropout_conv,\n",
        "                                          hidden_dim_lin, num_layers_lin, dropout_lin):\n",
        "        super(Tile_GNN, self).__init__()\n",
        "\n",
        "        self.len_opcode_embedd = len_opcode_embedd\n",
        "        self.hidden_dim_conv = hidden_dim_conv\n",
        "        self.output_dim_conv = output_dim_conv\n",
        "        self.num_layers_conv = num_layers_conv\n",
        "        self.dropout_conv = 0 if dropout_conv is None else dropout_conv\n",
        "\n",
        "        self.hidden_dim_lin = hidden_dim_lin\n",
        "        self.num_layers_lin = num_layers_lin\n",
        "        self.dropout_lin = dropout_lin\n",
        "        self.dropout_lin = 0 if dropout_lin is None else dropout_lin\n",
        "\n",
        "        # Dropout\n",
        "        self.conv_dropout = nn.Dropout(p=self.dropout_conv)\n",
        "        self.lin_dropout = nn.Dropout(p=self.dropout_lin)\n",
        "        # Embeddings\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings = 120, embedding_dim=self.len_opcode_embedd)\n",
        "\n",
        "        # GNN\n",
        "        input_dim = self.len_opcode_embedd + 140\n",
        "        layers = nn.ModuleList()\n",
        "        layers.append(GCNConv(input_dim, self.hidden_dim_conv))\n",
        "        for _ in range(self.num_layers_conv - 2): # TODO list comp, ReLU\n",
        "            layers.append(GCNConv(self.hidden_dim_conv, self.hidden_dim_conv))\n",
        "        layers.append(GCNConv(self.hidden_dim_conv,self.output_dim_conv))\n",
        "\n",
        "        self.conv = layers\n",
        "\n",
        "        # Linear\n",
        "        lin_layers = [nn.Linear(self.output_dim_conv + 24, self.hidden_dim_lin), nn.ReLU(), self.lin_dropout]\n",
        "        for i in range(self.num_layers_lin - 2):\n",
        "          lin_layers.append(nn.Linear(self.hidden_dim_lin, self.hidden_dim_lin))\n",
        "          lin_layers.append(nn.ReLU())\n",
        "          lin_layers.append(self.lin_dropout)\n",
        "        lin_layers.append(nn.Linear(self.hidden_dim_lin, 1))\n",
        "\n",
        "        self.linear = nn.Sequential(*lin_layers)\n",
        "\n",
        "    def forward(self, data):\n",
        "\n",
        "        opcode_embedd = self.embedding_layer(data['node_opcode']) # (n,) -> (n,len_opcode_embedd)\n",
        "\n",
        "        x = torch.cat((opcode_embedd, data['node_feat']), dim=1) # [(n, len_opcode_embedd), (n,140)] -> (n, len_opcode_embedd + 140 + 18)\n",
        "\n",
        "        for layer in self.conv:\n",
        "          x = layer(x, data['edge_index'])\n",
        "          x = torch.relu(x)\n",
        "          x = self.conv_dropout(x)\n",
        "\n",
        "        # differ two cases:\n",
        "        # 1) batched data used for training\n",
        "        # 2) single graph Data object used for inference\n",
        "\n",
        "        if isinstance(data, Batch):\n",
        "\n",
        "          '''\n",
        "          The geometric data loader will take batch_size number of graphs. Then it will take all nodes in all these graphs and fuse them together into one graph.\n",
        "          On this fuesed graph it will perform the convolution to calculate all the node embeddings at once.\n",
        "          To apply the linear layer we have to seperate out all the graphs out of the batch again.\n",
        "          '''\n",
        "\n",
        "          # tensor used to store config predictions for each graph\n",
        "          configs = torch.empty(0,1).to(device)\n",
        "\n",
        "          # used to retrieve the config_feat tensors for each graph\n",
        "          total = 0\n",
        "\n",
        "          for graph_ind in range(data.num_graphs):\n",
        "\n",
        "            # using a mask to gather all nodes that belong to the graph_ind-th graph\n",
        "            node_indices = (data.batch == graph_ind).nonzero(as_tuple=True)[0]\n",
        "            # first dimension is the number of nodes in the graph with index graph_ind, second dimensions is the feature dimension of the convolution (n, output_dim)\n",
        "            graph_nodes = x[node_indices]\n",
        "\n",
        "            # reduce node embeedings to get a graph embedding\n",
        "            temp = reduce(graph_nodes, 'n f -> f', 'mean')\n",
        "\n",
        "            # number of configurations for the graph_ind-th graph\n",
        "            c = data.number_configs[graph_ind]\n",
        "\n",
        "            # config_feat for the graph_ind-th graph\n",
        "            graph_config_feat = data.config_feat[total:total+c]\n",
        "\n",
        "            total += c\n",
        "\n",
        "            # concatinating graph embedding with config_feat\n",
        "            temp = repeat(temp, 'f -> r f', r=c)\n",
        "            temp = torch.cat((temp, graph_config_feat), dim=1)\n",
        "\n",
        "\n",
        "            # apply linear layer to tensor with shape (c, output_dim+24)\n",
        "            temp = self.linear(temp)\n",
        "\n",
        "            # add calculated runtimes to configs\n",
        "            configs = torch.cat((configs, temp), dim=0)\n",
        "\n",
        "          configs = rearrange(configs, 'f 1 -> f')\n",
        "\n",
        "          return configs\n",
        "\n",
        "        # only working with one graph object\n",
        "\n",
        "        else:\n",
        "\n",
        "          x = reduce(x, 'n f -> f', 'mean') # (n, output_dim) -> (output_dim, )\n",
        "\n",
        "          x = repeat(x, 'f -> r f', r=len(data['config_feat'])) # (output_dim,) -> (c, output_dim)\n",
        "\n",
        "          x = torch.cat((x, data['config_feat']), dim=1) # [(x, output_dim), (c,24)] -> (c, output_dim + 24)\n",
        "\n",
        "          x = self.linear(x)\n",
        "\n",
        "          x = rearrange(x, 'f 1 -> f')\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "1vFA1u4XIiiA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loops"
      ],
      "metadata": {
        "id": "LlWb0FzGLQlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MSE_training_tile(model: Tile_GNN, dataloader: DataLoader, epochs: int, lr=0.01):\n",
        "    '''\n",
        "    Training model using MSE\n",
        "    '''\n",
        "\n",
        "    print(type(model))\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "    #optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "    loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        for batch, data in enumerate(dataloader):\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            x_pred = model(data)\n",
        "            #print(f\"shapes: {x_pred.shape}, {data['y'].shape}\")\n",
        "            loss = loss_fn(x_pred, data['y'])/len(data['y'])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            #if batch % 200 == 0:\n",
        "            #    print('Epoch [{}/{}], Batch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, batch+1, len(dataloader), loss.item()))"
      ],
      "metadata": {
        "id": "YmM4aknTLPws"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implementaion of ListNET Loss (see: https://arxiv.org/pdf/1911.09798v2.pdf)\n",
        "\n",
        "def ListNet_training_tile(model: Tile_GNN, dataloader: DataLoader, epochs: int, lr=0.01):\n",
        "    '''\n",
        "    Training model using MSE\n",
        "    '''\n",
        "\n",
        "    print(type(model))\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "    #optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        for batch, data in enumerate(dataloader):\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            x_pred = model(data)\n",
        "\n",
        "            # predicted distribution, need to negate since lower ist better\n",
        "\n",
        "            pred_distribution = F.softmax(-x_pred, dim=0)\n",
        "\n",
        "            label_distribution = F.softmax(-data['y'], dim=0)\n",
        "\n",
        "            listnet_loss = -torch.sum(label_distribution * torch.log(pred_distribution))\n",
        "\n",
        "            listnet_loss.backward()\n",
        "            optimizer.step()"
      ],
      "metadata": {
        "id": "ejl6ADJiLagE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation"
      ],
      "metadata": {
        "id": "eKdaAJKTNIpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "\n",
        "def validate_model_tiles(model, dataset):\n",
        "\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = []\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    for tile in tqdm(dataset):\n",
        "        tile.to(device)\n",
        "        out = model(tile)\n",
        "        predictions.append(torch.sort(out).indices)\n",
        "\n",
        "    # Calculate score\n",
        "    score = 0.0\n",
        "\n",
        "    for i, tile in tqdm(enumerate(dataset), total=len(dataset)):\n",
        "        best_prediction = min([dataset[i][\"y\"][pred_ind] for pred_ind in predictions[i][:5]])\n",
        "        best_total = min(dataset[i][\"y\"])\n",
        "        score += 2.0 - best_prediction / best_total\n",
        "\n",
        "    avg_score = score / len(dataset)\n",
        "    print(\"Score:\", avg_score)\n",
        "    return avg_score"
      ],
      "metadata": {
        "id": "rEH8DbM5NHwx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameter Search"
      ],
      "metadata": {
        "id": "gwOdbqYmG_Nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = load_data_to_df(tile_xla, \"train\")\n",
        "df_valid = load_data_to_df(tile_xla, \"valid\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2Q2qqPgHUYK",
        "outputId": "1b2ae767-78dc-4dee-ddb4-c2b66dff7c77"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5709/5709 [02:34<00:00, 36.89it/s] \n",
            "100%|██████████| 673/673 [00:10<00:00, 62.50it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = RuntimeDataset(df_train, mode=\"tile\")\n",
        "valid_dataset = RuntimeDataset(df_valid, mode=\"tile\")\n",
        "data_loader = runtime_data_loader(train_dataset, batch_size=16)\n",
        "len(data_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ioVRAKuHi57",
        "outputId": "bca7700e-c390-4a1d-8c90-69d630118e07"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "357"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "VApaePOzqc2m"
      },
      "outputs": [],
      "source": [
        "# lists of parameters to optimize for Tile model:\n",
        "param_list = {\n",
        "  'len_opcode_embedd': [12],\n",
        "  'hidden_dim_conv': [64],\n",
        "  'output_dim_conv': [32],\n",
        "  'num_layers_conv': [5],\n",
        "  'hidden_dim_lin': [20, 48],\n",
        "  'num_layers_lin': [2,4,6],\n",
        "  'optimizer': ['Adam'], # TODO implement\n",
        "  'lr': [0.01],\n",
        "  'dropout_conv': [0,0.3],\n",
        "  'dropout_lin': [0,0.3],\n",
        "  'loss_fn': ['MSE']\n",
        "}\n",
        "\n",
        "para_grid = ParameterGrid(param_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame(columns=['score', *param_list.keys(), 'epochs', 'number of parameters', 'validation'])"
      ],
      "metadata": {
        "id": "aa5isP5NBw6U"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 40\n",
        "VALIDATION = \"split\"\n",
        "\n",
        "for i, params in enumerate(para_grid):\n",
        "  # define model\n",
        "  model = Tile_GNN(len_opcode_embedd=params['len_opcode_embedd'], hidden_dim_conv=params['hidden_dim_conv'], output_dim_conv=params['output_dim_conv'], num_layers_conv=params['num_layers_conv'], dropout_conv=params['dropout_conv'],\n",
        "                   hidden_dim_lin=params['hidden_dim_lin'], num_layers_lin=params['num_layers_lin'], dropout_lin=params['dropout_lin'])\n",
        "\n",
        "  num_para = sum(p.numel() for p in model.parameters())\n",
        "  score = None\n",
        "\n",
        "  # train model\n",
        "  if params['loss_fn'] == 'MSE':\n",
        "    MSE_training_tile(model, data_loader, epochs=EPOCHS, lr=params['lr'])\n",
        "  elif params['loss_fn'] == 'ListNET':\n",
        "    ListNet_training_tile(model, data_loader, epochs=EPOCHS, lr=params['lr'])\n",
        "\n",
        "  if VALIDATION == 'split':\n",
        "    score = validate_model_tiles(model, valid_dataset)\n",
        "\n",
        "  elif VALIDATION == 'cross':\n",
        "    pass\n",
        "\n",
        "  res = {\n",
        "    'len_opcode_embedd': params['len_opcode_embedd'],\n",
        "    'hidden_dim_conv': params['hidden_dim_conv'],\n",
        "    'output_dim_conv': params['output_dim_conv'],\n",
        "    'num_layers_conv': params['num_layers_conv'],\n",
        "    'hidden_dim_lin': params['hidden_dim_lin'],\n",
        "    'num_layers_lin': params['num_layers_lin'],\n",
        "    'optimizer': params['optimizer'],\n",
        "    'lr': params['lr'],\n",
        "    'dropout_conv': params['dropout_conv'],\n",
        "    'dropout_lin': params['dropout_lin'],\n",
        "    'loss_fn': params['loss_fn'],\n",
        "    'score': score,\n",
        "    'epochs': EPOCHS,\n",
        "    'number of parameters': num_para,\n",
        "    'validation': VALIDATION\n",
        "  }\n",
        "  print(res)\n",
        "  results = pd.concat([results, pd.DataFrame([res])], ignore_index=True)\n",
        "  print(f\"[{i+1}]/[{len(para_grid)}] configs tested\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWyq1PBgF_JZ",
        "outputId": "a20a237e-b1cc-4ba6-df1b-5597a201b192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [10:14<00:00, 15.35s/it]\n",
            "100%|██████████| 673/673 [00:03<00:00, 196.56it/s]\n",
            "100%|██████████| 673/673 [00:06<00:00, 97.47it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.7717)\n",
            "{'len_opcode_embedd': 12, 'hidden_dim_conv': 64, 'output_dim_conv': 32, 'num_layers_conv': 5, 'hidden_dim_lin': 20, 'num_layers_lin': 2, 'optimizer': 'Adam', 'lr': 0.01, 'dropout_conv': 0, 'dropout_lin': 0, 'loss_fn': 'MSE', 'score': tensor(0.7717), 'epochs': 40, 'number of parameters': 26953, 'validation': 'split'}\n",
            "[1]/[24] configs tested\n",
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [13:18<00:00, 19.96s/it]\n",
            "100%|██████████| 673/673 [00:03<00:00, 190.82it/s]\n",
            "100%|██████████| 673/673 [00:06<00:00, 100.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(-1.5095)\n",
            "{'len_opcode_embedd': 12, 'hidden_dim_conv': 64, 'output_dim_conv': 32, 'num_layers_conv': 5, 'hidden_dim_lin': 20, 'num_layers_lin': 4, 'optimizer': 'Adam', 'lr': 0.01, 'dropout_conv': 0, 'dropout_lin': 0, 'loss_fn': 'MSE', 'score': tensor(-1.5095), 'epochs': 40, 'number of parameters': 27793, 'validation': 'split'}\n",
            "[2]/[24] configs tested\n",
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [14:40<00:00, 22.01s/it]\n",
            "100%|██████████| 673/673 [00:03<00:00, 180.66it/s]\n",
            "100%|██████████| 673/673 [00:06<00:00, 96.17it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.9728)\n",
            "{'len_opcode_embedd': 12, 'hidden_dim_conv': 64, 'output_dim_conv': 32, 'num_layers_conv': 5, 'hidden_dim_lin': 20, 'num_layers_lin': 6, 'optimizer': 'Adam', 'lr': 0.01, 'dropout_conv': 0, 'dropout_lin': 0, 'loss_fn': 'MSE', 'score': tensor(0.9728), 'epochs': 40, 'number of parameters': 28633, 'validation': 'split'}\n",
            "[3]/[24] configs tested\n",
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [10:34<00:00, 15.85s/it]\n",
            "100%|██████████| 673/673 [00:03<00:00, 196.61it/s]\n",
            "100%|██████████| 673/673 [00:06<00:00, 98.41it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.6001)\n",
            "{'len_opcode_embedd': 12, 'hidden_dim_conv': 64, 'output_dim_conv': 32, 'num_layers_conv': 5, 'hidden_dim_lin': 48, 'num_layers_lin': 2, 'optimizer': 'Adam', 'lr': 0.01, 'dropout_conv': 0, 'dropout_lin': 0, 'loss_fn': 'MSE', 'score': tensor(0.6001), 'epochs': 40, 'number of parameters': 28577, 'validation': 'split'}\n",
            "[4]/[24] configs tested\n",
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [13:32<00:00, 20.31s/it]\n",
            "100%|██████████| 673/673 [00:03<00:00, 189.00it/s]\n",
            "100%|██████████| 673/673 [00:06<00:00, 97.14it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.7146)\n",
            "{'len_opcode_embedd': 12, 'hidden_dim_conv': 64, 'output_dim_conv': 32, 'num_layers_conv': 5, 'hidden_dim_lin': 48, 'num_layers_lin': 4, 'optimizer': 'Adam', 'lr': 0.01, 'dropout_conv': 0, 'dropout_lin': 0, 'loss_fn': 'MSE', 'score': tensor(0.7146), 'epochs': 40, 'number of parameters': 33281, 'validation': 'split'}\n",
            "[5]/[24] configs tested\n",
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [14:56<00:00, 22.42s/it]\n",
            "100%|██████████| 673/673 [00:03<00:00, 181.52it/s]\n",
            "100%|██████████| 673/673 [00:06<00:00, 96.26it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.8212)\n",
            "{'len_opcode_embedd': 12, 'hidden_dim_conv': 64, 'output_dim_conv': 32, 'num_layers_conv': 5, 'hidden_dim_lin': 48, 'num_layers_lin': 6, 'optimizer': 'Adam', 'lr': 0.01, 'dropout_conv': 0, 'dropout_lin': 0, 'loss_fn': 'MSE', 'score': tensor(0.8212), 'epochs': 40, 'number of parameters': 37985, 'validation': 'split'}\n",
            "[6]/[24] configs tested\n",
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [10:36<00:00, 15.92s/it]\n",
            "100%|██████████| 673/673 [00:03<00:00, 194.64it/s]\n",
            "100%|██████████| 673/673 [00:07<00:00, 95.35it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.9728)\n",
            "{'len_opcode_embedd': 12, 'hidden_dim_conv': 64, 'output_dim_conv': 32, 'num_layers_conv': 5, 'hidden_dim_lin': 20, 'num_layers_lin': 2, 'optimizer': 'Adam', 'lr': 0.01, 'dropout_conv': 0, 'dropout_lin': 0.3, 'loss_fn': 'MSE', 'score': tensor(0.9728), 'epochs': 40, 'number of parameters': 26953, 'validation': 'split'}\n",
            "[7]/[24] configs tested\n",
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [13:35<00:00, 20.39s/it]\n",
            "100%|██████████| 673/673 [00:03<00:00, 192.08it/s]\n",
            "100%|██████████| 673/673 [00:07<00:00, 94.01it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.6437)\n",
            "{'len_opcode_embedd': 12, 'hidden_dim_conv': 64, 'output_dim_conv': 32, 'num_layers_conv': 5, 'hidden_dim_lin': 20, 'num_layers_lin': 4, 'optimizer': 'Adam', 'lr': 0.01, 'dropout_conv': 0, 'dropout_lin': 0.3, 'loss_fn': 'MSE', 'score': tensor(0.6437), 'epochs': 40, 'number of parameters': 27793, 'validation': 'split'}\n",
            "[8]/[24] configs tested\n",
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [15:09<00:00, 22.73s/it]\n",
            "100%|██████████| 673/673 [00:03<00:00, 185.57it/s]\n",
            "100%|██████████| 673/673 [00:07<00:00, 95.74it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.9728)\n",
            "{'len_opcode_embedd': 12, 'hidden_dim_conv': 64, 'output_dim_conv': 32, 'num_layers_conv': 5, 'hidden_dim_lin': 20, 'num_layers_lin': 6, 'optimizer': 'Adam', 'lr': 0.01, 'dropout_conv': 0, 'dropout_lin': 0.3, 'loss_fn': 'MSE', 'score': tensor(0.9728), 'epochs': 40, 'number of parameters': 28633, 'validation': 'split'}\n",
            "[9]/[24] configs tested\n",
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [10:27<00:00, 15.70s/it]\n",
            "100%|██████████| 673/673 [00:03<00:00, 197.98it/s]\n",
            "100%|██████████| 673/673 [00:06<00:00, 96.71it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.0772)\n",
            "{'len_opcode_embedd': 12, 'hidden_dim_conv': 64, 'output_dim_conv': 32, 'num_layers_conv': 5, 'hidden_dim_lin': 48, 'num_layers_lin': 2, 'optimizer': 'Adam', 'lr': 0.01, 'dropout_conv': 0, 'dropout_lin': 0.3, 'loss_fn': 'MSE', 'score': tensor(0.0772), 'epochs': 40, 'number of parameters': 28577, 'validation': 'split'}\n",
            "[10]/[24] configs tested\n",
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [13:57<00:00, 20.94s/it]\n",
            "100%|██████████| 673/673 [00:03<00:00, 191.58it/s]\n",
            "100%|██████████| 673/673 [00:07<00:00, 95.99it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.4532)\n",
            "{'len_opcode_embedd': 12, 'hidden_dim_conv': 64, 'output_dim_conv': 32, 'num_layers_conv': 5, 'hidden_dim_lin': 48, 'num_layers_lin': 4, 'optimizer': 'Adam', 'lr': 0.01, 'dropout_conv': 0, 'dropout_lin': 0.3, 'loss_fn': 'MSE', 'score': tensor(0.4532), 'epochs': 40, 'number of parameters': 33281, 'validation': 'split'}\n",
            "[11]/[24] configs tested\n",
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [15:38<00:00, 23.46s/it]\n",
            "100%|██████████| 673/673 [00:03<00:00, 182.00it/s]\n",
            "100%|██████████| 673/673 [00:06<00:00, 97.20it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.7573)\n",
            "{'len_opcode_embedd': 12, 'hidden_dim_conv': 64, 'output_dim_conv': 32, 'num_layers_conv': 5, 'hidden_dim_lin': 48, 'num_layers_lin': 6, 'optimizer': 'Adam', 'lr': 0.01, 'dropout_conv': 0, 'dropout_lin': 0.3, 'loss_fn': 'MSE', 'score': tensor(0.7573), 'epochs': 40, 'number of parameters': 37985, 'validation': 'split'}\n",
            "[12]/[24] configs tested\n",
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [10:17<00:00, 15.44s/it]\n",
            "100%|██████████| 673/673 [00:03<00:00, 195.49it/s]\n",
            "100%|██████████| 673/673 [00:06<00:00, 96.53it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.9728)\n",
            "{'len_opcode_embedd': 12, 'hidden_dim_conv': 64, 'output_dim_conv': 32, 'num_layers_conv': 5, 'hidden_dim_lin': 20, 'num_layers_lin': 2, 'optimizer': 'Adam', 'lr': 0.01, 'dropout_conv': 0.3, 'dropout_lin': 0, 'loss_fn': 'MSE', 'score': tensor(0.9728), 'epochs': 40, 'number of parameters': 26953, 'validation': 'split'}\n",
            "[13]/[24] configs tested\n",
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [12:59<00:00, 19.50s/it]\n",
            "100%|██████████| 673/673 [00:03<00:00, 190.23it/s]\n",
            "100%|██████████| 673/673 [00:06<00:00, 98.10it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.9728)\n",
            "{'len_opcode_embedd': 12, 'hidden_dim_conv': 64, 'output_dim_conv': 32, 'num_layers_conv': 5, 'hidden_dim_lin': 20, 'num_layers_lin': 4, 'optimizer': 'Adam', 'lr': 0.01, 'dropout_conv': 0.3, 'dropout_lin': 0, 'loss_fn': 'MSE', 'score': tensor(0.9728), 'epochs': 40, 'number of parameters': 27793, 'validation': 'split'}\n",
            "[14]/[24] configs tested\n",
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [14:15<00:00, 21.40s/it]\n",
            "100%|██████████| 673/673 [00:03<00:00, 181.78it/s]\n",
            "100%|██████████| 673/673 [00:07<00:00, 91.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.9728)\n",
            "{'len_opcode_embedd': 12, 'hidden_dim_conv': 64, 'output_dim_conv': 32, 'num_layers_conv': 5, 'hidden_dim_lin': 20, 'num_layers_lin': 6, 'optimizer': 'Adam', 'lr': 0.01, 'dropout_conv': 0.3, 'dropout_lin': 0, 'loss_fn': 'MSE', 'score': tensor(0.9728), 'epochs': 40, 'number of parameters': 28633, 'validation': 'split'}\n",
            "[15]/[24] configs tested\n",
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [10:29<00:00, 15.75s/it]\n",
            "100%|██████████| 673/673 [00:03<00:00, 193.75it/s]\n",
            "100%|██████████| 673/673 [00:07<00:00, 95.81it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.6119)\n",
            "{'len_opcode_embedd': 12, 'hidden_dim_conv': 64, 'output_dim_conv': 32, 'num_layers_conv': 5, 'hidden_dim_lin': 48, 'num_layers_lin': 2, 'optimizer': 'Adam', 'lr': 0.01, 'dropout_conv': 0.3, 'dropout_lin': 0, 'loss_fn': 'MSE', 'score': tensor(0.6119), 'epochs': 40, 'number of parameters': 28577, 'validation': 'split'}\n",
            "[16]/[24] configs tested\n",
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [13:25<00:00, 20.14s/it]\n",
            "100%|██████████| 673/673 [00:03<00:00, 186.15it/s]\n",
            "100%|██████████| 673/673 [00:07<00:00, 94.07it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.6567)\n",
            "{'len_opcode_embedd': 12, 'hidden_dim_conv': 64, 'output_dim_conv': 32, 'num_layers_conv': 5, 'hidden_dim_lin': 48, 'num_layers_lin': 4, 'optimizer': 'Adam', 'lr': 0.01, 'dropout_conv': 0.3, 'dropout_lin': 0, 'loss_fn': 'MSE', 'score': tensor(0.6567), 'epochs': 40, 'number of parameters': 33281, 'validation': 'split'}\n",
            "[17]/[24] configs tested\n",
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [15:05<00:00, 22.65s/it]\n",
            "100%|██████████| 673/673 [00:03<00:00, 180.93it/s]\n",
            "100%|██████████| 673/673 [00:07<00:00, 91.87it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.9728)\n",
            "{'len_opcode_embedd': 12, 'hidden_dim_conv': 64, 'output_dim_conv': 32, 'num_layers_conv': 5, 'hidden_dim_lin': 48, 'num_layers_lin': 6, 'optimizer': 'Adam', 'lr': 0.01, 'dropout_conv': 0.3, 'dropout_lin': 0, 'loss_fn': 'MSE', 'score': tensor(0.9728), 'epochs': 40, 'number of parameters': 37985, 'validation': 'split'}\n",
            "[18]/[24] configs tested\n",
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [10:32<00:00, 15.81s/it]\n",
            "100%|██████████| 673/673 [00:03<00:00, 198.44it/s]\n",
            "100%|██████████| 673/673 [00:06<00:00, 96.79it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.9728)\n",
            "{'len_opcode_embedd': 12, 'hidden_dim_conv': 64, 'output_dim_conv': 32, 'num_layers_conv': 5, 'hidden_dim_lin': 20, 'num_layers_lin': 2, 'optimizer': 'Adam', 'lr': 0.01, 'dropout_conv': 0.3, 'dropout_lin': 0.3, 'loss_fn': 'MSE', 'score': tensor(0.9728), 'epochs': 40, 'number of parameters': 26953, 'validation': 'split'}\n",
            "[19]/[24] configs tested\n",
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [13:40<00:00, 20.52s/it]\n",
            "100%|██████████| 673/673 [00:03<00:00, 189.60it/s]\n",
            "100%|██████████| 673/673 [00:07<00:00, 95.23it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.9728)\n",
            "{'len_opcode_embedd': 12, 'hidden_dim_conv': 64, 'output_dim_conv': 32, 'num_layers_conv': 5, 'hidden_dim_lin': 20, 'num_layers_lin': 4, 'optimizer': 'Adam', 'lr': 0.01, 'dropout_conv': 0.3, 'dropout_lin': 0.3, 'loss_fn': 'MSE', 'score': tensor(0.9728), 'epochs': 40, 'number of parameters': 27793, 'validation': 'split'}\n",
            "[20]/[24] configs tested\n",
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [15:14<00:00, 22.86s/it]\n",
            "100%|██████████| 673/673 [00:03<00:00, 187.18it/s]\n",
            "100%|██████████| 673/673 [00:06<00:00, 96.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.9728)\n",
            "{'len_opcode_embedd': 12, 'hidden_dim_conv': 64, 'output_dim_conv': 32, 'num_layers_conv': 5, 'hidden_dim_lin': 20, 'num_layers_lin': 6, 'optimizer': 'Adam', 'lr': 0.01, 'dropout_conv': 0.3, 'dropout_lin': 0.3, 'loss_fn': 'MSE', 'score': tensor(0.9728), 'epochs': 40, 'number of parameters': 28633, 'validation': 'split'}\n",
            "[21]/[24] configs tested\n",
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [10:33<00:00, 15.84s/it]\n",
            "100%|██████████| 673/673 [00:03<00:00, 204.39it/s]\n",
            "100%|██████████| 673/673 [00:07<00:00, 94.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.9728)\n",
            "{'len_opcode_embedd': 12, 'hidden_dim_conv': 64, 'output_dim_conv': 32, 'num_layers_conv': 5, 'hidden_dim_lin': 48, 'num_layers_lin': 2, 'optimizer': 'Adam', 'lr': 0.01, 'dropout_conv': 0.3, 'dropout_lin': 0.3, 'loss_fn': 'MSE', 'score': tensor(0.9728), 'epochs': 40, 'number of parameters': 28577, 'validation': 'split'}\n",
            "[22]/[24] configs tested\n",
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [14:01<00:00, 21.04s/it]\n",
            "100%|██████████| 673/673 [00:03<00:00, 192.08it/s]\n",
            "100%|██████████| 673/673 [00:07<00:00, 95.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: tensor(0.9728)\n",
            "{'len_opcode_embedd': 12, 'hidden_dim_conv': 64, 'output_dim_conv': 32, 'num_layers_conv': 5, 'hidden_dim_lin': 48, 'num_layers_lin': 4, 'optimizer': 'Adam', 'lr': 0.01, 'dropout_conv': 0.3, 'dropout_lin': 0.3, 'loss_fn': 'MSE', 'score': tensor(0.9728), 'epochs': 40, 'number of parameters': 33281, 'validation': 'split'}\n",
            "[23]/[24] configs tested\n",
            "<class '__main__.Tile_GNN'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 16/40 [06:21<09:33, 23.88s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "x_IDeoSxITZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "\n",
        "cest = timezone('Europe/Berlin')\n",
        "now = datetime.now(timezone('UTC'))\n",
        "now_cest = now.astimezone(cest)\n",
        "now_str = now_cest.strftime('%Y-%m-%d_%H:%M:%S')\n",
        "\n",
        "results.to_csv('/content/drive/MyDrive/google-tpu/predict-ai-model-runtime/tile_parameter_search/' + now_str, index=False)"
      ],
      "metadata": {
        "id": "lnPtFPeCQB3Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}