{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch-geometric","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-17T12:13:32.510168Z","iopub.execute_input":"2023-09-17T12:13:32.510659Z","iopub.status.idle":"2023-09-17T12:13:47.576099Z","shell.execute_reply.started":"2023-09-17T12:13:32.510612Z","shell.execute_reply":"2023-09-17T12:13:47.574887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom tqdm import tqdm\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\n\nfrom torch_geometric import nn as gnn\nfrom torch_geometric.data import Data, Dataset, Batch\nfrom torch_geometric.loader import DataLoader\n\nfrom matplotlib import pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:15:39.818790Z","iopub.execute_input":"2023-09-17T14:15:39.819203Z","iopub.status.idle":"2023-09-17T14:15:39.826753Z","shell.execute_reply.started":"2023-09-17T14:15:39.819170Z","shell.execute_reply":"2023-09-17T14:15:39.825563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"splits = [\"train\", \"valid\", \"test\"]\n\nlayout_nlp_default = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/nlp/default'\nlayout_nlp_random = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/nlp/random'\nlayout_xla_default = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/xla/default'\nlayout_xla_random = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/xla/random'\n\ntile_xla = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/tile/xla'","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:13:51.449570Z","iopub.execute_input":"2023-09-17T12:13:51.450200Z","iopub.status.idle":"2023-09-17T12:13:51.458669Z","shell.execute_reply.started":"2023-09-17T12:13:51.450166Z","shell.execute_reply":"2023-09-17T12:13:51.456555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_n_data_to_df(directory, split, n, pos=0):\n    \n    path = os.path.join(directory, split)\n    files = os.listdir(path)\n    \n    data_list = []\n    \n    n = min(n, len(files))\n    for file in tqdm(files[pos:pos + n]):\n        file_path = os.path.join(path, file)\n        model_graph = dict(np.load(file_path))\n        model_graph[\"file\"] = file\n        data_list.append(model_graph)\n    \n    return pd.DataFrame(data_list)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:13:51.460243Z","iopub.execute_input":"2023-09-17T12:13:51.460668Z","iopub.status.idle":"2023-09-17T12:13:51.476050Z","shell.execute_reply.started":"2023-09-17T12:13:51.460635Z","shell.execute_reply":"2023-09-17T12:13:51.474959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data_to_df(directory, split):\n    \n    n = len(os.listdir(os.path.join(directory, split)))\n    return load_n_data_to_df(directory, split, n)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:13:51.480318Z","iopub.execute_input":"2023-09-17T12:13:51.480662Z","iopub.status.idle":"2023-09-17T12:13:51.488231Z","shell.execute_reply.started":"2023-09-17T12:13:51.480636Z","shell.execute_reply":"2023-09-17T12:13:51.487017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data","metadata":{}},{"cell_type":"code","source":"class CustomData(Data):\n    def __cat_dim__(self, key, value, *args, **kwargs):\n        if key == 'config_feat':\n            return None\n        else:\n            return super().__cat_dim__(key, value, args, kwargs)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:13:51.490780Z","iopub.execute_input":"2023-09-17T12:13:51.491743Z","iopub.status.idle":"2023-09-17T12:13:51.500331Z","shell.execute_reply.started":"2023-09-17T12:13:51.491709Z","shell.execute_reply":"2023-09-17T12:13:51.499329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TileDataset(Dataset):\n    \n    def __init__(self, graphs, lookup):\n        super().__init__()\n        self.graphs = graphs\n        self.lookup = lookup\n    \n    def len(self):\n        return len(self.lookup)\n    \n    def get(self, idx):\n        graph_idx, config_idx = self.lookup[idx]\n        \n        return self.get_quad(graph_idx, config_idx)\n        \n    \n    def get_quad(self, graph_idx, config_idx):\n        graph = self.graphs[graph_idx]\n        \n        return CustomData(\n            x = graph['node_feat'],\n            edge_index = graph['edge_index'],\n            y = graph['y'][config_idx],\n            \n            node_opcode = graph['node_opcode'],\n            config_feat = graph['config_feat'][config_idx, :],\n            file = graph['file']\n        )","metadata":{"execution":{"iopub.status.busy":"2023-09-17T15:51:02.796733Z","iopub.execute_input":"2023-09-17T15:51:02.797366Z","iopub.status.idle":"2023-09-17T15:51:02.812543Z","shell.execute_reply.started":"2023-09-17T15:51:02.797322Z","shell.execute_reply":"2023-09-17T15:51:02.811403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataset(df):\n    \n    graphs = []\n    lookup = []\n    \n    for index, graph in tqdm(df.iterrows(), total=len(df)):\n               \n        c = graph['config_feat'].shape[0]\n        \n        graph = {\n            'file': graph['file'],\n            'node_feat': torch.from_numpy(graph['node_feat']),\n            'node_opcode': torch.from_numpy(graph['node_opcode']).type(torch.int64),\n            'edge_index': torch.from_numpy(graph['edge_index']).t().contiguous(),\n            'config_feat': torch.from_numpy(graph['config_feat']),\n            'y': torch.from_numpy(graph['config_runtime']) / torch.from_numpy(graph['config_runtime_normalizers'])   \n        }\n        \n        graphs.append(graph)\n        lookup.extend((index, conf_idx) for conf_idx in range(c))\n        \n    print(f\"Read {len(graphs)} graphs with a total of {len(lookup)} configurations\")\n    return TileDataset(graphs, lookup)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:36:20.169802Z","iopub.execute_input":"2023-09-17T12:36:20.170407Z","iopub.status.idle":"2023-09-17T12:36:20.184929Z","shell.execute_reply.started":"2023-09-17T12:36:20.170364Z","shell.execute_reply":"2023-09-17T12:36:20.184014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = load_data_to_df(tile_xla, \"train\")\ndf_valid = load_data_to_df(tile_xla, \"valid\")\ndf_test = load_data_to_df(tile_xla, \"test\")","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:39:13.901508Z","iopub.execute_input":"2023-09-17T12:39:13.901890Z","iopub.status.idle":"2023-09-17T12:39:46.850703Z","shell.execute_reply.started":"2023-09-17T12:39:13.901859Z","shell.execute_reply":"2023-09-17T12:39:46.849685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = get_dataset(df_train)\nvalid_dataset = get_dataset(df_valid)\ntest_dataset = get_dataset(df_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T15:51:06.964343Z","iopub.execute_input":"2023-09-17T15:51:06.964736Z","iopub.status.idle":"2023-09-17T15:51:11.198463Z","shell.execute_reply.started":"2023-09-17T15:51:06.964702Z","shell.execute_reply":"2023-09-17T15:51:11.197394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size = 512, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T14:33:04.505059Z","iopub.execute_input":"2023-09-17T14:33:04.506122Z","iopub.status.idle":"2023-09-17T14:33:04.511704Z","shell.execute_reply.started":"2023-09-17T14:33:04.506080Z","shell.execute_reply":"2023-09-17T14:33:04.510666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"class TileModel(nn.Module):\n    \n    def __init__(self, opcode_embedding_dim = 4, conv_hidden_channels = 120, conv_num_lyers = 4, conv_out_dim = 48):\n        super().__init__()\n        \n        self.opcode_embedding = nn.Embedding(120, opcode_embedding_dim)\n        \n        node_feature_dim = 140\n            \n        self.conv = gnn.GraphSAGE(opcode_embedding_dim + node_feature_dim, conv_hidden_channels, conv_num_lyers, conv_out_dim)\n        \n        config_dim = 24\n        self.fwd = nn.Sequential(\n            nn.Linear(conv_out_dim + config_dim, 48),\n            nn.ReLU(),\n            nn.Linear(48, 48),\n            nn.ReLU(),\n            nn.Linear(48, 1)\n        )\n        \n        \n    def forward(self, data):\n        \"\"\"\n            Shapes:\n                node_feat    - (n, 140)\n                node_opcode  - (n, )\n                edge_index   - (m, 2)\n                config_feat  - (1, 24)\n            \n            Approach:\n                1. Opcode embeddings\n                2. Concatenate embeddings to node feature-vector\n                3. Convolutional layer for node embeddings\n                4. Pooling for graph embedding\n                5. Concatenate configuration feature-vector to graph embedding\n                6. Forward layer\n                7. Flatten\n            \n            Approach is inline with the paper Phitchaya Mangpo Phothilimthana et. al (2023) \n        \"\"\"\n        \n        node_opcode_embedding = self.opcode_embedding(data[\"node_opcode\"]) # (n, 4)\n        \n        x = torch.concat([data[\"x\"], node_opcode_embedding], dim = 1) # (n, 144)\n        \n        x = self.conv(x, data[\"edge_index\"]) # (n, 48)\n        \n        means = []\n        for start, end in zip(data.ptr[:-1], data.ptr[1:]):            \n            means.append(torch.mean(x[start:end, :], 0))\n        \n        x = torch.stack(means) # (batch_size, 48)\n        \n        x = torch.concat([x, data[\"config_feat\"]], dim = 1) # (batch_size, 72)\n        \n        x = self.fwd(x) # (batch_size, 1)\n        \n        return x.flatten()\n        ","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:43:49.373522Z","iopub.execute_input":"2023-09-17T12:43:49.373922Z","iopub.status.idle":"2023-09-17T12:43:49.388170Z","shell.execute_reply.started":"2023-09-17T12:43:49.373890Z","shell.execute_reply":"2023-09-17T12:43:49.387133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_num_params(model):\n    # Count the number of parameters\n    total_params = sum(p.numel() for p in model.parameters())\n    print(f\"Total parameters in the model: {total_params}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:43:52.492158Z","iopub.execute_input":"2023-09-17T12:43:52.493256Z","iopub.status.idle":"2023-09-17T12:43:52.499050Z","shell.execute_reply.started":"2023-09-17T12:43:52.493222Z","shell.execute_reply":"2023-09-17T12:43:52.497589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndef train_step(model, criterion, opt):\n    model.train()\n    \n    epoch_train_losses = np.empty((0,))\n    \n    for tile_data in (pbar := tqdm(train_loader)):\n        \n        tile_data.to(device)\n        \n        opt.zero_grad()\n        pred = model(tile_data)\n        loss = criterion(pred, tile_data[\"y\"])\n                \n        loss.backward()\n        opt.step()\n        \n        pbar.set_description(f\"Loss: {loss.item():8.2f}\")\n        epoch_train_losses = np.append(epoch_train_losses, loss.item())\n    return np.mean(epoch_train_losses)\n\ndef test(model, criterion):\n    model.eval()\n    \n    epoch_valid_losses = np.empty((0,))\n    \n    with torch.no_grad():\n        for tile in DataLoader(valid_dataset, batch_size = 512):\n                \n            tile.to(device)\n            \n            pred = model(tile)\n            loss = criterion(pred, tile[\"y\"])\n            \n            epoch_valid_losses = np.append(epoch_valid_losses, loss.item())\n    return np.mean(epoch_valid_losses)\n\ndef train(model, lr = 0.01, epochs = 10):\n    \n    model.to(device)\n    \n    loss_fn = nn.MSELoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    \n    train_losses = np.empty((0,))\n    valid_losses = np.empty((0,))\n    \n    for i in range(1, epochs + 1):\n    \n        train_loss = train_step(model, loss_fn, optimizer)\n        valid_loss = test(model, loss_fn)\n    \n        train_losses = np.append(train_losses, train_loss)\n        valid_losses = np.append(valid_losses, valid_loss) \n        print(f\"Epoch: {i}, Train Loss: {train_losses[-1]}, Valid Loss: {valid_losses[-1]}\")\n    \n    return valid_losses[-1]\n","metadata":{"execution":{"iopub.status.busy":"2023-09-17T16:59:22.985535Z","iopub.execute_input":"2023-09-17T16:59:22.985918Z","iopub.status.idle":"2023-09-17T16:59:22.998910Z","shell.execute_reply.started":"2023-09-17T16:59:22.985882Z","shell.execute_reply":"2023-09-17T16:59:22.997907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = TileModel()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"def predict(batch, model):\n    model = model.to(device)\n    batch.to(device)\n    \n    out = model(batch).to(\"cpu\")\n    return out","metadata":{"execution":{"iopub.status.busy":"2023-09-17T15:05:29.254095Z","iopub.execute_input":"2023-09-17T15:05:29.254488Z","iopub.status.idle":"2023-09-17T15:05:29.260145Z","shell.execute_reply.started":"2023-09-17T15:05:29.254454Z","shell.execute_reply":"2023-09-17T15:05:29.259036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predictions_per_file(model, dataset):\n        \n    model.eval()\n    \n    with torch.no_grad():\n        predictions = []\n        for graph_configs in tqdm(DataLoader(dataset, batch_size = 512)):\n            predictions.append(predict(graph_configs, model))\n    \n    all_predictions = torch.cat(predictions)\n        \n    pred_index = 0\n    predictions = {}\n    for graph in tqdm(dataset.graphs):\n        c = graph['y'].shape[0]\n        rel_pred = all_predictions[pred_index : pred_index + c]\n    \n        top_5 = torch.sort(rel_pred).indices[:5]\n        predictions[graph['file']] = top_5\n        pred_index += c\n\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2023-09-17T17:39:54.056756Z","iopub.execute_input":"2023-09-17T17:39:54.057221Z","iopub.status.idle":"2023-09-17T17:39:54.065918Z","shell.execute_reply.started":"2023-09-17T17:39:54.057185Z","shell.execute_reply":"2023-09-17T17:39:54.064739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, predictions):\n    \n    predictions = list(predictions.values())\n\n    # Calculate score\n    scores = np.empty((0,))\n\n    for i, graph in tqdm(enumerate(valid_dataset.graphs), total=len(valid_dataset.graphs)):\n        best_prediction = min([graph[\"y\"][pred_ind] for pred_ind in predictions[i][:5]])\n        best_total = min(graph[\"y\"])\n        scores = np.append(scores, 2.0 - best_prediction / best_total)\n\n    avg_score = np.mean(scores)\n    print(\"Score:\", avg_score)\n    return avg_score\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-17T16:24:10.744117Z","iopub.execute_input":"2023-09-17T16:24:10.744627Z","iopub.status.idle":"2023-09-17T16:24:10.758278Z","shell.execute_reply.started":"2023-09-17T16:24:10.744572Z","shell.execute_reply":"2023-09-17T16:24:10.757299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions\n# predictions = get_predictions_per_file(model, valid_dataset)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-09-17T17:40:00.587771Z","iopub.execute_input":"2023-09-17T17:40:00.588186Z","iopub.status.idle":"2023-09-17T17:44:00.527036Z","shell.execute_reply.started":"2023-09-17T17:40:00.588153Z","shell.execute_reply":"2023-09-17T17:44:00.525982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate_model(model, predictions)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T17:44:39.201579Z","iopub.execute_input":"2023-09-17T17:44:39.202687Z","iopub.status.idle":"2023-09-17T17:44:46.228410Z","shell.execute_reply.started":"2023-09-17T17:44:39.202642Z","shell.execute_reply":"2023-09-17T17:44:46.227414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_submission(predictions):\n    \n    submission = pd.read_csv(\"/kaggle/input/predict-ai-model-runtime/sample_submission.csv\")\n    \n    \n    for model_name in predictions.keys():\n        model_id = 'tile:xla:' + model_name[:-4]\n        submission.loc[submission[\"ID\"] == model_id, \"TopConfigs\"] = \";\".join([str(pred) for pred in predictions[model_name].tolist()])\n    \n    submission.to_csv(\"submission.csv\", index=False)\n        \n# create_submission(predictions)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T16:27:40.509364Z","iopub.execute_input":"2023-09-17T16:27:40.509798Z","iopub.status.idle":"2023-09-17T16:27:40.860412Z","shell.execute_reply.started":"2023-09-17T16:27:40.509766Z","shell.execute_reply":"2023-09-17T16:27:40.859393Z"},"trusted":true},"execution_count":null,"outputs":[]}]}