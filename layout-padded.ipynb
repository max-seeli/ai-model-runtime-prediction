{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch-geometric","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-21T00:08:46.458389Z","iopub.execute_input":"2023-09-21T00:08:46.458916Z","iopub.status.idle":"2023-09-21T00:09:27.627741Z","shell.execute_reply.started":"2023-09-21T00:08:46.458870Z","shell.execute_reply":"2023-09-21T00:09:27.626609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nfrom tqdm import tqdm\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torch_geometric as pyg\nfrom torch_geometric import nn as gnn\n\nfrom matplotlib import pyplot as plt\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2023-09-21T00:09:27.630891Z","iopub.execute_input":"2023-09-21T00:09:27.631633Z","iopub.status.idle":"2023-09-21T00:09:31.798993Z","shell.execute_reply.started":"2023-09-21T00:09:27.631594Z","shell.execute_reply":"2023-09-21T00:09:31.797850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"splits = [\"train\", \"valid\", \"test\"]\n\nlayout_nlp_default = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/nlp/default'\nlayout_nlp_random = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/nlp/random'\nlayout_xla_default = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/xla/default'\nlayout_xla_random = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/xla/random'","metadata":{"execution":{"iopub.status.busy":"2023-09-21T00:09:31.801076Z","iopub.execute_input":"2023-09-21T00:09:31.802132Z","iopub.status.idle":"2023-09-21T00:09:31.807919Z","shell.execute_reply.started":"2023-09-21T00:09:31.802092Z","shell.execute_reply":"2023-09-21T00:09:31.806819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_n_data_to_df(directory, split, n, pos=0):\n    \n    path = os.path.join(directory, split)\n    files = os.listdir(path)\n    \n    data_list = []\n    \n    n = min(n, len(files))\n    for file in tqdm(files[pos:pos + n]):\n        file_path = os.path.join(path, file)\n        model_graph = dict(np.load(file_path))\n        model_graph[\"file\"] = file\n        data_list.append(model_graph)\n    \n    return pd.DataFrame(data_list)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T00:09:31.809816Z","iopub.execute_input":"2023-09-21T00:09:31.810587Z","iopub.status.idle":"2023-09-21T00:09:31.826396Z","shell.execute_reply.started":"2023-09-21T00:09:31.810545Z","shell.execute_reply":"2023-09-21T00:09:31.825285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data_to_df(directory, split):\n    \n    n = len(os.listdir(os.path.join(directory, split)))\n    return load_n_data_to_df(directory, split, n)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T00:09:31.829981Z","iopub.execute_input":"2023-09-21T00:09:31.830376Z","iopub.status.idle":"2023-09-21T00:09:31.839473Z","shell.execute_reply.started":"2023-09-21T00:09:31.830339Z","shell.execute_reply":"2023-09-21T00:09:31.838275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LayoutLazyDataset(Dataset):\n    \n    def __init__(self, path, split):\n        \n        self.data_folder = os.path.join(path,split)\n        self.data_files = os.listdir(self.data_folder)\n\n    def __len__(self):\n        return len(self.data_files)\n\n    def __getitem__(self, index):\n        data_file = self.data_files[index]\n        \n        # Load data sample from storage when it's actually needed\n        data = self.load_data(data_file)\n\n        file = data['file']\n        node_feat = torch.from_numpy(data['node_feat'])\n        node_opcode = torch.from_numpy(data['node_opcode']).type(torch.int64)\n        edge_index = torch.from_numpy(data['edge_index']).permute(1, 0)\n        node_config_feat = torch.from_numpy(data['node_config_feat'])\n        node_config_ids = torch.from_numpy(data['node_config_ids'])\n        config_runtime = torch.from_numpy(data['config_runtime']).type(torch.float32)\n            \n        return {\n            \"file\": file,\n            \"node_feat\": node_feat,\n            \"node_opcode\": node_opcode,\n            \"edge_index\": edge_index,\n            \"node_config_feat\": node_config_feat,\n            \"node_config_ids\": node_config_ids,\n            \"y\": config_runtime # F.normalize(config_runtime, p=3, dim=0)\n        }\n\n    def load_data(self, data_file):\n        \n        data = dict(np.load(os.path.join(self.data_folder, data_file)))\n        data[\"file\"] = data_file\n        \n        return data\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T00:09:31.841009Z","iopub.execute_input":"2023-09-21T00:09:31.842023Z","iopub.status.idle":"2023-09-21T00:09:31.854485Z","shell.execute_reply.started":"2023-09-21T00:09:31.841986Z","shell.execute_reply":"2023-09-21T00:09:31.853731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LayoutModel(nn.Module):\n    \n    def __init__(self, opcode_embedding_dim = 4, conv_hidden_channels = 120, conv_num_layers = 4, conv_out_dim = 48):\n        super().__init__()\n        \n        self.opcode_embedding = nn.Embedding(120, opcode_embedding_dim)\n        \n        node_feature_dim = 140\n        node_config_dim = 18\n        \n        node_rep_dim = opcode_embedding_dim + node_feature_dim + node_config_dim\n        \n        self.conv = gnn.GCNConv(node_rep_dim, conv_out_dim)\n\n        # self.conv = gnn.GraphSAGE(node_rep_dim, conv_hidden_channels, conv_num_layers, conv_out_dim)\n        \n        hidden_dim = 48\n        self.fwd = nn.Sequential(\n            nn.Linear(conv_out_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, 1)\n        )\n            \n    def forward(self, node_feat, node_opcode, edge_index, node_config_feat, node_config_ids):\n        \"\"\"\n            Shapes:\n                node_feat    - (n, 140)\n                node_opcode  - (n, )\n                edge_index   - (2, m)\n                node_config_feat  - (c, nc, 18)\n                node_config_ids - (nc, )\n            \n            Approach:\n                1. Opcode embeddings\n                2. Concatenate embeddings and config to node feature-vector\n                3. Convolutional layer for node embeddings\n                4. Pooling for graph embedding\n                6. Forward layer\n                7. Flatten        \n        \"\"\"\n        n = node_feat.shape[0]\n        c = node_config_feat.shape[0]\n        \n        node_opcode_embedding = self.opcode_embedding(node_opcode) # (n, opcode_embedding_dim)\n        \n        empty_configs = torch.full([n, 18], -1).to(device)\n        \n        x = torch.cat([node_opcode_embedding, node_feat, empty_configs], dim=1) # (n, opcode_embedding_dim + 140 + 18)\n\n        runtimes = []\n        \n        # print(x.shape)\n        x = x.unsqueeze(0)\n        # print(x.shape)\n        x = x.repeat(c, 1, 1)\n        # print(x.shape)\n        \n        # print(node_config_feat.shape)\n        for i, config in enumerate(node_config_feat):\n        #    print(i)\n            for node_id, config_feat in zip(node_config_ids, config):\n                x[i, node_id, -18:] = config_feat\n            \n        x = self.conv(x, edge_index) # (c, n, conv_out_dim)\n        # print(cx.shape)\n        x = torch.mean(x, 1) # (c, conv_out_dim)\n        # print(cx.shape)\n        x = self.fwd(x) # (c, )\n        return torch.flatten(x) # (c, )\n        \n    \n        \n        ","metadata":{"execution":{"iopub.status.busy":"2023-09-21T00:09:31.856101Z","iopub.execute_input":"2023-09-21T00:09:31.856735Z","iopub.status.idle":"2023-09-21T00:09:31.872274Z","shell.execute_reply.started":"2023-09-21T00:09:31.856699Z","shell.execute_reply":"2023-09-21T00:09:31.871202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_dataset = LayoutLazyDataset(layout_nlp_random, 'train')\n\nlazy_loader = DataLoader(custom_dataset, batch_size=1)\n\nmodel = LayoutModel().to(device)\n\nfor data in custom_dataset:\n    print(\"Test\")\n    print(data[\"y\"])\n    for k, v in data.items():\n        if isinstance(v, torch.Tensor):\n            data[k] = v.to(device)\n    \n    node_feat, node_opcode, edge_index, node_config_feat, node_config_ids = data[\"node_feat\"], data[\"node_opcode\"], data[\"edge_index\"], data[\"node_config_feat\"], data[\"node_config_ids\"]\n    print(model(node_feat, node_opcode, edge_index, node_config_feat[0:2, :, :], node_config_ids).shape)\n    break\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T00:09:31.873751Z","iopub.execute_input":"2023-09-21T00:09:31.874207Z","iopub.status.idle":"2023-09-21T00:09:37.883412Z","shell.execute_reply.started":"2023-09-21T00:09:31.874172Z","shell.execute_reply":"2023-09-21T00:09:37.881585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Total parameters in the model: {sum(p.numel() for p in model.parameters())}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-21T00:09:37.885025Z","iopub.execute_input":"2023-09-21T00:09:37.885392Z","iopub.status.idle":"2023-09-21T00:09:37.892043Z","shell.execute_reply.started":"2023-09-21T00:09:37.885358Z","shell.execute_reply":"2023-09-21T00:09:37.891006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"def node_config_selection(node_config_feat, config_runtime, n):\n    c = config_runtime.shape[0]\n\n    num_chosen_configs = min(c, n)\n    configs = list(range(0, c))\n    random.shuffle(configs)\n    chosen_configs = configs[:num_chosen_configs]\n    return node_config_feat[chosen_configs, :, :], config_runtime[chosen_configs]","metadata":{"execution":{"iopub.status.busy":"2023-09-21T00:09:37.893444Z","iopub.execute_input":"2023-09-21T00:09:37.894071Z","iopub.status.idle":"2023-09-21T00:09:37.903809Z","shell.execute_reply.started":"2023-09-21T00:09:37.894031Z","shell.execute_reply":"2023-09-21T00:09:37.902872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_step(model, dataloader, criterion, opt):\n    model.train()\n    \n    step = 0\n    \n    epoch_train_losses = np.empty((0,))\n    for layout in tqdm(dataloader):\n        \n        node_feat, node_opcode, edge_index, node_config_feat, node_config_ids = layout[\"node_feat\"][0].to(device), layout[\"node_opcode\"][0].to(device), layout[\"edge_index\"][0].to(device), layout[\"node_config_feat\"][0].to(device), layout[\"node_config_ids\"][0].to(device)\n        y = layout[\"y\"][0].to(device)\n        node_config_feat, y = node_config_selection(node_config_feat, y, 100)\n        \n        opt.zero_grad()\n        pred = model(node_feat, node_opcode, edge_index, node_config_feat, node_config_ids)\n        loss = criterion(pred, y)\n        loss.backward()\n        \n        parameters = [p for p in model.parameters() if p.grad is not None and p.requires_grad]\n        \n        gradient_norms = []\n        if len(parameters) == 0:\n            print(\"No grads\")\n            total_norm = 0.0\n        else:\n            total_norm = torch.norm(torch.stack([torch.norm(p.grad.detach(), 2).to(device) for p in parameters]), 2.0).item()\n        \n        for param_group in opt.param_groups:\n            for param in param_group['params']:\n                if param.grad is not None:\n                    gradient_norms.append(param.grad.data.norm().cpu())\n        \n        gradient_norms = np.array(gradient_norms)\n        print(f\"bAvg grad norm: {np.mean(gradient_norms)}\\nbMax grad norm: {np.max(gradient_norms)}\\nbMedian grad norm: {np.median(gradient_norms)}\")\n        print(f\"bTotal norm: {total_norm}\")        \n        \n        \n        max_grad_norm = 10000.0\n        # nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n        \n        gradient_norms = []\n        if len(parameters) == 0:\n            print(\"No grads\")\n            total_norm = 0.0\n        else:\n            total_norm = torch.norm(torch.stack([torch.norm(p.grad.detach(), 2).to(device) for p in parameters]), 2.0).item()\n        \n        for param_group in opt.param_groups:\n            for param in param_group['params']:\n                if param.grad is not None:\n                    gradient_norms.append(param.grad.data.norm().cpu())\n        \n        gradient_norms = np.array(gradient_norms)\n        print(f\"Avg grad norm: {np.mean(gradient_norms)}\\nMax grad norm: {np.max(gradient_norms)}\\nMedian grad norm: {np.median(gradient_norms)}\")\n        print(f\"Total norm: {total_norm}\")        \n        \n        opt.step()\n        step += 1\n        epoch_train_losses = np.append(epoch_train_losses, loss.item())\n    return np.mean(epoch_train_losses)\n\ndef test(model, dataloader, criterion):\n    model.eval()\n    \n    epoch_valid_losses = np.empty((0,))\n    \n    with torch.no_grad():\n        for layout in dataloader:\n                \n            node_feat, node_opcode, edge_index, node_config_feat, node_config_ids = layout[\"node_feat\"][0].to(device), layout[\"node_opcode\"][0].to(device), layout[\"edge_index\"][0].to(device), layout[\"node_config_feat\"][0].to(device), layout[\"node_config_ids\"][0].to(device)\n            y = layout[\"y\"][0].to(device)\n            \n            node_config_feat, y = node_config_selection(node_config_feat, y, 1)\n            \n            pred = model(node_feat, node_opcode, edge_index, node_config_feat, node_config_ids)\n            loss = criterion(pred, y)\n            \n            epoch_valid_losses = np.append(epoch_valid_losses, loss.item())\n    return np.mean(epoch_valid_losses)\n\ndef train(model, trainloader, validloader, lr = 0.01, epochs = 10):\n    \n    model.to(device)\n    \n    loss_fn = nn.MSELoss().to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    \n    train_losses = np.empty((0,))\n    valid_losses = np.empty((0,))\n    \n    for i in range(1, epochs + 1):\n    \n        train_loss = train_step(model, trainloader, loss_fn, optimizer)\n        valid_loss = test(model, validloader, loss_fn)\n    \n        train_losses = np.append(train_losses, train_loss)\n        valid_losses = np.append(valid_losses, valid_loss) \n        print(f\"Epoch: {i}, Train Loss: {train_loss}, Valid Loss: {valid_loss}\")\n    \n    return valid_losses[-1]","metadata":{"execution":{"iopub.status.busy":"2023-09-21T00:09:37.905345Z","iopub.execute_input":"2023-09-21T00:09:37.905944Z","iopub.status.idle":"2023-09-21T00:09:37.929147Z","shell.execute_reply.started":"2023-09-21T00:09:37.905894Z","shell.execute_reply":"2023-09-21T00:09:37.928115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(42)\nrandom.seed(42)\n\nmodel = LayoutModel()\ntrainloader = DataLoader(LayoutLazyDataset(layout_nlp_default, 'train'), batch_size = 1, shuffle = True)\nvalidloader = DataLoader(LayoutLazyDataset(layout_nlp_default, 'valid'), batch_size = 1, shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T00:09:37.930748Z","iopub.execute_input":"2023-09-21T00:09:37.931324Z","iopub.status.idle":"2023-09-21T00:09:38.018208Z","shell.execute_reply.started":"2023-09-21T00:09:37.931284Z","shell.execute_reply":"2023-09-21T00:09:38.017232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train(model, trainloader, validloader, lr=0.01, epochs=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T00:09:38.019601Z","iopub.execute_input":"2023-09-21T00:09:38.020431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predictions","metadata":{}},{"cell_type":"code","source":"def predict(model, layout):\n    model = model.to(device)\n    node_feat, node_opcode, edge_index, node_config_feat, node_config_ids = layout[\"node_feat\"].to(device), layout[\"node_opcode\"].to(device), layout[\"edge_index\"].to(device), layout[\"node_config_feat\"].to(device), layout[\"node_config_ids\"].to(device)\n    \n    runtimes = []\n    for i in range(len(node_config_feat)):\n        pred = model(node_feat, node_opcode, edge_index, node_config_feat[i:i+1, :, :], node_config_ids)\n        runtimes.append(pred)\n    \n    runtimes = torch.cat(runtimes)\n    \n    return torch.sort(runtimes).indices\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predictions_per_file(model, dataset):\n    \n    model.eval()\n    prediction_for_file = {}\n    \n    with torch.no_grad():\n        for layout in dataset:\n            prediction_for_file[layout[\"file\"]] = predict(model, layout)\n    \n    return prediction_for_file\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import kendalltau\n\ndef evaluate(model, dataset):\n    model.eval()\n    \n    correlations = np.array([])\n    p_values = np.array([])\n    \n    with torch.no_grad():\n        for layout in tqdm(dataset):\n            preds = predict(model, layout).cpu()\n            actual = torch.sort(layout[\"y\"]).indices\n            correlation, p_value = kendalltau(preds, actual)\n        \n            correlations = np.append(correlations, correlation)\n            p_values = np.append(p_values, p_value)\n            \n    print(f\"Average Tau: {np.mean(correlations)}\")\n    print(f\"Max Tau: {np.max(correlations)}\")\n          \n    plt.boxplot(correlations)\n    plt.title(\"Kendall Tau\")\n    plt.ylabel(\"Tau Coefficient\")\n    plt.show()\n    \n            \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = LayoutLazyDataset(layout_nlp_default, 'test')\n\n# evaluate(model, test_dataset)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}