{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch-geometric","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-30T11:18:53.773834Z","iopub.execute_input":"2023-09-30T11:18:53.774154Z","iopub.status.idle":"2023-09-30T11:19:13.707378Z","shell.execute_reply.started":"2023-09-30T11:18:53.774126Z","shell.execute_reply":"2023-09-30T11:19:13.706301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nfrom tqdm import tqdm\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torch_geometric as pyg\nfrom torch_geometric import nn as gnn\n\nfrom matplotlib import pyplot as plt\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2023-09-30T11:19:13.709521Z","iopub.execute_input":"2023-09-30T11:19:13.710168Z","iopub.status.idle":"2023-09-30T11:19:17.938333Z","shell.execute_reply.started":"2023-09-30T11:19:13.710124Z","shell.execute_reply":"2023-09-30T11:19:17.937439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"splits = [\"train\", \"valid\", \"test\"]\n\nlayout_nlp_default = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/nlp/default'\nlayout_nlp_random = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/nlp/random'\nlayout_xla_default = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/xla/default'\nlayout_xla_random = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/xla/random'","metadata":{"execution":{"iopub.status.busy":"2023-09-30T11:19:17.939625Z","iopub.execute_input":"2023-09-30T11:19:17.940445Z","iopub.status.idle":"2023-09-30T11:19:17.945804Z","shell.execute_reply.started":"2023-09-30T11:19:17.940413Z","shell.execute_reply":"2023-09-30T11:19:17.944731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load data sample from storage only when it's actually needed\nclass LayoutLazyDataset(Dataset):\n    \n    def __init__(self, path, split):\n        \n        self.data_folder = os.path.join(path,split)\n        self.data_files = os.listdir(self.data_folder)\n\n    def __len__(self):\n        return len(self.data_files)\n\n    def __getitem__(self, index):\n        data_file = self.data_files[index]\n        \n        data = self.load_data(data_file)\n\n        return {\n            \"file\": data['file'],\n            \"node_feat\": torch.from_numpy(data['node_feat']),\n            \"node_opcode\": torch.from_numpy(data['node_opcode']).type(torch.int64),\n            \"edge_index\": torch.from_numpy(data['edge_index']).permute(1, 0),\n            \"node_config_feat\": torch.from_numpy(data['node_config_feat']),\n            \"node_config_ids\": torch.from_numpy(data['node_config_ids']),\n            \"y\": torch.from_numpy(data['config_runtime']).type(torch.float32)\n        }\n\n    def load_data(self, data_file):\n        \n        data = dict(np.load(os.path.join(self.data_folder, data_file)))\n        data[\"file\"] = data_file\n        return data\n","metadata":{"execution":{"iopub.status.busy":"2023-09-30T11:19:17.948587Z","iopub.execute_input":"2023-09-30T11:19:17.949447Z","iopub.status.idle":"2023-09-30T11:19:17.959176Z","shell.execute_reply.started":"2023-09-30T11:19:17.949417Z","shell.execute_reply":"2023-09-30T11:19:17.958368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load all data sample to memory when initializing the dataset\nclass LayoutDataset(Dataset):\n    \n    def __init__(self, path, split, chunk_size = 1000):\n        self.layouts = self.load_data_to_df(path, split, chunk_size)\n        \n    def load_data_to_df(directory, split, chunk_size):\n    \n        path = os.path.join(directory, split)\n        files = os.listdir(path)\n    \n        graphs = []\n        for file in tqdm(files):\n            file_path = os.path.join(path, file)\n            with np.load(file_path) as np_file:\n                graphs.append({\n                    \"file\": file,\n                    'node_feat': torch.tensor(np_file['node_feat']),\n                    'node_opcode': torch.tensor(np_file['node_opcode']).type(torch.int64),\n                    'edge_index': torch.tensor(np_file['edge_index']).permute(1, 0),\n                    'node_config_feat': torch.tensor(np_file['node_config_feat'][:chunk_size]),\n                    'node_config_ids': torch.tensor(np_file['node_config_ids']),\n                    'y': torch.tensor(np_file['config_runtime']).type(torch.float32)\n                })\n    \n        return pd.DataFrame(graphs)\n\n    def __len__(self):\n        return len(self.layouts)\n\n    def __getitem__(self, idx):\n        return self.layouts.iloc[idx].to_dict()\n    \n    \n","metadata":{"execution":{"iopub.status.busy":"2023-09-30T11:19:17.960550Z","iopub.execute_input":"2023-09-30T11:19:17.961421Z","iopub.status.idle":"2023-09-30T11:19:17.970732Z","shell.execute_reply.started":"2023-09-30T11:19:17.961392Z","shell.execute_reply":"2023-09-30T11:19:17.969840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LayoutModel(nn.Module):\n    \n    def __init__(self, opcode_embedding_dim = 4, conv_hidden_channels = 120, conv_num_layers = 4, conv_out_dim = 48):\n        super().__init__()\n        \n        self.opcode_embedding = nn.Embedding(120, opcode_embedding_dim)\n        \n        node_feature_dim = 140\n        node_config_dim = 18\n        \n        node_rep_dim = opcode_embedding_dim + node_feature_dim + node_config_dim\n        \n        self.conv = gnn.GCNConv(node_rep_dim, conv_out_dim)\n\n        # self.conv = gnn.GraphSAGE(node_rep_dim, conv_hidden_channels, conv_num_layers, conv_out_dim)\n        \n        hidden_dim = 48\n        self.fwd = nn.Sequential(\n            nn.Linear(conv_out_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, 1)\n        )\n            \n    def forward(self, node_feat, node_opcode, edge_index, node_config_feat, node_config_ids):\n        \"\"\"\n            Shapes:\n                node_feat    - (n, 140)\n                node_opcode  - (n, )\n                edge_index   - (2, m)\n                node_config_feat  - (c, nc, 18)\n                node_config_ids - (nc, )\n            \n            Approach:\n                1. Opcode embeddings\n                2. Concatenate embeddings and config to node feature-vector\n                3. Convolutional layer for node embeddings\n                4. Pooling for graph embedding\n                6. Forward layer\n                7. Flatten        \n        \"\"\"\n        n = node_feat.shape[0]\n        c = node_config_feat.shape[0]\n        \n        node_opcode_embedding = self.opcode_embedding(node_opcode) # (n, opcode_embedding_dim)\n        \n        empty_configs = torch.full([n, 18], -1).to(device)\n        \n        x = torch.cat([node_opcode_embedding, node_feat, empty_configs], dim=1) # (n, opcode_embedding_dim + 140 + 18)\n\n        runtimes = []\n        \n        # print(x.shape)\n        x = x.unsqueeze(0)\n        # print(x.shape)\n        x = x.repeat(c, 1, 1)\n        # print(x.shape)\n        \n        # print(node_config_feat.shape)\n        for i, config in enumerate(node_config_feat):\n        #    print(i)\n            for node_id, config_feat in zip(node_config_ids, config):\n                x[i, node_id, -18:] = config_feat\n            \n        x = self.conv(x, edge_index) # (c, n, conv_out_dim)\n        # print(cx.shape)\n        x = torch.mean(x, 1) # (c, conv_out_dim)\n        # print(cx.shape)\n        x = self.fwd(x) # (c, )\n        return torch.flatten(x) # (c, )\n        \n    \n        \n        ","metadata":{"execution":{"iopub.status.busy":"2023-09-30T11:19:17.972032Z","iopub.execute_input":"2023-09-30T11:19:17.972568Z","iopub.status.idle":"2023-09-30T11:19:17.985875Z","shell.execute_reply.started":"2023-09-30T11:19:17.972539Z","shell.execute_reply":"2023-09-30T11:19:17.984912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Total parameters in the model: {sum(p.numel() for p in LayoutModel().parameters())}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-30T11:19:17.987091Z","iopub.execute_input":"2023-09-30T11:19:17.987449Z","iopub.status.idle":"2023-09-30T11:19:18.026529Z","shell.execute_reply.started":"2023-09-30T11:19:17.987422Z","shell.execute_reply":"2023-09-30T11:19:18.025638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"def node_config_selection(node_config_feat, config_runtime, n):\n    c = config_runtime.shape[0]\n\n    num_chosen_configs = min(c, n)\n    configs = list(range(0, c))\n    random.shuffle(configs)\n    chosen_configs = configs[:num_chosen_configs]\n    return node_config_feat[chosen_configs, :, :], config_runtime[chosen_configs]","metadata":{"execution":{"iopub.status.busy":"2023-09-30T11:19:18.027589Z","iopub.execute_input":"2023-09-30T11:19:18.028325Z","iopub.status.idle":"2023-09-30T11:19:18.033657Z","shell.execute_reply.started":"2023-09-30T11:19:18.028296Z","shell.execute_reply":"2023-09-30T11:19:18.032704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_step(model, dataloader, criterion, opt):\n    model.train()\n    \n    step = 0\n    \n    epoch_train_losses = np.empty((0,))\n    for layout in tqdm(dataloader):\n        \n        node_feat, node_opcode, edge_index, node_config_feat, node_config_ids = layout[\"node_feat\"][0].to(device), layout[\"node_opcode\"][0].to(device), layout[\"edge_index\"][0].to(device), layout[\"node_config_feat\"][0].to(device), layout[\"node_config_ids\"][0].to(device)\n        y = layout[\"y\"][0].to(device)\n        node_config_feat, y = node_config_selection(node_config_feat, y, 100)\n        \n        opt.zero_grad()\n        pred = model(node_feat, node_opcode, edge_index, node_config_feat, node_config_ids)\n        loss = criterion(pred, y)\n        loss.backward()\n        \n        # max_grad_norm = 10000.0\n        # nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n        \n        parameters = [p for p in model.parameters() if p.grad is not None and p.requires_grad]     \n        gradient_norms = []\n        if len(parameters) == 0:\n            print(\"No grads\")\n            total_norm = 0.0\n        else:\n            total_norm = torch.norm(torch.stack([torch.norm(p.grad.detach(), 2).to(device) for p in parameters]), 2.0).item()\n        \n        for param_group in opt.param_groups:\n            for param in param_group['params']:\n                if param.grad is not None:\n                    gradient_norms.append(param.grad.data.norm().cpu())\n        \n        gradient_norms = np.array(gradient_norms)\n        print(f\"Avg grad norm: {np.mean(gradient_norms)}\")\n        print(f\"Max grad norm: {np.max(gradient_norms)}\")\n        print(f\"Median grad norm: {np.median(gradient_norms)}\")\n        print(f\"Total norm: {total_norm}\")        \n        \n        opt.step()\n        step += 1\n        epoch_train_losses = np.append(epoch_train_losses, loss.item())\n    return np.mean(epoch_train_losses)\n\ndef test(model, dataloader, criterion):\n    model.eval()\n    \n    epoch_valid_losses = np.empty((0,))\n    \n    with torch.no_grad():\n        for layout in dataloader:\n                \n            node_feat, node_opcode, edge_index, node_config_feat, node_config_ids = layout[\"node_feat\"][0].to(device), layout[\"node_opcode\"][0].to(device), layout[\"edge_index\"][0].to(device), layout[\"node_config_feat\"][0].to(device), layout[\"node_config_ids\"][0].to(device)\n            y = layout[\"y\"][0].to(device)\n            \n            node_config_feat, y = node_config_selection(node_config_feat, y, 1)\n            \n            pred = model(node_feat, node_opcode, edge_index, node_config_feat, node_config_ids)\n            loss = criterion(pred, y)\n            \n            epoch_valid_losses = np.append(epoch_valid_losses, loss.item())\n    return np.mean(epoch_valid_losses)\n\ndef train(model, trainloader, validloader, lr = 0.01, epochs = 10):\n    \n    model.to(device)\n    \n    loss_fn = nn.MSELoss().to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    \n    train_losses = np.empty((0,))\n    valid_losses = np.empty((0,))\n    \n    for i in range(1, epochs + 1):\n    \n        train_loss = train_step(model, trainloader, loss_fn, optimizer)\n        valid_loss = test(model, validloader, loss_fn)\n    \n        train_losses = np.append(train_losses, train_loss)\n        valid_losses = np.append(valid_losses, valid_loss) \n        print(f\"Epoch: {i}, Train Loss: {train_loss}, Valid Loss: {valid_loss}\")\n    \n    return valid_losses[-1]","metadata":{"execution":{"iopub.status.busy":"2023-09-30T11:19:18.035031Z","iopub.execute_input":"2023-09-30T11:19:18.035637Z","iopub.status.idle":"2023-09-30T11:19:18.050814Z","shell.execute_reply.started":"2023-09-30T11:19:18.035608Z","shell.execute_reply":"2023-09-30T11:19:18.049977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(42)\nrandom.seed(42)\n\nmodel = LayoutModel()\n# trainloader = DataLoader(LayoutDataset(layout_nlp_default, 'train'), batch_size = 1, shuffle = True)\n# validloader = DataLoader(LayoutDataset(layout_nlp_default, 'valid'), batch_size = 1, shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T11:19:18.054018Z","iopub.execute_input":"2023-09-30T11:19:18.054301Z","iopub.status.idle":"2023-09-30T11:19:18.069385Z","shell.execute_reply.started":"2023-09-30T11:19:18.054274Z","shell.execute_reply":"2023-09-30T11:19:18.068591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train(model, trainloader, validloader, lr=0.01, epochs=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T11:19:18.070850Z","iopub.execute_input":"2023-09-30T11:19:18.071431Z","iopub.status.idle":"2023-09-30T11:19:18.075397Z","shell.execute_reply.started":"2023-09-30T11:19:18.071402Z","shell.execute_reply":"2023-09-30T11:19:18.074579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predictions","metadata":{}},{"cell_type":"code","source":"def predict(model, layout):\n    model = model.to(device)\n    node_feat, node_opcode, edge_index, node_config_feat, node_config_ids = layout[\"node_feat\"].to(device), layout[\"node_opcode\"].to(device), layout[\"edge_index\"].to(device), layout[\"node_config_feat\"].to(device), layout[\"node_config_ids\"].to(device)\n    \n    runtimes = []\n    for i in range(len(node_config_feat)):\n        pred = model(node_feat, node_opcode, edge_index, node_config_feat[i:i+1, :, :], node_config_ids)\n        runtimes.append(pred)\n    \n    runtimes = torch.cat(runtimes)\n    \n    return torch.sort(runtimes).indices\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-30T11:19:18.076762Z","iopub.execute_input":"2023-09-30T11:19:18.077526Z","iopub.status.idle":"2023-09-30T11:19:18.088282Z","shell.execute_reply.started":"2023-09-30T11:19:18.077385Z","shell.execute_reply":"2023-09-30T11:19:18.087573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predictions_per_file(model, dataset):\n    \n    model.eval()\n    prediction_for_file = {}\n    \n    with torch.no_grad():\n        for layout in dataset:\n            prediction_for_file[layout[\"file\"]] = predict(model, layout)\n    \n    return prediction_for_file\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-30T11:19:18.089635Z","iopub.execute_input":"2023-09-30T11:19:18.090238Z","iopub.status.idle":"2023-09-30T11:19:18.097988Z","shell.execute_reply.started":"2023-09-30T11:19:18.090210Z","shell.execute_reply":"2023-09-30T11:19:18.097209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import kendalltau\n\ndef evaluate(model, dataset):\n    model.eval()\n    \n    correlations = np.array([])\n    p_values = np.array([])\n    \n    with torch.no_grad():\n        for layout in tqdm(dataset):\n            preds = predict(model, layout).cpu()\n            actual = torch.sort(layout[\"y\"]).indices\n            correlation, p_value = kendalltau(preds, actual)\n        \n            correlations = np.append(correlations, correlation)\n            p_values = np.append(p_values, p_value)\n            \n    print(f\"Average Tau: {np.mean(correlations)}\")\n    print(f\"Max Tau: {np.max(correlations)}\")\n          \n    plt.boxplot(correlations)\n    plt.title(\"Kendall Tau\")\n    plt.ylabel(\"Tau Coefficient\")\n    plt.show()\n    \n            \n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-30T11:19:18.099196Z","iopub.execute_input":"2023-09-30T11:19:18.100050Z","iopub.status.idle":"2023-09-30T11:19:18.603714Z","shell.execute_reply.started":"2023-09-30T11:19:18.100015Z","shell.execute_reply":"2023-09-30T11:19:18.602836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_dataset = LayoutLazyDataset(layout_nlp_default, 'test')\n# evaluate(model, test_dataset)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-30T11:19:18.604907Z","iopub.execute_input":"2023-09-30T11:19:18.605265Z","iopub.status.idle":"2023-09-30T11:19:18.609508Z","shell.execute_reply.started":"2023-09-30T11:19:18.605213Z","shell.execute_reply":"2023-09-30T11:19:18.608565Z"},"trusted":true},"execution_count":null,"outputs":[]}]}