{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch-geometric","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:23:39.479495Z","iopub.execute_input":"2023-09-15T08:23:39.479899Z","iopub.status.idle":"2023-09-15T08:23:54.147025Z","shell.execute_reply.started":"2023-09-15T08:23:39.479864Z","shell.execute_reply":"2023-09-15T08:23:54.145871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom tqdm import tqdm\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch_geometric import nn as gnn\n\nfrom matplotlib import pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:23:54.149028Z","iopub.execute_input":"2023-09-15T08:23:54.149359Z","iopub.status.idle":"2023-09-15T08:24:16.000584Z","shell.execute_reply.started":"2023-09-15T08:23:54.149326Z","shell.execute_reply":"2023-09-15T08:24:15.999452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"splits = [\"train\", \"valid\", \"test\"]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-15T08:24:16.001906Z","iopub.execute_input":"2023-09-15T08:24:16.002420Z","iopub.status.idle":"2023-09-15T08:24:16.006774Z","shell.execute_reply.started":"2023-09-15T08:24:16.002380Z","shell.execute_reply":"2023-09-15T08:24:16.006012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layout_nlp_default = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/nlp/default'\nlayout_nlp_random = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/nlp/random'\nlayout_xla_default = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/xla/default'\nlayout_xla_random = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/xla/random'\n\ntile_xla = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/tile/xla'","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:24:16.008755Z","iopub.execute_input":"2023-09-15T08:24:16.009042Z","iopub.status.idle":"2023-09-15T08:24:16.019650Z","shell.execute_reply.started":"2023-09-15T08:24:16.009015Z","shell.execute_reply":"2023-09-15T08:24:16.018936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_n_data_to_df(directory, split, n, pos=0):\n    \n    path = os.path.join(directory, split)\n    files = os.listdir(path)\n    \n    data_list = []\n    \n    n = min(n, len(files))\n    for file in tqdm(files[pos:pos + n]):\n        file_path = os.path.join(path, file)\n        model_graph = dict(np.load(file_path))\n        model_graph[\"file\"] = file\n        data_list.append(model_graph)\n    \n    return pd.DataFrame(data_list)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:24:16.020624Z","iopub.execute_input":"2023-09-15T08:24:16.020892Z","iopub.status.idle":"2023-09-15T08:24:16.029699Z","shell.execute_reply.started":"2023-09-15T08:24:16.020867Z","shell.execute_reply":"2023-09-15T08:24:16.028894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data_to_df(directory, split):\n    \n    n = len(os.listdir(os.path.join(directory, split)))\n    return load_n_data_to_df(directory, split, n)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:24:16.030689Z","iopub.execute_input":"2023-09-15T08:24:16.031035Z","iopub.status.idle":"2023-09-15T08:24:16.039477Z","shell.execute_reply.started":"2023-09-15T08:24:16.031008Z","shell.execute_reply":"2023-09-15T08:24:16.038723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_layout = load_n_data_to_df(layout_nlp_random, \"valid\", 5)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:24:16.040550Z","iopub.execute_input":"2023-09-15T08:24:16.040841Z","iopub.status.idle":"2023-09-15T08:24:20.516080Z","shell.execute_reply.started":"2023-09-15T08:24:16.040814Z","shell.execute_reply":"2023-09-15T08:24:20.515267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(6):\n    print(len(df_layout.iloc[3, i]))\n\nprint(len(df_layout.iloc[3, 3][0]))\ndf_layout.iloc[3]","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:24:20.517200Z","iopub.execute_input":"2023-09-15T08:24:20.517491Z","iopub.status.idle":"2023-09-15T08:24:23.306036Z","shell.execute_reply.started":"2023-09-15T08:24:20.517465Z","shell.execute_reply":"2023-09-15T08:24:23.305117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df_layout","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:24:23.307298Z","iopub.execute_input":"2023-09-15T08:24:23.307601Z","iopub.status.idle":"2023-09-15T08:24:23.311758Z","shell.execute_reply.started":"2023-09-15T08:24:23.307573Z","shell.execute_reply":"2023-09-15T08:24:23.310940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GAT(nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, heads):\n        super().__init__()\n        self.conv1 = gnn.GATConv(in_channels, hidden_channels, heads, dropout=0.6)\n        # On the Pubmed dataset, use `heads` output heads in `conv2`.\n        self.conv2 = gnn.GATConv(hidden_channels * heads, out_channels, heads=1,\n                             concat=False, dropout=0.6)\n\n    def forward(self, x, edge_index):\n        x = F.dropout(x, p=0.6, training=self.training)\n        x = F.elu(self.conv1(x, edge_index))\n        x = F.dropout(x, p=0.6, training=self.training)\n        x = self.conv2(x, edge_index)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:24:23.315626Z","iopub.execute_input":"2023-09-15T08:24:23.315932Z","iopub.status.idle":"2023-09-15T08:24:23.325240Z","shell.execute_reply.started":"2023-09-15T08:24:23.315905Z","shell.execute_reply":"2023-09-15T08:24:23.324334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TileModel(nn.Module):\n    \n    def __init__(self, opcode_embedding_dim = 8, conv_hidden_channels = 120, conv_num_lyers = 4, conv_out_dim = 48):\n        super().__init__()\n        \n        self.opcode_embedding = nn.Embedding(120, opcode_embedding_dim)\n        \n        node_feature_dim = 140\n            \n        # hidden_channels = 8\n        # heads = 8\n        # self.conv = GAT(opcode_embedding_dim + node_feature_dim, hidden_channels, conv_out_dim, heads)\n        \n        # self.conv = gnn.GCNConv(opcode_embedding_dim + node_feature_dim, conv_out_dim)\n        \n        self.conv = gnn.GraphSAGE(opcode_embedding_dim + node_feature_dim, conv_hidden_channels, conv_num_lyers, conv_out_dim)\n        \n        config_dim = 24\n        self.fwd = nn.Sequential(\n            nn.Linear(conv_out_dim + config_dim, 48),\n            nn.ReLU(),\n            nn.Linear(48, 48),\n            nn.ReLU(),\n            nn.Linear(48, 1)\n        )\n        \n        \n    def forward(self, node_feat, node_opcode, edge_index, config_feat):\n        \"\"\"\n            Shapes:\n                node_feat    - (n, 140)\n                node_opcode  - (n, )\n                edge_index   - (m, 2)\n                config_feat  - (c, 24)\n            \n            Approach:\n                1. Opcode embeddings\n                2. Concatenate embeddings to node feature-vector\n                3. Convolutional layer for node embeddings\n                4. Pooling for graph embedding\n                5. Concatenate configuration feature-vector to graph embedding\n                6. Forward layer\n                7. Flatten\n            \n            Approach is inline with the paper Phitchaya Mangpo Phothilimthana et. al (2023) \n        \"\"\"\n        node_opcode_embedding = self.opcode_embedding(node_opcode) # (n, 8)\n        \n        x = torch.concat([node_feat, node_opcode_embedding], dim = 1) # (n, 148)\n        \n        x = self.conv(x, edge_index) # (n, 48)\n                \n        x = torch.mean(x, 0) # (48, )    \n            \n        x = x.repeat(len(config_feat), 1) # (c, 48)\n        \n        x = torch.concat([x, config_feat], dim = 1) # (c, 72)\n        \n        x = self.fwd(x) # (c, 1)\n        \n        return torch.flatten(x) # (c, )\n        ","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:24:23.326370Z","iopub.execute_input":"2023-09-15T08:24:23.326701Z","iopub.status.idle":"2023-09-15T08:24:23.341166Z","shell.execute_reply.started":"2023-09-15T08:24:23.326672Z","shell.execute_reply":"2023-09-15T08:24:23.340370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TileDataset(Dataset):\n    \n    def __init__(self, tiles):\n        self.tiles = tiles\n    \n    def __len__(self):\n        return len(self.tiles)\n    \n    def __getitem__(self, idx):\n        \n        file = self.tiles.iloc[idx]['file']\n        node_feat = torch.from_numpy(self.tiles.iloc[idx]['node_feat'])\n        node_opcode = torch.from_numpy(self.tiles.iloc[idx]['node_opcode']).type(torch.int64)\n        edge_index = torch.from_numpy(self.tiles.iloc[idx]['edge_index']).permute(1, 0)\n        config_feat = torch.from_numpy(self.tiles.iloc[idx]['config_feat'])\n        config_runtime = torch.from_numpy(self.tiles.iloc[idx]['config_runtime'])\n        config_runtime_normalizers = torch.from_numpy(self.tiles.iloc[idx]['config_runtime_normalizers'])\n        \n        return {\n            \"file\": file,\n            \"node_feat\": node_feat,\n            \"node_opcode\": node_opcode,\n            \"edge_index\": edge_index,\n            \"config_feat\": config_feat,\n            \"y\": config_runtime / config_runtime_normalizers\n        }\n    \n    def __iter__(self):\n        self.i = 0\n        return self\n    \n    def __next__(self):\n        if self.i < len(self.tiles):\n            item = self[self.i]\n            self.i += 1\n            return item\n        else:\n            raise StopIteration\n\ndf_train = load_data_to_df(tile_xla, \"train\")\ndf_valid = load_data_to_df(tile_xla, \"valid\")\ndf_test = load_data_to_df(tile_xla, \"test\")\n\ntrain_dataset = TileDataset(df_train)\nvalid_dataset = TileDataset(df_valid)\ntest_dataset = TileDataset(df_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:24:23.342295Z","iopub.execute_input":"2023-09-15T08:24:23.342574Z","iopub.status.idle":"2023-09-15T08:25:48.109125Z","shell.execute_reply.started":"2023-09-15T08:24:23.342548Z","shell.execute_reply":"2023-09-15T08:25:48.108222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = TileModel()\n\ndata = train_dataset[0]\n\nmodel(data['node_feat'], data['node_opcode'], data['edge_index'], data['config_feat'])","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-09-15T08:25:48.110281Z","iopub.execute_input":"2023-09-15T08:25:48.110608Z","iopub.status.idle":"2023-09-15T08:25:48.143852Z","shell.execute_reply.started":"2023-09-15T08:25:48.110578Z","shell.execute_reply":"2023-09-15T08:25:48.142983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_num_params(model):\n    # Count the number of parameters\n    total_params = sum(p.numel() for p in model.parameters())\n    print(f\"Total parameters in the model: {total_params}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:25:48.145053Z","iopub.execute_input":"2023-09-15T08:25:48.145368Z","iopub.status.idle":"2023-09-15T08:25:48.150387Z","shell.execute_reply.started":"2023-09-15T08:25:48.145339Z","shell.execute_reply":"2023-09-15T08:25:48.149511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndef train_step(model, criterion, opt):\n    model.train()\n    \n    epoch_train_losses = np.empty((0,))\n    for tile in tqdm(train_dataset):\n        \n        node_feat, node_opcode, edge_index, config_feat = tile[\"node_feat\"].to(device), tile[\"node_opcode\"].to(device), tile[\"edge_index\"].to(device), tile[\"config_feat\"].to(device)\n        \n        opt.zero_grad()\n        pred = model(node_feat, node_opcode, edge_index, config_feat).to(\"cpu\")\n        loss = criterion(pred, tile[\"y\"])\n                \n        loss.backward()\n        opt.step()\n        \n        epoch_train_losses = np.append(epoch_train_losses, loss.item())\n    return np.mean(epoch_train_losses)\n\ndef test(model, criterion):\n    model.eval()\n    \n    epoch_valid_losses = np.empty((0,))\n    \n    with torch.no_grad():\n        for tile in valid_dataset:\n                \n            node_feat, node_opcode, edge_index, config_feat = tile[\"node_feat\"].to(device), tile[\"node_opcode\"].to(device), tile[\"edge_index\"].to(device), tile[\"config_feat\"].to(device)\n    \n            pred = model(node_feat, node_opcode, edge_index, config_feat).to(\"cpu\")\n            loss = criterion(pred, tile[\"y\"])\n            \n            epoch_valid_losses = np.append(epoch_valid_losses, loss.item())\n    return np.mean(epoch_valid_losses)\n\ndef train(model, lr = 0.01, epochs = 10):\n    \n    model.to(device)\n    \n    loss_fn = nn.MSELoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    \n    train_losses = np.empty((0,))\n    valid_losses = np.empty((0,))\n    \n    for i in range(1, epochs + 1):\n    \n        train_loss = train_step(model, loss_fn, optimizer)\n        valid_loss = test(model, loss_fn)\n    \n        train_losses = np.append(train_losses, train_loss)\n        valid_losses = np.append(valid_losses, valid_loss) \n        print(f\"Epoch: {i}, Train Loss: {train_losses[-1]}, Valid Loss: {valid_losses[-1]}\")\n    \n    return valid_losses[-1]\n","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:25:48.151575Z","iopub.execute_input":"2023-09-15T08:25:48.151879Z","iopub.status.idle":"2023-09-15T08:25:48.168338Z","shell.execute_reply.started":"2023-09-15T08:25:48.151851Z","shell.execute_reply":"2023-09-15T08:25:48.167595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def store_model(model):\n    # Store model\n    torch.save(model.state_dict(), \"tile_model.pt\")","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:25:48.169471Z","iopub.execute_input":"2023-09-15T08:25:48.169779Z","iopub.status.idle":"2023-09-15T08:25:48.183191Z","shell.execute_reply.started":"2023-09-15T08:25:48.169753Z","shell.execute_reply":"2023-09-15T08:25:48.182375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_losses(valid_losses, train_losses):\n    # Plot losses\n    all_epochs = list(1, 1 + range(len(valid_losses)))\n\n    # create figure and axis objects with subplots()\n    fig,ax = plt.subplots()\n    # make a plot\n    ax.plot(all_epochs,\n        valid_losses,\n        color=\"red\", \n        marker=\"o\")\n    # set x-axis label\n    ax.set_xlabel(\"Epoch\", fontsize = 14)\n    # set y-axis label\n    ax.set_ylabel(\"Valid\",\n              color=\"red\",\n              fontsize=14)\n\n    # twin object for two different y-axis on the sample plot\n    ax2=ax.twinx()\n    # make a plot with different y-axis using second axis object\n    ax2.plot(all_epochs, train_losses,color=\"blue\",marker=\"o\")\n    ax2.set_ylabel(\"Train\",color=\"blue\",fontsize=14)\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:25:48.184212Z","iopub.execute_input":"2023-09-15T08:25:48.184494Z","iopub.status.idle":"2023-09-15T08:25:48.196762Z","shell.execute_reply.started":"2023-09-15T08:25:48.184461Z","shell.execute_reply":"2023-09-15T08:25:48.196012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(tile, model):\n    model = model.to(device)\n    node_feat = tile[\"node_feat\"].to(device)\n    node_opcode = tile[\"node_opcode\"].to(device)\n    edge_index = tile[\"edge_index\"].to(device)\n    config_feat = tile[\"config_feat\"].to(device)\n    \n    out = model(node_feat, node_opcode, edge_index, config_feat).to(\"cpu\")\n    return torch.sort(out).indices[:5]\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:25:48.197760Z","iopub.execute_input":"2023-09-15T08:25:48.198049Z","iopub.status.idle":"2023-09-15T08:25:48.206952Z","shell.execute_reply.started":"2023-09-15T08:25:48.198023Z","shell.execute_reply":"2023-09-15T08:25:48.206172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predictions_per_file(model, dataset):\n    \n    if isinstance(model, str):\n        state_dict = torch.load(model)\n        model = TileModel()\n        model.load_state_dict(state_dict)\n    \n    model.eval()\n    prediction_for_file = {}\n    \n    with torch.no_grad():\n        for tile in dataset:\n            prediction_for_file[tile[\"file\"]] = predict(tile, model)\n\n    return prediction_for_file","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:25:48.207957Z","iopub.execute_input":"2023-09-15T08:25:48.208246Z","iopub.status.idle":"2023-09-15T08:25:48.217923Z","shell.execute_reply.started":"2023-09-15T08:25:48.208221Z","shell.execute_reply":"2023-09-15T08:25:48.217159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model):\n    \n    # Make predictions\n    predictions = list(get_predictions_per_file(model, valid_dataset).values())\n\n    # Calculate score\n    scores = np.empty((0,))\n\n    for i, tile in tqdm(enumerate(valid_dataset), total=len(valid_dataset)):\n        best_prediction = min([valid_dataset[i][\"y\"][pred_ind] for pred_ind in predictions[i][:5]])\n        best_total = min(valid_dataset[i][\"y\"])\n        scores = np.append(scores, 2.0 - best_prediction / best_total)\n\n    avg_score = np.mean(scores)\n    print(\"Score:\", avg_score)\n    return avg_score\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:25:48.218930Z","iopub.execute_input":"2023-09-15T08:25:48.219224Z","iopub.status.idle":"2023-09-15T08:25:48.227982Z","shell.execute_reply.started":"2023-09-15T08:25:48.219194Z","shell.execute_reply":"2023-09-15T08:25:48.227230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\nimport math\n\ndef hyperparameter_search():\n    \n    opcode_embedding = [4, 8, 16]\n    hidden_channels = [64, 128, 256]\n    num_layers = [5, 7]\n    conv_out_dim = [32, 48, 64]\n    lr = [0.001, 0.01]\n    epochs = [15]\n    \n    hyperparameters = [opcode_embedding, hidden_channels, num_layers, conv_out_dim, lr, epochs]\n    \n    best_score = 0.0\n    best_config = ()\n    best_model = None\n    \n    \n    configs = list(itertools.product(*hyperparameters))\n    num_configs = len(configs)\n    \n    print(configs[58])\n    \n    print(f\"Testing a total of {num_configs} configurations\")\n    \n    for i, config in enumerate(configs):\n        \n        print(f\"Testing config {i + 1}/{num_configs}\")\n        print(config)\n        \n        model = TileModel(config[0], config[1], config[2], config[3]).to(device)\n        \n        train(model, config[4], config[5])\n                \n        score = evaluate_model(model)\n                \n        if score > best_score:\n            best_score = score\n            best_config = config\n            best_model = model\n            store_model(model)\n        \n        del model\n                    \n    return best_model, best_config, best_score\n","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:26:02.428983Z","iopub.execute_input":"2023-09-15T08:26:02.429319Z","iopub.status.idle":"2023-09-15T08:26:02.440424Z","shell.execute_reply.started":"2023-09-15T08:26:02.429290Z","shell.execute_reply":"2023-09-15T08:26:02.439584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hyperparameter_search()\nmodel = TileModel(8, 128, 7, 64).to(device)\n# train(model, 0.001, 15)\n# score = evaluate_model(model)\n# print(score)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:26:02.441490Z","iopub.execute_input":"2023-09-15T08:26:02.441801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hyperparameter_search()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_submission():\n    \n    submission = pd.read_csv(\"/kaggle/input/predict-ai-model-runtime/sample_submission.csv\")\n    \n    state_dict = torch.load(\"tile_model.pt\")\n    model = TileModel(16, 256, 7, 64)\n    model.load_state_dict(state_dict)\n    predictions = get_predictions_per_file(model, test_dataset)\n    \n    for model_name in predictions.keys():\n        model_id = 'tile:xla:' + model_name[:-4]\n        submission.loc[submission[\"ID\"] == model_id, \"TopConfigs\"] = \";\".join([str(pred) for pred in predictions[model_name].tolist()])\n    \n    submission.to_csv(\"submission.csv\", index=False)\n        \n# create_submission()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}