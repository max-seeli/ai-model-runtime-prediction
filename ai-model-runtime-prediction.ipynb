{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch-geometric","metadata":{"execution":{"iopub.status.busy":"2023-09-14T00:40:02.233702Z","iopub.execute_input":"2023-09-14T00:40:02.234310Z","iopub.status.idle":"2023-09-14T00:40:15.728948Z","shell.execute_reply.started":"2023-09-14T00:40:02.234254Z","shell.execute_reply":"2023-09-14T00:40:15.727542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom tqdm import tqdm\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch_geometric import nn as gnn\n\nfrom matplotlib import pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-09-14T00:40:15.732113Z","iopub.execute_input":"2023-09-14T00:40:15.732869Z","iopub.status.idle":"2023-09-14T00:40:15.738854Z","shell.execute_reply.started":"2023-09-14T00:40:15.732831Z","shell.execute_reply":"2023-09-14T00:40:15.737846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"splits = [\"train\", \"valid\", \"test\"]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-14T00:40:15.740373Z","iopub.execute_input":"2023-09-14T00:40:15.740963Z","iopub.status.idle":"2023-09-14T00:40:15.752173Z","shell.execute_reply.started":"2023-09-14T00:40:15.740913Z","shell.execute_reply":"2023-09-14T00:40:15.751220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layout_nlp_default = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/nlp/default'\nlayout_nlp_random = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/nlp/random'\nlayout_xla_default = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/xla/default'\nlayout_xla_random = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/xla/random'\n\ntile_xla = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/tile/xla'","metadata":{"execution":{"iopub.status.busy":"2023-09-14T00:40:15.756981Z","iopub.execute_input":"2023-09-14T00:40:15.757322Z","iopub.status.idle":"2023-09-14T00:40:15.763690Z","shell.execute_reply.started":"2023-09-14T00:40:15.757299Z","shell.execute_reply":"2023-09-14T00:40:15.762471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_n_data_to_df(directory, split, n, pos=0):\n    \n    path = os.path.join(directory, split)\n    files = os.listdir(path)\n    \n    data_list = []\n    \n    n = min(n, len(files))\n    for file in tqdm(files[pos:pos + n]):\n        file_path = os.path.join(path, file)\n        model_graph = dict(np.load(file_path))\n        model_graph[\"file\"] = file\n        data_list.append(model_graph)\n    \n    return pd.DataFrame(data_list)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T00:40:15.765825Z","iopub.execute_input":"2023-09-14T00:40:15.766267Z","iopub.status.idle":"2023-09-14T00:40:15.775517Z","shell.execute_reply.started":"2023-09-14T00:40:15.766235Z","shell.execute_reply":"2023-09-14T00:40:15.774661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data_to_df(directory, split):\n    \n    n = len(os.listdir(os.path.join(directory, split)))\n    return load_n_data_to_df(directory, split, n)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T00:40:15.777228Z","iopub.execute_input":"2023-09-14T00:40:15.777661Z","iopub.status.idle":"2023-09-14T00:40:15.789970Z","shell.execute_reply.started":"2023-09-14T00:40:15.777564Z","shell.execute_reply":"2023-09-14T00:40:15.788926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_layout = load_n_data_to_df(layout_nlp_random, \"valid\", 5)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T00:40:15.791691Z","iopub.execute_input":"2023-09-14T00:40:15.792613Z","iopub.status.idle":"2023-09-14T00:40:21.572413Z","shell.execute_reply.started":"2023-09-14T00:40:15.792574Z","shell.execute_reply":"2023-09-14T00:40:21.571338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(6):\n    print(len(df_layout.iloc[3, i]))\n\nprint(len(df_layout.iloc[3, 3][0]))\ndf_layout.iloc[3]","metadata":{"execution":{"iopub.status.busy":"2023-09-14T00:40:21.574292Z","iopub.execute_input":"2023-09-14T00:40:21.575012Z","iopub.status.idle":"2023-09-14T00:40:23.992715Z","shell.execute_reply.started":"2023-09-14T00:40:21.574973Z","shell.execute_reply":"2023-09-14T00:40:23.991619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df_layout","metadata":{"execution":{"iopub.status.busy":"2023-09-14T00:40:23.994121Z","iopub.execute_input":"2023-09-14T00:40:23.994551Z","iopub.status.idle":"2023-09-14T00:40:23.999659Z","shell.execute_reply.started":"2023-09-14T00:40:23.994518Z","shell.execute_reply":"2023-09-14T00:40:23.998595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = load_data_to_df(tile_xla, \"train\")\ndf_valid = load_data_to_df(tile_xla, \"valid\")\ndf_test = load_data_to_df(tile_xla, \"test\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T00:40:24.005001Z","iopub.execute_input":"2023-09-14T00:40:24.005499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GAT(nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, heads):\n        super().__init__()\n        self.conv1 = gnn.GATConv(in_channels, hidden_channels, heads, dropout=0.6)\n        # On the Pubmed dataset, use `heads` output heads in `conv2`.\n        self.conv2 = gnn.GATConv(hidden_channels * heads, out_channels, heads=1,\n                             concat=False, dropout=0.6)\n\n    def forward(self, x, edge_index):\n        x = F.dropout(x, p=0.6, training=self.training)\n        x = F.elu(self.conv1(x, edge_index))\n        x = F.dropout(x, p=0.6, training=self.training)\n        x = self.conv2(x, edge_index)\n        return x\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TileModel(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        \n        op_embedding_dim = 8\n        self.opcode_embedding = nn.Embedding(120, op_embedding_dim)\n        \n        node_feature_dim = 140\n        \n        conv_out_dim = 48\n        \n        \n        # hidden_channels = 8\n        # heads = 8\n        # self.conv = GAT(op_embedding_dim + node_feature_dim, hidden_channels, conv_out_dim, heads)\n        \n        # self.conv = gnn.GCNConv(op_embedding_dim + node_feature_dim, conv_out_dim)\n        \n        hidden_channels = 120\n        num_layers = 4\n        self.conv = gnn.GraphSAGE(op_embedding_dim + node_feature_dim, hidden_channels, num_layers, conv_out_dim)\n        \n        config_dim = 24\n        self.fwd = nn.Sequential(\n            nn.Linear(conv_out_dim + config_dim, 48),\n            nn.ReLU(),\n            nn.Linear(48, 48),\n            nn.ReLU(),\n            nn.Linear(48, 1)\n        )\n        \n        \n    def forward(self, node_feat, node_opcode, edge_index, config_feat):\n        \"\"\"\n            Shapes:\n                node_feat    - (n, 140)\n                node_opcode  - (n, )\n                edge_index   - (m, 2)\n                config_feat  - (c, 24)\n            \n            Approach:\n                1. Opcode embeddings\n                2. Concatenate embeddings to node feature-vector\n                3. Convolutional layer for node embeddings\n                4. Pooling for graph embedding\n                5. Concatenate configuration feature-vector to graph embedding\n                6. Forward layer\n                7. Flatten\n            \n            Approach is inline with the paper Phitchaya Mangpo Phothilimthana et. al (2023) \n        \"\"\"\n        node_opcode_embedding = self.opcode_embedding(node_opcode) # (n, 8)\n        \n        x = torch.concat([node_feat, node_opcode_embedding], dim = 1) # (n, 148)\n        \n        x = self.conv(x, edge_index) # (n, 48)\n                \n        x = torch.mean(x, 0) # (48, )    \n            \n        x = x.repeat(len(config_feat), 1) # (c, 48)\n        \n        x = torch.concat([x, config_feat], dim = 1) # (c, 72)\n        \n        x = self.fwd(x) # (c, 1)\n        \n        return torch.flatten(x) # (c, )\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TileDataset(Dataset):\n    \n    def __init__(self, tiles):\n        self.tiles = tiles\n    \n    def __len__(self):\n        return len(self.tiles)\n    \n    def __getitem__(self, idx):\n        \n        file = self.tiles.iloc[idx]['file']\n        node_feat = torch.from_numpy(self.tiles.iloc[idx]['node_feat'])\n        node_opcode = torch.from_numpy(self.tiles.iloc[idx]['node_opcode']).type(torch.int64)\n        edge_index = torch.from_numpy(self.tiles.iloc[idx]['edge_index']).permute(1, 0)\n        config_feat = torch.from_numpy(self.tiles.iloc[idx]['config_feat'])\n        config_runtime = torch.from_numpy(self.tiles.iloc[idx]['config_runtime'])\n        config_runtime_normalizers = torch.from_numpy(self.tiles.iloc[idx]['config_runtime_normalizers'])\n        \n        return {\n            \"file\": file,\n            \"node_feat\": node_feat,\n            \"node_opcode\": node_opcode,\n            \"edge_index\": edge_index,\n            \"config_feat\": config_feat,\n            \"y\": config_runtime / config_runtime_normalizers\n        }\n    \n    def __iter__(self):\n        self.i = 0\n        return self\n    \n    def __next__(self):\n        if self.i < len(self.tiles):\n            item = self[self.i]\n            self.i += 1\n            return item\n        else:\n            raise StopIteration\n    \ntrain_dataset = TileDataset(df_train)\nvalid_dataset = TileDataset(df_valid)\ntest_dataset = TileDataset(df_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = TileModel()\n\ndata = train_dataset[0]\n\nmodel(data['node_feat'], data['node_opcode'], data['edge_index'], data['config_feat'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the number of parameters\ntotal_params = sum(p.numel() for p in model.parameters())\nprint(f\"Total parameters in the model: {total_params}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel = TileModel().to(device)\nloss_fn = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nepochs = 10\n\ntrain_losses = np.empty((0,))\nvalid_losses = np.empty((0,))\n    \n\n\ndef train():\n    model.train()\n    \n    epoch_train_losses = np.empty((0,))\n    for tile in train_dataset:\n        \n        node_feat, node_opcode, edge_index, config_feat = tile[\"node_feat\"].to(device), tile[\"node_opcode\"].to(device), tile[\"edge_index\"].to(device), tile[\"config_feat\"].to(device)\n        \n        optimizer.zero_grad()\n        pred = model(node_feat, node_opcode, edge_index, config_feat).to(\"cpu\")\n        loss = loss_fn(pred, tile[\"y\"])\n                \n        loss.backward()\n        optimizer.step()\n        \n        epoch_train_losses = np.append(epoch_train_losses, loss.item())\n    return np.mean(epoch_train_losses)\n\ndef test():\n    model.eval()\n    \n    epoch_valid_losses = np.empty((0,))\n    \n    with torch.no_grad():\n        for tile in valid_dataset:\n                \n            node_feat, node_opcode, edge_index, config_feat = tile[\"node_feat\"].to(device), tile[\"node_opcode\"].to(device), tile[\"edge_index\"].to(device), tile[\"config_feat\"].to(device)\n    \n            pred = model(node_feat, node_opcode, edge_index, config_feat).to(\"cpu\")\n            loss = loss_fn(pred, tile[\"y\"])\n            \n            epoch_valid_losses = np.append(epoch_valid_losses, loss.item())\n    return np.mean(epoch_valid_losses)\n\n\nfor i in range(1, epochs + 1):\n    \n    train_loss = train()\n    valid_loss = test()\n    \n    train_losses = np.append(train_losses, train_loss)\n    valid_losses = np.append(valid_losses, valid_loss) \n    print(f\"Epoch: {i}, Train Loss: {train_losses[-1]}, Valid Loss: {valid_losses[-1]}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Store model\ntorch.save(model.state_dict(), \"tile_model.pt\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot losses\nall_epochs = list(range(epochs))\n\n# create figure and axis objects with subplots()\nfig,ax = plt.subplots()\n# make a plot\nax.plot(all_epochs,\n        valid_losses,\n        color=\"red\", \n        marker=\"o\")\n# set x-axis label\nax.set_xlabel(\"Epoch\", fontsize = 14)\n# set y-axis label\nax.set_ylabel(\"Valid\",\n              color=\"red\",\n              fontsize=14)\n\n# twin object for two different y-axis on the sample plot\nax2=ax.twinx()\n# make a plot with different y-axis using second axis object\nax2.plot(all_epochs, train_losses,color=\"blue\",marker=\"o\")\nax2.set_ylabel(\"Train\",color=\"blue\",fontsize=14)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(tile, model):\n    model = model.to(device)\n    node_feat = tile[\"node_feat\"].to(device)\n    node_opcode = tile[\"node_opcode\"].to(device)\n    edge_index = tile[\"edge_index\"].to(device)\n    config_feat = tile[\"config_feat\"].to(device)\n    \n    out = model(node_feat, node_opcode, edge_index, config_feat).to(\"cpu\")\n    return torch.sort(out).indices[:5]\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predictions_per_file(model, dataset):\n    \n    if isinstance(model, str):\n        state_dict = torch.load(model)\n        model = TileModel()\n        model.load_state_dict(state_dict)\n    \n    model.eval()\n    prediction_for_file = {}\n    \n    with torch.no_grad():\n        for tile in dataset:\n            prediction_for_file[tile[\"file\"]] = predict(tile, model)\n\n    return prediction_for_file","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model):\n    \n    # Make predictions\n    predictions = list(get_predictions_per_file(model, valid_dataset).values())\n\n    # Calculate score\n    scores = np.empty((0,))\n\n    for i, tile in tqdm(enumerate(valid_dataset), total=len(valid_dataset)):\n        best_prediction = min([valid_dataset[i][\"y\"][pred_ind] for pred_ind in predictions[i][:5]])\n        best_total = min(valid_dataset[i][\"y\"])\n        scores = np.append(scores, 2.0 - best_prediction / best_total)\n\n    avg_score = np.mean(scores)\n    print(\"Score:\", avg_score)\n    return avg_score\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_model(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_submission():\n    \n    submission = pd.read_csv(\"/kaggle/input/predict-ai-model-runtime/sample_submission.csv\")\n    \n    predictions = get_predictions_per_file(\"tile_model.pt\", test_dataset)\n    \n    for model_name in predictions.keys():\n        model_id = 'tile:xla:' + model_name[:-4]\n        submission.loc[submission[\"ID\"] == model_id, \"TopConfigs\"] = \";\".join([str(pred) for pred in predictions[model_name].tolist()])\n    \n    submission.to_csv(\"submission.csv\", index=False)\n        \ncreate_submission()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}